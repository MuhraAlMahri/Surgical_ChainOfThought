{
  "best_global_step": 2500,
  "best_metric": 0.0984354168176651,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/exp1/models/exp1_medgemma4b_instruction/checkpoint-2500",
  "epoch": 1.070886075949367,
  "eval_steps": 125,
  "global_step": 2750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019474196689386564,
      "grad_norm": 12.791662216186523,
      "learning_rate": 6.347150259067358e-06,
      "loss": 3.0294,
      "step": 50
    },
    {
      "epoch": 0.03894839337877313,
      "grad_norm": 3.4441113471984863,
      "learning_rate": 1.2823834196891193e-05,
      "loss": 0.7578,
      "step": 100
    },
    {
      "epoch": 0.04868549172346641,
      "eval_loss": 0.29016509652137756,
      "eval_runtime": 1262.1128,
      "eval_samples_per_second": 6.961,
      "eval_steps_per_second": 3.481,
      "step": 125
    },
    {
      "epoch": 0.05842259006815969,
      "grad_norm": 3.30155348777771,
      "learning_rate": 1.9300518134715025e-05,
      "loss": 0.2626,
      "step": 150
    },
    {
      "epoch": 0.07789678675754626,
      "grad_norm": 2.7914717197418213,
      "learning_rate": 2.5777202072538865e-05,
      "loss": 0.2369,
      "step": 200
    },
    {
      "epoch": 0.09737098344693282,
      "grad_norm": 1.1721752882003784,
      "learning_rate": 3.225388601036269e-05,
      "loss": 0.2001,
      "step": 250
    },
    {
      "epoch": 0.09737098344693282,
      "eval_loss": 0.1956070512533188,
      "eval_runtime": 1264.5056,
      "eval_samples_per_second": 6.948,
      "eval_steps_per_second": 3.474,
      "step": 250
    },
    {
      "epoch": 0.11684518013631938,
      "grad_norm": 4.827869415283203,
      "learning_rate": 3.873056994818653e-05,
      "loss": 0.2092,
      "step": 300
    },
    {
      "epoch": 0.13631937682570594,
      "grad_norm": 3.4637882709503174,
      "learning_rate": 4.520725388601036e-05,
      "loss": 0.2007,
      "step": 350
    },
    {
      "epoch": 0.1460564751703992,
      "eval_loss": 0.1662958264350891,
      "eval_runtime": 1264.174,
      "eval_samples_per_second": 6.95,
      "eval_steps_per_second": 3.475,
      "step": 375
    },
    {
      "epoch": 0.15579357351509251,
      "grad_norm": 3.3574814796447754,
      "learning_rate": 4.994780793319416e-05,
      "loss": 0.1598,
      "step": 400
    },
    {
      "epoch": 0.17526777020447906,
      "grad_norm": 0.799234926700592,
      "learning_rate": 4.974706921471013e-05,
      "loss": 0.1546,
      "step": 450
    },
    {
      "epoch": 0.19474196689386564,
      "grad_norm": 2.028505802154541,
      "learning_rate": 4.954633049622611e-05,
      "loss": 0.1351,
      "step": 500
    },
    {
      "epoch": 0.19474196689386564,
      "eval_loss": 0.1460782289505005,
      "eval_runtime": 1263.5055,
      "eval_samples_per_second": 6.954,
      "eval_steps_per_second": 3.477,
      "step": 500
    },
    {
      "epoch": 0.21421616358325218,
      "grad_norm": 2.16020131111145,
      "learning_rate": 4.9345591777742094e-05,
      "loss": 0.1638,
      "step": 550
    },
    {
      "epoch": 0.23369036027263876,
      "grad_norm": 0.7911776900291443,
      "learning_rate": 4.9144853059258075e-05,
      "loss": 0.1486,
      "step": 600
    },
    {
      "epoch": 0.24342745861733203,
      "eval_loss": 0.13814182579517365,
      "eval_runtime": 1263.3463,
      "eval_samples_per_second": 6.955,
      "eval_steps_per_second": 3.477,
      "step": 625
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.40389442443847656,
      "learning_rate": 4.894411434077405e-05,
      "loss": 0.1251,
      "step": 650
    },
    {
      "epoch": 0.2726387536514119,
      "grad_norm": 0.9059221148490906,
      "learning_rate": 4.874337562229003e-05,
      "loss": 0.1421,
      "step": 700
    },
    {
      "epoch": 0.2921129503407984,
      "grad_norm": 0.6104530692100525,
      "learning_rate": 4.854263690380601e-05,
      "loss": 0.125,
      "step": 750
    },
    {
      "epoch": 0.2921129503407984,
      "eval_loss": 0.13081160187721252,
      "eval_runtime": 1267.0916,
      "eval_samples_per_second": 6.934,
      "eval_steps_per_second": 3.467,
      "step": 750
    },
    {
      "epoch": 0.31158714703018503,
      "grad_norm": 3.590296745300293,
      "learning_rate": 4.8341898185321986e-05,
      "loss": 0.1273,
      "step": 800
    },
    {
      "epoch": 0.3310613437195716,
      "grad_norm": 1.1850606203079224,
      "learning_rate": 4.814115946683797e-05,
      "loss": 0.1316,
      "step": 850
    },
    {
      "epoch": 0.34079844206426485,
      "eval_loss": 0.1191524788737297,
      "eval_runtime": 1264.1316,
      "eval_samples_per_second": 6.95,
      "eval_steps_per_second": 3.475,
      "step": 875
    },
    {
      "epoch": 0.3505355404089581,
      "grad_norm": 2.53153133392334,
      "learning_rate": 4.794042074835394e-05,
      "loss": 0.1176,
      "step": 900
    },
    {
      "epoch": 0.37000973709834467,
      "grad_norm": 0.8021656274795532,
      "learning_rate": 4.773968202986992e-05,
      "loss": 0.1161,
      "step": 950
    },
    {
      "epoch": 0.3894839337877313,
      "grad_norm": 0.42190366983413696,
      "learning_rate": 4.7538943311385904e-05,
      "loss": 0.1213,
      "step": 1000
    },
    {
      "epoch": 0.3894839337877313,
      "eval_loss": 0.11468423902988434,
      "eval_runtime": 1264.6988,
      "eval_samples_per_second": 6.947,
      "eval_steps_per_second": 3.474,
      "step": 1000
    },
    {
      "epoch": 0.4089581304771178,
      "grad_norm": 0.5396890044212341,
      "learning_rate": 4.733820459290188e-05,
      "loss": 0.1336,
      "step": 1050
    },
    {
      "epoch": 0.42843232716650437,
      "grad_norm": 3.7343380451202393,
      "learning_rate": 4.713746587441786e-05,
      "loss": 0.1155,
      "step": 1100
    },
    {
      "epoch": 0.43816942551119764,
      "eval_loss": 0.11174548417329788,
      "eval_runtime": 1262.797,
      "eval_samples_per_second": 6.958,
      "eval_steps_per_second": 3.479,
      "step": 1125
    },
    {
      "epoch": 0.44790652385589097,
      "grad_norm": 1.6785144805908203,
      "learning_rate": 4.693672715593384e-05,
      "loss": 0.1046,
      "step": 1150
    },
    {
      "epoch": 0.4673807205452775,
      "grad_norm": 0.5129356980323792,
      "learning_rate": 4.6735988437449815e-05,
      "loss": 0.1109,
      "step": 1200
    },
    {
      "epoch": 0.48685491723466406,
      "grad_norm": 1.6676509380340576,
      "learning_rate": 4.6535249718965796e-05,
      "loss": 0.1191,
      "step": 1250
    },
    {
      "epoch": 0.48685491723466406,
      "eval_loss": 0.11507166922092438,
      "eval_runtime": 1260.3309,
      "eval_samples_per_second": 6.971,
      "eval_steps_per_second": 3.486,
      "step": 1250
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.639726996421814,
      "learning_rate": 4.633451100048177e-05,
      "loss": 0.1063,
      "step": 1300
    },
    {
      "epoch": 0.5258033106134372,
      "grad_norm": 3.0422048568725586,
      "learning_rate": 4.613377228199776e-05,
      "loss": 0.1192,
      "step": 1350
    },
    {
      "epoch": 0.5355404089581305,
      "eval_loss": 0.10868248343467712,
      "eval_runtime": 1260.4756,
      "eval_samples_per_second": 6.97,
      "eval_steps_per_second": 3.485,
      "step": 1375
    },
    {
      "epoch": 0.5452775073028238,
      "grad_norm": 0.7975704073905945,
      "learning_rate": 4.593303356351373e-05,
      "loss": 0.1105,
      "step": 1400
    },
    {
      "epoch": 0.5647517039922103,
      "grad_norm": 0.6967064738273621,
      "learning_rate": 4.5732294845029714e-05,
      "loss": 0.1161,
      "step": 1450
    },
    {
      "epoch": 0.5842259006815969,
      "grad_norm": 0.9257274866104126,
      "learning_rate": 4.553155612654569e-05,
      "loss": 0.1012,
      "step": 1500
    },
    {
      "epoch": 0.5842259006815969,
      "eval_loss": 0.10884140431880951,
      "eval_runtime": 1262.2152,
      "eval_samples_per_second": 6.961,
      "eval_steps_per_second": 3.48,
      "step": 1500
    },
    {
      "epoch": 0.6037000973709834,
      "grad_norm": 0.6882683038711548,
      "learning_rate": 4.533081740806167e-05,
      "loss": 0.1185,
      "step": 1550
    },
    {
      "epoch": 0.6231742940603701,
      "grad_norm": 0.7656596302986145,
      "learning_rate": 4.513007868957765e-05,
      "loss": 0.1074,
      "step": 1600
    },
    {
      "epoch": 0.6329113924050633,
      "eval_loss": 0.10580053925514221,
      "eval_runtime": 1260.4041,
      "eval_samples_per_second": 6.971,
      "eval_steps_per_second": 3.485,
      "step": 1625
    },
    {
      "epoch": 0.6426484907497566,
      "grad_norm": 2.06453800201416,
      "learning_rate": 4.4929339971093625e-05,
      "loss": 0.1062,
      "step": 1650
    },
    {
      "epoch": 0.6621226874391432,
      "grad_norm": 0.11391545832157135,
      "learning_rate": 4.4728601252609606e-05,
      "loss": 0.1148,
      "step": 1700
    },
    {
      "epoch": 0.6815968841285297,
      "grad_norm": 1.052453875541687,
      "learning_rate": 4.452786253412559e-05,
      "loss": 0.1089,
      "step": 1750
    },
    {
      "epoch": 0.6815968841285297,
      "eval_loss": 0.10605243593454361,
      "eval_runtime": 1262.4569,
      "eval_samples_per_second": 6.959,
      "eval_steps_per_second": 3.48,
      "step": 1750
    },
    {
      "epoch": 0.7010710808179162,
      "grad_norm": 0.7291653156280518,
      "learning_rate": 4.432712381564156e-05,
      "loss": 0.0873,
      "step": 1800
    },
    {
      "epoch": 0.7205452775073028,
      "grad_norm": 1.0698312520980835,
      "learning_rate": 4.412638509715754e-05,
      "loss": 0.095,
      "step": 1850
    },
    {
      "epoch": 0.7302823758519961,
      "eval_loss": 0.10688985139131546,
      "eval_runtime": 1263.4742,
      "eval_samples_per_second": 6.954,
      "eval_steps_per_second": 3.477,
      "step": 1875
    },
    {
      "epoch": 0.7400194741966893,
      "grad_norm": 0.7528385519981384,
      "learning_rate": 4.392564637867352e-05,
      "loss": 0.1066,
      "step": 1900
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 1.54226553440094,
      "learning_rate": 4.37249076601895e-05,
      "loss": 0.1081,
      "step": 1950
    },
    {
      "epoch": 0.7789678675754625,
      "grad_norm": 1.5259941816329956,
      "learning_rate": 4.352416894170548e-05,
      "loss": 0.1078,
      "step": 2000
    },
    {
      "epoch": 0.7789678675754625,
      "eval_loss": 0.10131596028804779,
      "eval_runtime": 1262.7201,
      "eval_samples_per_second": 6.958,
      "eval_steps_per_second": 3.479,
      "step": 2000
    },
    {
      "epoch": 0.7984420642648491,
      "grad_norm": 0.47069916129112244,
      "learning_rate": 4.3323430223221454e-05,
      "loss": 0.0932,
      "step": 2050
    },
    {
      "epoch": 0.8179162609542356,
      "grad_norm": 0.5191752314567566,
      "learning_rate": 4.3122691504737435e-05,
      "loss": 0.0981,
      "step": 2100
    },
    {
      "epoch": 0.8276533592989289,
      "eval_loss": 0.10049405694007874,
      "eval_runtime": 1264.7436,
      "eval_samples_per_second": 6.947,
      "eval_steps_per_second": 3.473,
      "step": 2125
    },
    {
      "epoch": 0.8373904576436222,
      "grad_norm": 0.6711384654045105,
      "learning_rate": 4.2921952786253416e-05,
      "loss": 0.1045,
      "step": 2150
    },
    {
      "epoch": 0.8568646543330087,
      "grad_norm": 0.15026210248470306,
      "learning_rate": 4.27212140677694e-05,
      "loss": 0.1028,
      "step": 2200
    },
    {
      "epoch": 0.8763388510223953,
      "grad_norm": 0.7084754705429077,
      "learning_rate": 4.252047534928537e-05,
      "loss": 0.0975,
      "step": 2250
    },
    {
      "epoch": 0.8763388510223953,
      "eval_loss": 0.10429280996322632,
      "eval_runtime": 1264.2898,
      "eval_samples_per_second": 6.949,
      "eval_steps_per_second": 3.475,
      "step": 2250
    },
    {
      "epoch": 0.8958130477117819,
      "grad_norm": 0.5660409927368164,
      "learning_rate": 4.2319736630801346e-05,
      "loss": 0.1057,
      "step": 2300
    },
    {
      "epoch": 0.9152872444011685,
      "grad_norm": 0.33753645420074463,
      "learning_rate": 4.2118997912317334e-05,
      "loss": 0.1106,
      "step": 2350
    },
    {
      "epoch": 0.9250243427458618,
      "eval_loss": 0.09858618676662445,
      "eval_runtime": 1263.9481,
      "eval_samples_per_second": 6.951,
      "eval_steps_per_second": 3.476,
      "step": 2375
    },
    {
      "epoch": 0.934761441090555,
      "grad_norm": 0.679785966873169,
      "learning_rate": 4.191825919383331e-05,
      "loss": 0.1073,
      "step": 2400
    },
    {
      "epoch": 0.9542356377799416,
      "grad_norm": 0.24077774584293365,
      "learning_rate": 4.171752047534929e-05,
      "loss": 0.0966,
      "step": 2450
    },
    {
      "epoch": 0.9737098344693281,
      "grad_norm": 0.6740450263023376,
      "learning_rate": 4.1516781756865263e-05,
      "loss": 0.0902,
      "step": 2500
    },
    {
      "epoch": 0.9737098344693281,
      "eval_loss": 0.0984354168176651,
      "eval_runtime": 1263.2919,
      "eval_samples_per_second": 6.955,
      "eval_steps_per_second": 3.477,
      "step": 2500
    },
    {
      "epoch": 0.9931840311587147,
      "grad_norm": 0.35131141543388367,
      "learning_rate": 4.1316043038381245e-05,
      "loss": 0.0852,
      "step": 2550
    },
    {
      "epoch": 1.0124634858812074,
      "grad_norm": 0.7308456897735596,
      "learning_rate": 4.1115304319897226e-05,
      "loss": 0.0921,
      "step": 2600
    },
    {
      "epoch": 1.0222005842259008,
      "eval_loss": 0.09978897124528885,
      "eval_runtime": 1262.7573,
      "eval_samples_per_second": 6.958,
      "eval_steps_per_second": 3.479,
      "step": 2625
    },
    {
      "epoch": 1.031937682570594,
      "grad_norm": 0.6526220440864563,
      "learning_rate": 4.09145656014132e-05,
      "loss": 0.099,
      "step": 2650
    },
    {
      "epoch": 1.0514118792599805,
      "grad_norm": 0.9713829159736633,
      "learning_rate": 4.071382688292918e-05,
      "loss": 0.0997,
      "step": 2700
    },
    {
      "epoch": 1.070886075949367,
      "grad_norm": 1.2246105670928955,
      "learning_rate": 4.051308816444516e-05,
      "loss": 0.0889,
      "step": 2750
    },
    {
      "epoch": 1.070886075949367,
      "eval_loss": 0.09927733987569809,
      "eval_runtime": 1262.2717,
      "eval_samples_per_second": 6.96,
      "eval_steps_per_second": 3.48,
      "step": 2750
    }
  ],
  "logging_steps": 50,
  "max_steps": 12840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 125,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.2296475121528896e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

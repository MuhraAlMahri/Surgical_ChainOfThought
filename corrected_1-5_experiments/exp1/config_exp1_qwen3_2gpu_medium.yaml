# Qwen3-VL 2 GPUs with Medium Resolution - 12 Hour Target
# 768×768 images (~1,500 tokens) for speed

model_name: Qwen/Qwen3-VL-8B-Instruct

vision_frozen: true

lora:
  r: 16  # Can increase with medium resolution
  alpha: 32
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj]

train:
  seed: 42
  max_seq_len: 1800  # Medium resolution: ~1,500 image + ~250 text
  train_bs: 1  # Per-device (2 GPUs × 1 = 2)
  grad_accum: 8  # Effective batch = 2×1×8 = 16
  eval_bs: 1
  lr: 5.0e-6
  weight_decay: 0.0
  epochs: 3
  warmup_ratio: 0.0
  bf16: true
  gradient_checkpointing: true
  logging_steps: 10
  save_steps: 2000
  eval_steps: 2000

data:
  train_jsonl: datasets/kvasir_ULTRA_CONDENSED/train_CATEGORY_BASED.jsonl
  val_jsonl: datasets/kvasir_ULTRA_CONDENSED/val_CATEGORY_BASED.jsonl
  image_root: /l/users/muhra.almahri/Surgical_COT/datasets/Kvasir-VQA/raw/images
  use_vision_cache: false
  # Set medium resolution
  image_resolution: 768  # Process images at 768×768

eval:
  numeric_rel_tol: 0.05
  numeric_abs_tol: 0.0

# ============================================================================
# MEDIUM RESOLUTION 2-GPU TRAINING
# ============================================================================
# - 768×768 resolution: ~1,500 tokens (vs 2,900 full res)
# - 2x fewer tokens = ~2x faster processing
# - 2 GPUs: ~1.8x speedup from parallelism
# - Combined: ~3.6x faster than 1 GPU full res
# - Expected: 50h ÷ 3.6 = ~14 hours for 3 epochs
# - Quality: Slightly lower than full res, but still very good
# ============================================================================







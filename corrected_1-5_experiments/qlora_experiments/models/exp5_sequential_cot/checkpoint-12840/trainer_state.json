{
  "best_global_step": 7710,
  "best_metric": 0.08097381144762039,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/qlora_experiments/models/exp5_sequential_cot/checkpoint-7710",
  "epoch": 5.0,
  "eval_steps": 2570,
  "global_step": 12840,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019474670756347526,
      "grad_norm": 2.558105230331421,
      "learning_rate": 6.347150259067358e-06,
      "loss": 1.27,
      "step": 50
    },
    {
      "epoch": 0.03894934151269505,
      "grad_norm": 0.887501060962677,
      "learning_rate": 1.2823834196891193e-05,
      "loss": 1.1391,
      "step": 100
    },
    {
      "epoch": 0.05842401226904258,
      "grad_norm": 1.3030140399932861,
      "learning_rate": 1.9300518134715025e-05,
      "loss": 0.4441,
      "step": 150
    },
    {
      "epoch": 0.0778986830253901,
      "grad_norm": 0.9134023785591125,
      "learning_rate": 2.5777202072538865e-05,
      "loss": 0.2562,
      "step": 200
    },
    {
      "epoch": 0.09737335378173763,
      "grad_norm": 0.6383275985717773,
      "learning_rate": 3.225388601036269e-05,
      "loss": 0.1851,
      "step": 250
    },
    {
      "epoch": 0.11684802453808515,
      "grad_norm": 1.3085088729858398,
      "learning_rate": 3.873056994818653e-05,
      "loss": 0.1845,
      "step": 300
    },
    {
      "epoch": 0.13632269529443267,
      "grad_norm": 1.1855664253234863,
      "learning_rate": 4.520725388601036e-05,
      "loss": 0.1721,
      "step": 350
    },
    {
      "epoch": 0.1557973660507802,
      "grad_norm": 0.7001462578773499,
      "learning_rate": 4.994780793319416e-05,
      "loss": 0.147,
      "step": 400
    },
    {
      "epoch": 0.17527203680712772,
      "grad_norm": 0.5967233180999756,
      "learning_rate": 4.974706921471013e-05,
      "loss": 0.1319,
      "step": 450
    },
    {
      "epoch": 0.19474670756347526,
      "grad_norm": 1.016194224357605,
      "learning_rate": 4.954633049622611e-05,
      "loss": 0.1141,
      "step": 500
    },
    {
      "epoch": 0.21422137831982277,
      "grad_norm": 1.360198736190796,
      "learning_rate": 4.9345591777742094e-05,
      "loss": 0.1479,
      "step": 550
    },
    {
      "epoch": 0.2336960490761703,
      "grad_norm": 0.5921339988708496,
      "learning_rate": 4.9144853059258075e-05,
      "loss": 0.1259,
      "step": 600
    },
    {
      "epoch": 0.2531707198325178,
      "grad_norm": 1.1299903392791748,
      "learning_rate": 4.894411434077405e-05,
      "loss": 0.1165,
      "step": 650
    },
    {
      "epoch": 0.27264539058886533,
      "grad_norm": 0.7285795211791992,
      "learning_rate": 4.874337562229003e-05,
      "loss": 0.1279,
      "step": 700
    },
    {
      "epoch": 0.2921200613452129,
      "grad_norm": 0.3679521083831787,
      "learning_rate": 4.854263690380601e-05,
      "loss": 0.111,
      "step": 750
    },
    {
      "epoch": 0.3115947321015604,
      "grad_norm": 1.9986627101898193,
      "learning_rate": 4.8341898185321986e-05,
      "loss": 0.1071,
      "step": 800
    },
    {
      "epoch": 0.3310694028579079,
      "grad_norm": 1.0249972343444824,
      "learning_rate": 4.814115946683797e-05,
      "loss": 0.1096,
      "step": 850
    },
    {
      "epoch": 0.35054407361425544,
      "grad_norm": 0.9746227860450745,
      "learning_rate": 4.794042074835394e-05,
      "loss": 0.1034,
      "step": 900
    },
    {
      "epoch": 0.370018744370603,
      "grad_norm": 1.0293394327163696,
      "learning_rate": 4.773968202986992e-05,
      "loss": 0.1061,
      "step": 950
    },
    {
      "epoch": 0.3894934151269505,
      "grad_norm": 0.7394858002662659,
      "learning_rate": 4.7538943311385904e-05,
      "loss": 0.11,
      "step": 1000
    },
    {
      "epoch": 0.408968085883298,
      "grad_norm": 0.5221283435821533,
      "learning_rate": 4.733820459290188e-05,
      "loss": 0.1228,
      "step": 1050
    },
    {
      "epoch": 0.42844275663964554,
      "grad_norm": 2.9507031440734863,
      "learning_rate": 4.713746587441786e-05,
      "loss": 0.0994,
      "step": 1100
    },
    {
      "epoch": 0.4479174273959931,
      "grad_norm": 1.3251738548278809,
      "learning_rate": 4.693672715593384e-05,
      "loss": 0.0983,
      "step": 1150
    },
    {
      "epoch": 0.4673920981523406,
      "grad_norm": 0.5783472657203674,
      "learning_rate": 4.6735988437449815e-05,
      "loss": 0.0996,
      "step": 1200
    },
    {
      "epoch": 0.48686676890868813,
      "grad_norm": 0.6349902153015137,
      "learning_rate": 4.6535249718965796e-05,
      "loss": 0.1059,
      "step": 1250
    },
    {
      "epoch": 0.5063414396650356,
      "grad_norm": 1.7659626007080078,
      "learning_rate": 4.633451100048177e-05,
      "loss": 0.0862,
      "step": 1300
    },
    {
      "epoch": 0.5258161104213832,
      "grad_norm": 0.5982323288917542,
      "learning_rate": 4.613377228199776e-05,
      "loss": 0.111,
      "step": 1350
    },
    {
      "epoch": 0.5452907811777307,
      "grad_norm": 0.6744822859764099,
      "learning_rate": 4.593303356351373e-05,
      "loss": 0.0993,
      "step": 1400
    },
    {
      "epoch": 0.5647654519340782,
      "grad_norm": 3.778520345687866,
      "learning_rate": 4.5732294845029714e-05,
      "loss": 0.1074,
      "step": 1450
    },
    {
      "epoch": 0.5842401226904258,
      "grad_norm": 0.9123755693435669,
      "learning_rate": 4.553155612654569e-05,
      "loss": 0.0868,
      "step": 1500
    },
    {
      "epoch": 0.6037147934467733,
      "grad_norm": 0.8359512090682983,
      "learning_rate": 4.533081740806167e-05,
      "loss": 0.1002,
      "step": 1550
    },
    {
      "epoch": 0.6231894642031208,
      "grad_norm": 1.0460182428359985,
      "learning_rate": 4.513007868957765e-05,
      "loss": 0.0958,
      "step": 1600
    },
    {
      "epoch": 0.6426641349594684,
      "grad_norm": 2.043384075164795,
      "learning_rate": 4.4929339971093625e-05,
      "loss": 0.0994,
      "step": 1650
    },
    {
      "epoch": 0.6621388057158158,
      "grad_norm": 0.14742858707904816,
      "learning_rate": 4.4728601252609606e-05,
      "loss": 0.0992,
      "step": 1700
    },
    {
      "epoch": 0.6816134764721634,
      "grad_norm": 1.2308424711227417,
      "learning_rate": 4.452786253412559e-05,
      "loss": 0.0905,
      "step": 1750
    },
    {
      "epoch": 0.7010881472285109,
      "grad_norm": 1.1568042039871216,
      "learning_rate": 4.432712381564156e-05,
      "loss": 0.0849,
      "step": 1800
    },
    {
      "epoch": 0.7205628179848584,
      "grad_norm": 0.7812008857727051,
      "learning_rate": 4.412638509715754e-05,
      "loss": 0.0839,
      "step": 1850
    },
    {
      "epoch": 0.740037488741206,
      "grad_norm": 0.501720130443573,
      "learning_rate": 4.392564637867352e-05,
      "loss": 0.1035,
      "step": 1900
    },
    {
      "epoch": 0.7595121594975535,
      "grad_norm": 1.299431324005127,
      "learning_rate": 4.37249076601895e-05,
      "loss": 0.0897,
      "step": 1950
    },
    {
      "epoch": 0.778986830253901,
      "grad_norm": 0.8959566354751587,
      "learning_rate": 4.352416894170548e-05,
      "loss": 0.0909,
      "step": 2000
    },
    {
      "epoch": 0.7984615010102486,
      "grad_norm": 0.9959421157836914,
      "learning_rate": 4.3323430223221454e-05,
      "loss": 0.0783,
      "step": 2050
    },
    {
      "epoch": 0.817936171766596,
      "grad_norm": 0.7328907251358032,
      "learning_rate": 4.3122691504737435e-05,
      "loss": 0.0871,
      "step": 2100
    },
    {
      "epoch": 0.8374108425229436,
      "grad_norm": 0.7493707537651062,
      "learning_rate": 4.2921952786253416e-05,
      "loss": 0.0933,
      "step": 2150
    },
    {
      "epoch": 0.8568855132792911,
      "grad_norm": 0.18912550806999207,
      "learning_rate": 4.27212140677694e-05,
      "loss": 0.0869,
      "step": 2200
    },
    {
      "epoch": 0.8763601840356386,
      "grad_norm": 1.3312422037124634,
      "learning_rate": 4.252047534928537e-05,
      "loss": 0.0875,
      "step": 2250
    },
    {
      "epoch": 0.8958348547919862,
      "grad_norm": 0.6697584390640259,
      "learning_rate": 4.2319736630801346e-05,
      "loss": 0.0974,
      "step": 2300
    },
    {
      "epoch": 0.9153095255483337,
      "grad_norm": 0.5841102600097656,
      "learning_rate": 4.2118997912317334e-05,
      "loss": 0.0861,
      "step": 2350
    },
    {
      "epoch": 0.9347841963046812,
      "grad_norm": 0.5941388010978699,
      "learning_rate": 4.191825919383331e-05,
      "loss": 0.0916,
      "step": 2400
    },
    {
      "epoch": 0.9542588670610288,
      "grad_norm": 2.955653429031372,
      "learning_rate": 4.171752047534929e-05,
      "loss": 0.0894,
      "step": 2450
    },
    {
      "epoch": 0.9737335378173763,
      "grad_norm": 0.5998311042785645,
      "learning_rate": 4.1516781756865263e-05,
      "loss": 0.0824,
      "step": 2500
    },
    {
      "epoch": 0.9932082085737238,
      "grad_norm": 0.3093163073062897,
      "learning_rate": 4.1316043038381245e-05,
      "loss": 0.0766,
      "step": 2550
    },
    {
      "epoch": 1.000778986830254,
      "eval_loss": 0.08736201375722885,
      "eval_runtime": 1928.4864,
      "eval_samples_per_second": 4.556,
      "eval_steps_per_second": 4.556,
      "step": 2570
    },
    {
      "epoch": 1.0124637892840624,
      "grad_norm": 0.7896451950073242,
      "learning_rate": 4.1115304319897226e-05,
      "loss": 0.08,
      "step": 2600
    },
    {
      "epoch": 1.03193846004041,
      "grad_norm": 0.7665390968322754,
      "learning_rate": 4.09145656014132e-05,
      "loss": 0.0836,
      "step": 2650
    },
    {
      "epoch": 1.0514131307967576,
      "grad_norm": 0.8253440856933594,
      "learning_rate": 4.071382688292918e-05,
      "loss": 0.092,
      "step": 2700
    },
    {
      "epoch": 1.070887801553105,
      "grad_norm": 1.0447378158569336,
      "learning_rate": 4.051308816444516e-05,
      "loss": 0.079,
      "step": 2750
    },
    {
      "epoch": 1.0903624723094525,
      "grad_norm": 0.8265571594238281,
      "learning_rate": 4.031234944596114e-05,
      "loss": 0.0919,
      "step": 2800
    },
    {
      "epoch": 1.1098371430658,
      "grad_norm": 1.5428473949432373,
      "learning_rate": 4.011161072747712e-05,
      "loss": 0.0821,
      "step": 2850
    },
    {
      "epoch": 1.1293118138221476,
      "grad_norm": 0.8426840901374817,
      "learning_rate": 3.991087200899309e-05,
      "loss": 0.0909,
      "step": 2900
    },
    {
      "epoch": 1.148786484578495,
      "grad_norm": 0.8148809671401978,
      "learning_rate": 3.971013329050908e-05,
      "loss": 0.0812,
      "step": 2950
    },
    {
      "epoch": 1.1682611553348425,
      "grad_norm": 0.4650630056858063,
      "learning_rate": 3.9509394572025054e-05,
      "loss": 0.0958,
      "step": 3000
    },
    {
      "epoch": 1.18773582609119,
      "grad_norm": 0.8075239062309265,
      "learning_rate": 3.930865585354103e-05,
      "loss": 0.0717,
      "step": 3050
    },
    {
      "epoch": 1.2072104968475377,
      "grad_norm": 1.1517030000686646,
      "learning_rate": 3.910791713505701e-05,
      "loss": 0.0905,
      "step": 3100
    },
    {
      "epoch": 1.2266851676038852,
      "grad_norm": 1.119330644607544,
      "learning_rate": 3.890717841657299e-05,
      "loss": 0.086,
      "step": 3150
    },
    {
      "epoch": 1.2461598383602328,
      "grad_norm": 0.5373623371124268,
      "learning_rate": 3.870643969808897e-05,
      "loss": 0.0868,
      "step": 3200
    },
    {
      "epoch": 1.2656345091165804,
      "grad_norm": 0.6388840675354004,
      "learning_rate": 3.8505700979604947e-05,
      "loss": 0.0849,
      "step": 3250
    },
    {
      "epoch": 1.2851091798729277,
      "grad_norm": 1.162161111831665,
      "learning_rate": 3.830496226112093e-05,
      "loss": 0.0867,
      "step": 3300
    },
    {
      "epoch": 1.3045838506292753,
      "grad_norm": 1.2324520349502563,
      "learning_rate": 3.810422354263691e-05,
      "loss": 0.0874,
      "step": 3350
    },
    {
      "epoch": 1.3240585213856229,
      "grad_norm": 0.562613844871521,
      "learning_rate": 3.790348482415288e-05,
      "loss": 0.0876,
      "step": 3400
    },
    {
      "epoch": 1.3435331921419704,
      "grad_norm": 1.2433415651321411,
      "learning_rate": 3.7702746105668864e-05,
      "loss": 0.0897,
      "step": 3450
    },
    {
      "epoch": 1.3630078628983178,
      "grad_norm": 0.6610021591186523,
      "learning_rate": 3.750200738718484e-05,
      "loss": 0.0792,
      "step": 3500
    },
    {
      "epoch": 1.3824825336546653,
      "grad_norm": 1.1515592336654663,
      "learning_rate": 3.730126866870082e-05,
      "loss": 0.0792,
      "step": 3550
    },
    {
      "epoch": 1.401957204411013,
      "grad_norm": 1.8862751722335815,
      "learning_rate": 3.71005299502168e-05,
      "loss": 0.0765,
      "step": 3600
    },
    {
      "epoch": 1.4214318751673605,
      "grad_norm": 1.0464260578155518,
      "learning_rate": 3.6899791231732775e-05,
      "loss": 0.0807,
      "step": 3650
    },
    {
      "epoch": 1.440906545923708,
      "grad_norm": 2.392563581466675,
      "learning_rate": 3.6699052513248757e-05,
      "loss": 0.078,
      "step": 3700
    },
    {
      "epoch": 1.4603812166800556,
      "grad_norm": 0.040650367736816406,
      "learning_rate": 3.649831379476474e-05,
      "loss": 0.0722,
      "step": 3750
    },
    {
      "epoch": 1.479855887436403,
      "grad_norm": 0.4806736409664154,
      "learning_rate": 3.629757507628072e-05,
      "loss": 0.0639,
      "step": 3800
    },
    {
      "epoch": 1.4993305581927505,
      "grad_norm": 0.8713698983192444,
      "learning_rate": 3.609683635779669e-05,
      "loss": 0.0702,
      "step": 3850
    },
    {
      "epoch": 1.518805228949098,
      "grad_norm": 0.8051090836524963,
      "learning_rate": 3.589609763931267e-05,
      "loss": 0.0794,
      "step": 3900
    },
    {
      "epoch": 1.5382798997054457,
      "grad_norm": 0.5528950691223145,
      "learning_rate": 3.5695358920828655e-05,
      "loss": 0.0757,
      "step": 3950
    },
    {
      "epoch": 1.557754570461793,
      "grad_norm": 0.2836633324623108,
      "learning_rate": 3.549462020234463e-05,
      "loss": 0.0831,
      "step": 4000
    },
    {
      "epoch": 1.5772292412181406,
      "grad_norm": 1.0964597463607788,
      "learning_rate": 3.529388148386061e-05,
      "loss": 0.0748,
      "step": 4050
    },
    {
      "epoch": 1.5967039119744881,
      "grad_norm": 0.6412738561630249,
      "learning_rate": 3.5093142765376585e-05,
      "loss": 0.0725,
      "step": 4100
    },
    {
      "epoch": 1.6161785827308357,
      "grad_norm": 0.26720598340034485,
      "learning_rate": 3.4892404046892566e-05,
      "loss": 0.0813,
      "step": 4150
    },
    {
      "epoch": 1.6356532534871833,
      "grad_norm": 0.08489718288183212,
      "learning_rate": 3.469166532840855e-05,
      "loss": 0.0762,
      "step": 4200
    },
    {
      "epoch": 1.6551279242435308,
      "grad_norm": 1.5759810209274292,
      "learning_rate": 3.449092660992452e-05,
      "loss": 0.087,
      "step": 4250
    },
    {
      "epoch": 1.6746025949998784,
      "grad_norm": 3.6666407585144043,
      "learning_rate": 3.42901878914405e-05,
      "loss": 0.0924,
      "step": 4300
    },
    {
      "epoch": 1.694077265756226,
      "grad_norm": 0.754834771156311,
      "learning_rate": 3.4089449172956484e-05,
      "loss": 0.063,
      "step": 4350
    },
    {
      "epoch": 1.7135519365125733,
      "grad_norm": 0.3354836106300354,
      "learning_rate": 3.388871045447246e-05,
      "loss": 0.0754,
      "step": 4400
    },
    {
      "epoch": 1.7330266072689209,
      "grad_norm": 0.24599061906337738,
      "learning_rate": 3.368797173598844e-05,
      "loss": 0.1012,
      "step": 4450
    },
    {
      "epoch": 1.7525012780252682,
      "grad_norm": 0.5110364556312561,
      "learning_rate": 3.3487233017504414e-05,
      "loss": 0.0668,
      "step": 4500
    },
    {
      "epoch": 1.7719759487816158,
      "grad_norm": 0.299490749835968,
      "learning_rate": 3.32864942990204e-05,
      "loss": 0.0844,
      "step": 4550
    },
    {
      "epoch": 1.7914506195379634,
      "grad_norm": 0.4773801565170288,
      "learning_rate": 3.3085755580536376e-05,
      "loss": 0.087,
      "step": 4600
    },
    {
      "epoch": 1.810925290294311,
      "grad_norm": 1.4320192337036133,
      "learning_rate": 3.288501686205235e-05,
      "loss": 0.0806,
      "step": 4650
    },
    {
      "epoch": 1.8303999610506585,
      "grad_norm": 1.667637825012207,
      "learning_rate": 3.268427814356833e-05,
      "loss": 0.0879,
      "step": 4700
    },
    {
      "epoch": 1.849874631807006,
      "grad_norm": 0.7198501825332642,
      "learning_rate": 3.248353942508431e-05,
      "loss": 0.0738,
      "step": 4750
    },
    {
      "epoch": 1.8693493025633536,
      "grad_norm": 3.7369377613067627,
      "learning_rate": 3.2282800706600294e-05,
      "loss": 0.0812,
      "step": 4800
    },
    {
      "epoch": 1.8888239733197012,
      "grad_norm": 0.9260299801826477,
      "learning_rate": 3.208206198811627e-05,
      "loss": 0.0664,
      "step": 4850
    },
    {
      "epoch": 1.9082986440760485,
      "grad_norm": 0.662239134311676,
      "learning_rate": 3.188132326963224e-05,
      "loss": 0.0951,
      "step": 4900
    },
    {
      "epoch": 1.9277733148323961,
      "grad_norm": 0.5713833570480347,
      "learning_rate": 3.168058455114823e-05,
      "loss": 0.0725,
      "step": 4950
    },
    {
      "epoch": 1.9472479855887437,
      "grad_norm": 0.9719088673591614,
      "learning_rate": 3.1479845832664205e-05,
      "loss": 0.0799,
      "step": 5000
    },
    {
      "epoch": 1.966722656345091,
      "grad_norm": 0.3491615951061249,
      "learning_rate": 3.1279107114180186e-05,
      "loss": 0.0881,
      "step": 5050
    },
    {
      "epoch": 1.9861973271014386,
      "grad_norm": 0.12898622453212738,
      "learning_rate": 3.107836839569616e-05,
      "loss": 0.0794,
      "step": 5100
    },
    {
      "epoch": 2.001557973660508,
      "eval_loss": 0.0820116251707077,
      "eval_runtime": 1930.992,
      "eval_samples_per_second": 4.55,
      "eval_steps_per_second": 4.55,
      "step": 5140
    },
    {
      "epoch": 2.0054529078117773,
      "grad_norm": 0.4043625295162201,
      "learning_rate": 3.087762967721214e-05,
      "loss": 0.0791,
      "step": 5150
    },
    {
      "epoch": 2.024927578568125,
      "grad_norm": 1.2780327796936035,
      "learning_rate": 3.067689095872812e-05,
      "loss": 0.0793,
      "step": 5200
    },
    {
      "epoch": 2.0444022493244725,
      "grad_norm": 0.925430178642273,
      "learning_rate": 3.04761522402441e-05,
      "loss": 0.0836,
      "step": 5250
    },
    {
      "epoch": 2.06387692008082,
      "grad_norm": 0.663415789604187,
      "learning_rate": 3.0275413521760075e-05,
      "loss": 0.0629,
      "step": 5300
    },
    {
      "epoch": 2.0833515908371676,
      "grad_norm": 1.258466124534607,
      "learning_rate": 3.007467480327606e-05,
      "loss": 0.0846,
      "step": 5350
    },
    {
      "epoch": 2.102826261593515,
      "grad_norm": 0.3933124840259552,
      "learning_rate": 2.9873936084792037e-05,
      "loss": 0.0714,
      "step": 5400
    },
    {
      "epoch": 2.1223009323498623,
      "grad_norm": 0.20897682011127472,
      "learning_rate": 2.9673197366308015e-05,
      "loss": 0.0546,
      "step": 5450
    },
    {
      "epoch": 2.14177560310621,
      "grad_norm": 0.6074536442756653,
      "learning_rate": 2.9472458647823993e-05,
      "loss": 0.0724,
      "step": 5500
    },
    {
      "epoch": 2.1612502738625574,
      "grad_norm": 0.24954357743263245,
      "learning_rate": 2.9271719929339974e-05,
      "loss": 0.062,
      "step": 5550
    },
    {
      "epoch": 2.180724944618905,
      "grad_norm": 0.7160842418670654,
      "learning_rate": 2.907098121085595e-05,
      "loss": 0.0789,
      "step": 5600
    },
    {
      "epoch": 2.2001996153752525,
      "grad_norm": 2.005800247192383,
      "learning_rate": 2.887024249237193e-05,
      "loss": 0.0726,
      "step": 5650
    },
    {
      "epoch": 2.2196742861316,
      "grad_norm": 1.1940828561782837,
      "learning_rate": 2.8669503773887907e-05,
      "loss": 0.0738,
      "step": 5700
    },
    {
      "epoch": 2.2391489568879477,
      "grad_norm": 0.19971990585327148,
      "learning_rate": 2.8468765055403888e-05,
      "loss": 0.0772,
      "step": 5750
    },
    {
      "epoch": 2.2586236276442953,
      "grad_norm": 0.6108053922653198,
      "learning_rate": 2.8268026336919866e-05,
      "loss": 0.071,
      "step": 5800
    },
    {
      "epoch": 2.278098298400643,
      "grad_norm": 1.4367567300796509,
      "learning_rate": 2.8067287618435844e-05,
      "loss": 0.0734,
      "step": 5850
    },
    {
      "epoch": 2.29757296915699,
      "grad_norm": 1.8853429555892944,
      "learning_rate": 2.786654889995182e-05,
      "loss": 0.0774,
      "step": 5900
    },
    {
      "epoch": 2.317047639913338,
      "grad_norm": 0.8539448380470276,
      "learning_rate": 2.7665810181467806e-05,
      "loss": 0.0702,
      "step": 5950
    },
    {
      "epoch": 2.336522310669685,
      "grad_norm": 0.9497495293617249,
      "learning_rate": 2.7465071462983784e-05,
      "loss": 0.0807,
      "step": 6000
    },
    {
      "epoch": 2.3559969814260326,
      "grad_norm": 0.8462322950363159,
      "learning_rate": 2.726433274449976e-05,
      "loss": 0.066,
      "step": 6050
    },
    {
      "epoch": 2.37547165218238,
      "grad_norm": 0.7118891477584839,
      "learning_rate": 2.7063594026015736e-05,
      "loss": 0.0671,
      "step": 6100
    },
    {
      "epoch": 2.394946322938728,
      "grad_norm": 0.6315344572067261,
      "learning_rate": 2.686285530753172e-05,
      "loss": 0.0681,
      "step": 6150
    },
    {
      "epoch": 2.4144209936950753,
      "grad_norm": 1.585178256034851,
      "learning_rate": 2.6662116589047698e-05,
      "loss": 0.0717,
      "step": 6200
    },
    {
      "epoch": 2.433895664451423,
      "grad_norm": 0.7556675672531128,
      "learning_rate": 2.6461377870563676e-05,
      "loss": 0.0765,
      "step": 6250
    },
    {
      "epoch": 2.4533703352077705,
      "grad_norm": 1.464151382446289,
      "learning_rate": 2.6260639152079654e-05,
      "loss": 0.0812,
      "step": 6300
    },
    {
      "epoch": 2.472845005964118,
      "grad_norm": 1.397931694984436,
      "learning_rate": 2.6059900433595635e-05,
      "loss": 0.0812,
      "step": 6350
    },
    {
      "epoch": 2.4923196767204656,
      "grad_norm": 0.1491091102361679,
      "learning_rate": 2.5859161715111613e-05,
      "loss": 0.0785,
      "step": 6400
    },
    {
      "epoch": 2.5117943474768127,
      "grad_norm": 0.914486825466156,
      "learning_rate": 2.565842299662759e-05,
      "loss": 0.064,
      "step": 6450
    },
    {
      "epoch": 2.5312690182331608,
      "grad_norm": 1.3053919076919556,
      "learning_rate": 2.5457684278143568e-05,
      "loss": 0.0663,
      "step": 6500
    },
    {
      "epoch": 2.550743688989508,
      "grad_norm": 0.3647303283214569,
      "learning_rate": 2.525694555965955e-05,
      "loss": 0.0805,
      "step": 6550
    },
    {
      "epoch": 2.5702183597458554,
      "grad_norm": 0.9182514548301697,
      "learning_rate": 2.5056206841175527e-05,
      "loss": 0.0713,
      "step": 6600
    },
    {
      "epoch": 2.589693030502203,
      "grad_norm": 1.489528775215149,
      "learning_rate": 2.4855468122691505e-05,
      "loss": 0.0895,
      "step": 6650
    },
    {
      "epoch": 2.6091677012585506,
      "grad_norm": 1.1306533813476562,
      "learning_rate": 2.4654729404207486e-05,
      "loss": 0.0645,
      "step": 6700
    },
    {
      "epoch": 2.628642372014898,
      "grad_norm": 0.8894972205162048,
      "learning_rate": 2.4453990685723464e-05,
      "loss": 0.0699,
      "step": 6750
    },
    {
      "epoch": 2.6481170427712457,
      "grad_norm": 1.0086348056793213,
      "learning_rate": 2.4253251967239445e-05,
      "loss": 0.0703,
      "step": 6800
    },
    {
      "epoch": 2.6675917135275933,
      "grad_norm": 2.151926279067993,
      "learning_rate": 2.405251324875542e-05,
      "loss": 0.0699,
      "step": 6850
    },
    {
      "epoch": 2.687066384283941,
      "grad_norm": 2.429396390914917,
      "learning_rate": 2.38517745302714e-05,
      "loss": 0.071,
      "step": 6900
    },
    {
      "epoch": 2.7065410550402884,
      "grad_norm": 0.1840488463640213,
      "learning_rate": 2.3651035811787378e-05,
      "loss": 0.0615,
      "step": 6950
    },
    {
      "epoch": 2.7260157257966355,
      "grad_norm": 0.09777425974607468,
      "learning_rate": 2.345029709330336e-05,
      "loss": 0.0678,
      "step": 7000
    },
    {
      "epoch": 2.7454903965529835,
      "grad_norm": 0.681557834148407,
      "learning_rate": 2.3249558374819337e-05,
      "loss": 0.0738,
      "step": 7050
    },
    {
      "epoch": 2.7649650673093307,
      "grad_norm": 0.32223057746887207,
      "learning_rate": 2.3048819656335315e-05,
      "loss": 0.0632,
      "step": 7100
    },
    {
      "epoch": 2.7844397380656782,
      "grad_norm": 2.009155750274658,
      "learning_rate": 2.2848080937851292e-05,
      "loss": 0.0782,
      "step": 7150
    },
    {
      "epoch": 2.803914408822026,
      "grad_norm": 0.8232560157775879,
      "learning_rate": 2.2647342219367273e-05,
      "loss": 0.0678,
      "step": 7200
    },
    {
      "epoch": 2.8233890795783734,
      "grad_norm": 1.5280156135559082,
      "learning_rate": 2.244660350088325e-05,
      "loss": 0.0864,
      "step": 7250
    },
    {
      "epoch": 2.842863750334721,
      "grad_norm": 0.4183269739151001,
      "learning_rate": 2.2245864782399232e-05,
      "loss": 0.0696,
      "step": 7300
    },
    {
      "epoch": 2.8623384210910685,
      "grad_norm": 1.859864354133606,
      "learning_rate": 2.204512606391521e-05,
      "loss": 0.07,
      "step": 7350
    },
    {
      "epoch": 2.881813091847416,
      "grad_norm": 1.3159586191177368,
      "learning_rate": 2.1844387345431188e-05,
      "loss": 0.0836,
      "step": 7400
    },
    {
      "epoch": 2.9012877626037636,
      "grad_norm": 0.7057737112045288,
      "learning_rate": 2.1643648626947166e-05,
      "loss": 0.0633,
      "step": 7450
    },
    {
      "epoch": 2.920762433360111,
      "grad_norm": 1.2688324451446533,
      "learning_rate": 2.1442909908463147e-05,
      "loss": 0.0659,
      "step": 7500
    },
    {
      "epoch": 2.9402371041164583,
      "grad_norm": 0.21393677592277527,
      "learning_rate": 2.1242171189979124e-05,
      "loss": 0.0743,
      "step": 7550
    },
    {
      "epoch": 2.959711774872806,
      "grad_norm": 1.0718129873275757,
      "learning_rate": 2.1041432471495106e-05,
      "loss": 0.0644,
      "step": 7600
    },
    {
      "epoch": 2.9791864456291535,
      "grad_norm": 1.3490041494369507,
      "learning_rate": 2.084069375301108e-05,
      "loss": 0.0756,
      "step": 7650
    },
    {
      "epoch": 2.998661116385501,
      "grad_norm": 0.8520307540893555,
      "learning_rate": 2.063995503452706e-05,
      "loss": 0.0744,
      "step": 7700
    },
    {
      "epoch": 3.0023369604907617,
      "eval_loss": 0.08097381144762039,
      "eval_runtime": 1927.298,
      "eval_samples_per_second": 4.559,
      "eval_steps_per_second": 4.559,
      "step": 7710
    },
    {
      "epoch": 3.0179166970958398,
      "grad_norm": 2.291715383529663,
      "learning_rate": 2.043921631604304e-05,
      "loss": 0.0677,
      "step": 7750
    },
    {
      "epoch": 3.0373913678521873,
      "grad_norm": 0.507225751876831,
      "learning_rate": 2.023847759755902e-05,
      "loss": 0.0626,
      "step": 7800
    },
    {
      "epoch": 3.056866038608535,
      "grad_norm": 0.3729550838470459,
      "learning_rate": 2.0037738879074998e-05,
      "loss": 0.0485,
      "step": 7850
    },
    {
      "epoch": 3.0763407093648825,
      "grad_norm": 0.5247067213058472,
      "learning_rate": 1.9837000160590975e-05,
      "loss": 0.0788,
      "step": 7900
    },
    {
      "epoch": 3.09581538012123,
      "grad_norm": 0.7789948582649231,
      "learning_rate": 1.9636261442106953e-05,
      "loss": 0.0639,
      "step": 7950
    },
    {
      "epoch": 3.115290050877577,
      "grad_norm": 2.7609548568725586,
      "learning_rate": 1.9435522723622934e-05,
      "loss": 0.0805,
      "step": 8000
    },
    {
      "epoch": 3.1347647216339247,
      "grad_norm": 1.7804646492004395,
      "learning_rate": 1.9234784005138912e-05,
      "loss": 0.0727,
      "step": 8050
    },
    {
      "epoch": 3.1542393923902723,
      "grad_norm": 0.37674543261528015,
      "learning_rate": 1.9034045286654893e-05,
      "loss": 0.0642,
      "step": 8100
    },
    {
      "epoch": 3.17371406314662,
      "grad_norm": 3.6350605487823486,
      "learning_rate": 1.8833306568170868e-05,
      "loss": 0.0678,
      "step": 8150
    },
    {
      "epoch": 3.1931887339029674,
      "grad_norm": 0.2742744982242584,
      "learning_rate": 1.863256784968685e-05,
      "loss": 0.0544,
      "step": 8200
    },
    {
      "epoch": 3.212663404659315,
      "grad_norm": 1.1573920249938965,
      "learning_rate": 1.8431829131202826e-05,
      "loss": 0.0824,
      "step": 8250
    },
    {
      "epoch": 3.2321380754156626,
      "grad_norm": 0.4915546476840973,
      "learning_rate": 1.8231090412718808e-05,
      "loss": 0.0744,
      "step": 8300
    },
    {
      "epoch": 3.25161274617201,
      "grad_norm": 1.484659194946289,
      "learning_rate": 1.8030351694234785e-05,
      "loss": 0.0672,
      "step": 8350
    },
    {
      "epoch": 3.2710874169283577,
      "grad_norm": 1.7811529636383057,
      "learning_rate": 1.7829612975750763e-05,
      "loss": 0.0712,
      "step": 8400
    },
    {
      "epoch": 3.2905620876847053,
      "grad_norm": 0.817043662071228,
      "learning_rate": 1.762887425726674e-05,
      "loss": 0.0675,
      "step": 8450
    },
    {
      "epoch": 3.3100367584410524,
      "grad_norm": 0.3342244327068329,
      "learning_rate": 1.7428135538782722e-05,
      "loss": 0.0643,
      "step": 8500
    },
    {
      "epoch": 3.3295114291974,
      "grad_norm": 1.0535227060317993,
      "learning_rate": 1.72273968202987e-05,
      "loss": 0.0656,
      "step": 8550
    },
    {
      "epoch": 3.3489860999537475,
      "grad_norm": 0.8479731678962708,
      "learning_rate": 1.702665810181468e-05,
      "loss": 0.0678,
      "step": 8600
    },
    {
      "epoch": 3.368460770710095,
      "grad_norm": 0.556749165058136,
      "learning_rate": 1.682591938333066e-05,
      "loss": 0.057,
      "step": 8650
    },
    {
      "epoch": 3.3879354414664427,
      "grad_norm": 0.6203497052192688,
      "learning_rate": 1.6625180664846636e-05,
      "loss": 0.0663,
      "step": 8700
    },
    {
      "epoch": 3.40741011222279,
      "grad_norm": 0.8949929475784302,
      "learning_rate": 1.6424441946362614e-05,
      "loss": 0.0756,
      "step": 8750
    },
    {
      "epoch": 3.426884782979138,
      "grad_norm": 0.8875617980957031,
      "learning_rate": 1.6223703227878595e-05,
      "loss": 0.0653,
      "step": 8800
    },
    {
      "epoch": 3.4463594537354854,
      "grad_norm": 1.1317437887191772,
      "learning_rate": 1.6022964509394573e-05,
      "loss": 0.0552,
      "step": 8850
    },
    {
      "epoch": 3.465834124491833,
      "grad_norm": 1.401111364364624,
      "learning_rate": 1.5822225790910554e-05,
      "loss": 0.0681,
      "step": 8900
    },
    {
      "epoch": 3.4853087952481805,
      "grad_norm": 0.909425675868988,
      "learning_rate": 1.562148707242653e-05,
      "loss": 0.0693,
      "step": 8950
    },
    {
      "epoch": 3.504783466004528,
      "grad_norm": 1.7924774885177612,
      "learning_rate": 1.542074835394251e-05,
      "loss": 0.0552,
      "step": 9000
    },
    {
      "epoch": 3.524258136760875,
      "grad_norm": 1.8978575468063354,
      "learning_rate": 1.5220009635458487e-05,
      "loss": 0.0703,
      "step": 9050
    },
    {
      "epoch": 3.5437328075172227,
      "grad_norm": 2.2391767501831055,
      "learning_rate": 1.5019270916974469e-05,
      "loss": 0.0709,
      "step": 9100
    },
    {
      "epoch": 3.5632074782735703,
      "grad_norm": 0.6010942459106445,
      "learning_rate": 1.4818532198490445e-05,
      "loss": 0.0646,
      "step": 9150
    },
    {
      "epoch": 3.582682149029918,
      "grad_norm": 0.15369164943695068,
      "learning_rate": 1.4617793480006426e-05,
      "loss": 0.0557,
      "step": 9200
    },
    {
      "epoch": 3.6021568197862655,
      "grad_norm": 1.1946865320205688,
      "learning_rate": 1.4417054761522403e-05,
      "loss": 0.073,
      "step": 9250
    },
    {
      "epoch": 3.621631490542613,
      "grad_norm": 2.6877188682556152,
      "learning_rate": 1.4216316043038383e-05,
      "loss": 0.0648,
      "step": 9300
    },
    {
      "epoch": 3.6411061612989606,
      "grad_norm": 1.4942423105239868,
      "learning_rate": 1.401557732455436e-05,
      "loss": 0.0638,
      "step": 9350
    },
    {
      "epoch": 3.660580832055308,
      "grad_norm": 1.2867727279663086,
      "learning_rate": 1.381483860607034e-05,
      "loss": 0.066,
      "step": 9400
    },
    {
      "epoch": 3.6800555028116557,
      "grad_norm": 0.8224380016326904,
      "learning_rate": 1.3614099887586318e-05,
      "loss": 0.0643,
      "step": 9450
    },
    {
      "epoch": 3.699530173568003,
      "grad_norm": 0.08694371581077576,
      "learning_rate": 1.3413361169102299e-05,
      "loss": 0.0564,
      "step": 9500
    },
    {
      "epoch": 3.719004844324351,
      "grad_norm": 1.8279860019683838,
      "learning_rate": 1.3212622450618275e-05,
      "loss": 0.0579,
      "step": 9550
    },
    {
      "epoch": 3.738479515080698,
      "grad_norm": 1.4724392890930176,
      "learning_rate": 1.3011883732134256e-05,
      "loss": 0.069,
      "step": 9600
    },
    {
      "epoch": 3.7579541858370455,
      "grad_norm": 0.35454031825065613,
      "learning_rate": 1.2811145013650234e-05,
      "loss": 0.064,
      "step": 9650
    },
    {
      "epoch": 3.777428856593393,
      "grad_norm": 1.399311900138855,
      "learning_rate": 1.2610406295166213e-05,
      "loss": 0.0675,
      "step": 9700
    },
    {
      "epoch": 3.7969035273497407,
      "grad_norm": 1.0185964107513428,
      "learning_rate": 1.2409667576682191e-05,
      "loss": 0.0591,
      "step": 9750
    },
    {
      "epoch": 3.8163781981060882,
      "grad_norm": 0.6646443605422974,
      "learning_rate": 1.2208928858198169e-05,
      "loss": 0.0635,
      "step": 9800
    },
    {
      "epoch": 3.835852868862436,
      "grad_norm": 0.5821464657783508,
      "learning_rate": 1.2008190139714148e-05,
      "loss": 0.0657,
      "step": 9850
    },
    {
      "epoch": 3.8553275396187834,
      "grad_norm": 1.3536748886108398,
      "learning_rate": 1.1807451421230128e-05,
      "loss": 0.0614,
      "step": 9900
    },
    {
      "epoch": 3.874802210375131,
      "grad_norm": 2.9729738235473633,
      "learning_rate": 1.1606712702746105e-05,
      "loss": 0.0547,
      "step": 9950
    },
    {
      "epoch": 3.8942768811314785,
      "grad_norm": 3.709562301635742,
      "learning_rate": 1.1405973984262085e-05,
      "loss": 0.0744,
      "step": 10000
    },
    {
      "epoch": 3.9137515518878256,
      "grad_norm": 1.208885908126831,
      "learning_rate": 1.1205235265778063e-05,
      "loss": 0.0636,
      "step": 10050
    },
    {
      "epoch": 3.9332262226441737,
      "grad_norm": 0.8304363489151001,
      "learning_rate": 1.1004496547294042e-05,
      "loss": 0.0678,
      "step": 10100
    },
    {
      "epoch": 3.9527008934005208,
      "grad_norm": 0.39661315083503723,
      "learning_rate": 1.0803757828810022e-05,
      "loss": 0.0649,
      "step": 10150
    },
    {
      "epoch": 3.9721755641568683,
      "grad_norm": 0.2513391971588135,
      "learning_rate": 1.0603019110326e-05,
      "loss": 0.0608,
      "step": 10200
    },
    {
      "epoch": 3.991650234913216,
      "grad_norm": 0.7797765731811523,
      "learning_rate": 1.0402280391841979e-05,
      "loss": 0.0566,
      "step": 10250
    },
    {
      "epoch": 4.003115947321016,
      "eval_loss": 0.0843123123049736,
      "eval_runtime": 1924.7485,
      "eval_samples_per_second": 4.565,
      "eval_steps_per_second": 4.565,
      "step": 10280
    },
    {
      "epoch": 4.010905815623555,
      "grad_norm": 1.9046709537506104,
      "learning_rate": 1.0201541673357958e-05,
      "loss": 0.0506,
      "step": 10300
    },
    {
      "epoch": 4.030380486379902,
      "grad_norm": 0.7728248238563538,
      "learning_rate": 1.0000802954873936e-05,
      "loss": 0.0561,
      "step": 10350
    },
    {
      "epoch": 4.04985515713625,
      "grad_norm": 0.6647747755050659,
      "learning_rate": 9.800064236389915e-06,
      "loss": 0.0665,
      "step": 10400
    },
    {
      "epoch": 4.069329827892597,
      "grad_norm": 1.6397696733474731,
      "learning_rate": 9.599325517905893e-06,
      "loss": 0.0644,
      "step": 10450
    },
    {
      "epoch": 4.088804498648945,
      "grad_norm": 1.7221131324768066,
      "learning_rate": 9.398586799421873e-06,
      "loss": 0.063,
      "step": 10500
    },
    {
      "epoch": 4.108279169405292,
      "grad_norm": 1.4168342351913452,
      "learning_rate": 9.197848080937852e-06,
      "loss": 0.0715,
      "step": 10550
    },
    {
      "epoch": 4.12775384016164,
      "grad_norm": 0.8456053733825684,
      "learning_rate": 8.99710936245383e-06,
      "loss": 0.0622,
      "step": 10600
    },
    {
      "epoch": 4.147228510917987,
      "grad_norm": 3.749023199081421,
      "learning_rate": 8.79637064396981e-06,
      "loss": 0.0635,
      "step": 10650
    },
    {
      "epoch": 4.166703181674335,
      "grad_norm": 1.7986193895339966,
      "learning_rate": 8.595631925485789e-06,
      "loss": 0.0492,
      "step": 10700
    },
    {
      "epoch": 4.186177852430682,
      "grad_norm": 0.3222545385360718,
      "learning_rate": 8.394893207001766e-06,
      "loss": 0.0606,
      "step": 10750
    },
    {
      "epoch": 4.20565252318703,
      "grad_norm": 2.470597743988037,
      "learning_rate": 8.194154488517746e-06,
      "loss": 0.0556,
      "step": 10800
    },
    {
      "epoch": 4.225127193943377,
      "grad_norm": 1.385345697402954,
      "learning_rate": 7.993415770033724e-06,
      "loss": 0.0615,
      "step": 10850
    },
    {
      "epoch": 4.244601864699725,
      "grad_norm": 4.488131999969482,
      "learning_rate": 7.792677051549703e-06,
      "loss": 0.0717,
      "step": 10900
    },
    {
      "epoch": 4.264076535456073,
      "grad_norm": 1.172078251838684,
      "learning_rate": 7.591938333065682e-06,
      "loss": 0.0716,
      "step": 10950
    },
    {
      "epoch": 4.28355120621242,
      "grad_norm": 0.25444501638412476,
      "learning_rate": 7.39119961458166e-06,
      "loss": 0.0571,
      "step": 11000
    },
    {
      "epoch": 4.303025876968768,
      "grad_norm": 1.7342523336410522,
      "learning_rate": 7.19046089609764e-06,
      "loss": 0.0569,
      "step": 11050
    },
    {
      "epoch": 4.322500547725115,
      "grad_norm": 0.6007078886032104,
      "learning_rate": 6.989722177613618e-06,
      "loss": 0.0574,
      "step": 11100
    },
    {
      "epoch": 4.341975218481463,
      "grad_norm": 3.2825233936309814,
      "learning_rate": 6.788983459129597e-06,
      "loss": 0.0565,
      "step": 11150
    },
    {
      "epoch": 4.36144988923781,
      "grad_norm": 0.22573915123939514,
      "learning_rate": 6.5882447406455754e-06,
      "loss": 0.0581,
      "step": 11200
    },
    {
      "epoch": 4.380924559994158,
      "grad_norm": 1.0662461519241333,
      "learning_rate": 6.387506022161555e-06,
      "loss": 0.066,
      "step": 11250
    },
    {
      "epoch": 4.400399230750505,
      "grad_norm": 1.4271279573440552,
      "learning_rate": 6.1867673036775335e-06,
      "loss": 0.0591,
      "step": 11300
    },
    {
      "epoch": 4.419873901506852,
      "grad_norm": 1.2157784700393677,
      "learning_rate": 5.986028585193512e-06,
      "loss": 0.0477,
      "step": 11350
    },
    {
      "epoch": 4.4393485722632,
      "grad_norm": 0.6122291088104248,
      "learning_rate": 5.785289866709491e-06,
      "loss": 0.0594,
      "step": 11400
    },
    {
      "epoch": 4.458823243019547,
      "grad_norm": 2.156813144683838,
      "learning_rate": 5.58455114822547e-06,
      "loss": 0.0599,
      "step": 11450
    },
    {
      "epoch": 4.478297913775895,
      "grad_norm": 2.1582953929901123,
      "learning_rate": 5.383812429741449e-06,
      "loss": 0.0484,
      "step": 11500
    },
    {
      "epoch": 4.4977725845322425,
      "grad_norm": 3.4893221855163574,
      "learning_rate": 5.183073711257427e-06,
      "loss": 0.0573,
      "step": 11550
    },
    {
      "epoch": 4.5172472552885905,
      "grad_norm": 2.0909311771392822,
      "learning_rate": 4.982334992773406e-06,
      "loss": 0.0543,
      "step": 11600
    },
    {
      "epoch": 4.536721926044938,
      "grad_norm": 1.6796910762786865,
      "learning_rate": 4.781596274289385e-06,
      "loss": 0.0557,
      "step": 11650
    },
    {
      "epoch": 4.556196596801286,
      "grad_norm": 1.6569159030914307,
      "learning_rate": 4.580857555805364e-06,
      "loss": 0.06,
      "step": 11700
    },
    {
      "epoch": 4.575671267557633,
      "grad_norm": 0.7771202325820923,
      "learning_rate": 4.3801188373213425e-06,
      "loss": 0.0589,
      "step": 11750
    },
    {
      "epoch": 4.59514593831398,
      "grad_norm": 0.6111210584640503,
      "learning_rate": 4.179380118837321e-06,
      "loss": 0.0646,
      "step": 11800
    },
    {
      "epoch": 4.614620609070328,
      "grad_norm": 1.755793571472168,
      "learning_rate": 3.9786414003533e-06,
      "loss": 0.0608,
      "step": 11850
    },
    {
      "epoch": 4.634095279826676,
      "grad_norm": 1.8537170886993408,
      "learning_rate": 3.7779026818692787e-06,
      "loss": 0.0444,
      "step": 11900
    },
    {
      "epoch": 4.653569950583023,
      "grad_norm": 1.548416256904602,
      "learning_rate": 3.5771639633852578e-06,
      "loss": 0.0637,
      "step": 11950
    },
    {
      "epoch": 4.67304462133937,
      "grad_norm": 1.3429454565048218,
      "learning_rate": 3.3764252449012364e-06,
      "loss": 0.0661,
      "step": 12000
    },
    {
      "epoch": 4.692519292095718,
      "grad_norm": 0.8122550249099731,
      "learning_rate": 3.1756865264172154e-06,
      "loss": 0.0456,
      "step": 12050
    },
    {
      "epoch": 4.711993962852065,
      "grad_norm": 0.49093177914619446,
      "learning_rate": 2.9749478079331944e-06,
      "loss": 0.0503,
      "step": 12100
    },
    {
      "epoch": 4.731468633608413,
      "grad_norm": 3.3548638820648193,
      "learning_rate": 2.7742090894491734e-06,
      "loss": 0.0506,
      "step": 12150
    },
    {
      "epoch": 4.75094330436476,
      "grad_norm": 2.2233307361602783,
      "learning_rate": 2.573470370965152e-06,
      "loss": 0.0638,
      "step": 12200
    },
    {
      "epoch": 4.770417975121108,
      "grad_norm": 1.0409634113311768,
      "learning_rate": 2.372731652481131e-06,
      "loss": 0.063,
      "step": 12250
    },
    {
      "epoch": 4.789892645877456,
      "grad_norm": 4.988447189331055,
      "learning_rate": 2.1719929339971096e-06,
      "loss": 0.0525,
      "step": 12300
    },
    {
      "epoch": 4.809367316633804,
      "grad_norm": 0.35766077041625977,
      "learning_rate": 1.9712542155130882e-06,
      "loss": 0.0624,
      "step": 12350
    },
    {
      "epoch": 4.828841987390151,
      "grad_norm": 1.599137306213379,
      "learning_rate": 1.7705154970290668e-06,
      "loss": 0.0508,
      "step": 12400
    },
    {
      "epoch": 4.848316658146498,
      "grad_norm": 1.1637916564941406,
      "learning_rate": 1.5697767785450456e-06,
      "loss": 0.053,
      "step": 12450
    },
    {
      "epoch": 4.867791328902846,
      "grad_norm": 2.4098598957061768,
      "learning_rate": 1.3690380600610246e-06,
      "loss": 0.058,
      "step": 12500
    },
    {
      "epoch": 4.887265999659193,
      "grad_norm": 0.29723718762397766,
      "learning_rate": 1.1682993415770034e-06,
      "loss": 0.0519,
      "step": 12550
    },
    {
      "epoch": 4.906740670415541,
      "grad_norm": 0.39794328808784485,
      "learning_rate": 9.675606230929822e-07,
      "loss": 0.0634,
      "step": 12600
    },
    {
      "epoch": 4.926215341171888,
      "grad_norm": 0.8274386525154114,
      "learning_rate": 7.668219046089611e-07,
      "loss": 0.0519,
      "step": 12650
    },
    {
      "epoch": 4.945690011928236,
      "grad_norm": 1.688860297203064,
      "learning_rate": 5.660831861249399e-07,
      "loss": 0.055,
      "step": 12700
    },
    {
      "epoch": 4.965164682684583,
      "grad_norm": 2.585143566131592,
      "learning_rate": 3.6534446764091856e-07,
      "loss": 0.0565,
      "step": 12750
    },
    {
      "epoch": 4.984639353440931,
      "grad_norm": 0.8733022212982178,
      "learning_rate": 1.646057491568974e-07,
      "loss": 0.0628,
      "step": 12800
    }
  ],
  "logging_steps": 50,
  "max_steps": 12840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 2570,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.440217308121922e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

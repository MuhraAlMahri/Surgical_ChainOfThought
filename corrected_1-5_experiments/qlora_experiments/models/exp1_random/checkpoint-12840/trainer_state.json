{
  "best_global_step": 7710,
  "best_metric": 0.07932399958372116,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/qlora_experiments/models/exp1_random/checkpoint-7710",
  "epoch": 5.0,
  "eval_steps": 2570,
  "global_step": 12840,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019474670756347526,
      "grad_norm": 3.2358744144439697,
      "learning_rate": 6.347150259067358e-06,
      "loss": 1.365,
      "step": 50
    },
    {
      "epoch": 0.03894934151269505,
      "grad_norm": 2.134089708328247,
      "learning_rate": 1.2823834196891193e-05,
      "loss": 1.1069,
      "step": 100
    },
    {
      "epoch": 0.05842401226904258,
      "grad_norm": 1.1259195804595947,
      "learning_rate": 1.9300518134715025e-05,
      "loss": 0.4573,
      "step": 150
    },
    {
      "epoch": 0.0778986830253901,
      "grad_norm": 0.9843983054161072,
      "learning_rate": 2.5777202072538865e-05,
      "loss": 0.2513,
      "step": 200
    },
    {
      "epoch": 0.09737335378173763,
      "grad_norm": 0.8360822200775146,
      "learning_rate": 3.225388601036269e-05,
      "loss": 0.1729,
      "step": 250
    },
    {
      "epoch": 0.11684802453808515,
      "grad_norm": 0.8717260956764221,
      "learning_rate": 3.873056994818653e-05,
      "loss": 0.1771,
      "step": 300
    },
    {
      "epoch": 0.13632269529443267,
      "grad_norm": 1.4297869205474854,
      "learning_rate": 4.520725388601036e-05,
      "loss": 0.1582,
      "step": 350
    },
    {
      "epoch": 0.1557973660507802,
      "grad_norm": 1.5155220031738281,
      "learning_rate": 4.994780793319416e-05,
      "loss": 0.141,
      "step": 400
    },
    {
      "epoch": 0.17527203680712772,
      "grad_norm": 0.8040496110916138,
      "learning_rate": 4.974706921471013e-05,
      "loss": 0.1536,
      "step": 450
    },
    {
      "epoch": 0.19474670756347526,
      "grad_norm": 2.0650365352630615,
      "learning_rate": 4.954633049622611e-05,
      "loss": 0.1247,
      "step": 500
    },
    {
      "epoch": 0.21422137831982277,
      "grad_norm": 0.5549023151397705,
      "learning_rate": 4.9345591777742094e-05,
      "loss": 0.1313,
      "step": 550
    },
    {
      "epoch": 0.2336960490761703,
      "grad_norm": 0.9570275545120239,
      "learning_rate": 4.9144853059258075e-05,
      "loss": 0.1308,
      "step": 600
    },
    {
      "epoch": 0.2531707198325178,
      "grad_norm": 0.3464643359184265,
      "learning_rate": 4.894411434077405e-05,
      "loss": 0.1227,
      "step": 650
    },
    {
      "epoch": 0.27264539058886533,
      "grad_norm": 0.6415907144546509,
      "learning_rate": 4.874337562229003e-05,
      "loss": 0.1243,
      "step": 700
    },
    {
      "epoch": 0.2921200613452129,
      "grad_norm": 1.0783774852752686,
      "learning_rate": 4.854263690380601e-05,
      "loss": 0.0961,
      "step": 750
    },
    {
      "epoch": 0.3115947321015604,
      "grad_norm": 1.2778698205947876,
      "learning_rate": 4.8341898185321986e-05,
      "loss": 0.1081,
      "step": 800
    },
    {
      "epoch": 0.3310694028579079,
      "grad_norm": 0.4149257242679596,
      "learning_rate": 4.814115946683797e-05,
      "loss": 0.096,
      "step": 850
    },
    {
      "epoch": 0.35054407361425544,
      "grad_norm": 1.8097460269927979,
      "learning_rate": 4.794042074835394e-05,
      "loss": 0.1069,
      "step": 900
    },
    {
      "epoch": 0.370018744370603,
      "grad_norm": 0.48108768463134766,
      "learning_rate": 4.773968202986992e-05,
      "loss": 0.0912,
      "step": 950
    },
    {
      "epoch": 0.3894934151269505,
      "grad_norm": 0.3768472969532013,
      "learning_rate": 4.7538943311385904e-05,
      "loss": 0.0967,
      "step": 1000
    },
    {
      "epoch": 0.408968085883298,
      "grad_norm": 0.3387778103351593,
      "learning_rate": 4.733820459290188e-05,
      "loss": 0.1135,
      "step": 1050
    },
    {
      "epoch": 0.42844275663964554,
      "grad_norm": 0.8942424058914185,
      "learning_rate": 4.713746587441786e-05,
      "loss": 0.1034,
      "step": 1100
    },
    {
      "epoch": 0.4479174273959931,
      "grad_norm": 2.0872559547424316,
      "learning_rate": 4.693672715593384e-05,
      "loss": 0.1102,
      "step": 1150
    },
    {
      "epoch": 0.4673920981523406,
      "grad_norm": 1.1564322710037231,
      "learning_rate": 4.6735988437449815e-05,
      "loss": 0.1084,
      "step": 1200
    },
    {
      "epoch": 0.48686676890868813,
      "grad_norm": 1.6563714742660522,
      "learning_rate": 4.6535249718965796e-05,
      "loss": 0.102,
      "step": 1250
    },
    {
      "epoch": 0.5063414396650356,
      "grad_norm": 2.1196718215942383,
      "learning_rate": 4.633451100048177e-05,
      "loss": 0.108,
      "step": 1300
    },
    {
      "epoch": 0.5258161104213832,
      "grad_norm": 1.9026168584823608,
      "learning_rate": 4.613377228199776e-05,
      "loss": 0.082,
      "step": 1350
    },
    {
      "epoch": 0.5452907811777307,
      "grad_norm": 1.003090739250183,
      "learning_rate": 4.593303356351373e-05,
      "loss": 0.1024,
      "step": 1400
    },
    {
      "epoch": 0.5647654519340782,
      "grad_norm": 1.679473876953125,
      "learning_rate": 4.5732294845029714e-05,
      "loss": 0.0953,
      "step": 1450
    },
    {
      "epoch": 0.5842401226904258,
      "grad_norm": 0.7729378938674927,
      "learning_rate": 4.553155612654569e-05,
      "loss": 0.1098,
      "step": 1500
    },
    {
      "epoch": 0.6037147934467733,
      "grad_norm": 0.6714767813682556,
      "learning_rate": 4.533081740806167e-05,
      "loss": 0.098,
      "step": 1550
    },
    {
      "epoch": 0.6231894642031208,
      "grad_norm": 0.8112013339996338,
      "learning_rate": 4.513007868957765e-05,
      "loss": 0.0911,
      "step": 1600
    },
    {
      "epoch": 0.6426641349594684,
      "grad_norm": 1.0471410751342773,
      "learning_rate": 4.4929339971093625e-05,
      "loss": 0.1057,
      "step": 1650
    },
    {
      "epoch": 0.6621388057158158,
      "grad_norm": 1.9977575540542603,
      "learning_rate": 4.4728601252609606e-05,
      "loss": 0.0907,
      "step": 1700
    },
    {
      "epoch": 0.6816134764721634,
      "grad_norm": 1.11375093460083,
      "learning_rate": 4.452786253412559e-05,
      "loss": 0.088,
      "step": 1750
    },
    {
      "epoch": 0.7010881472285109,
      "grad_norm": 0.7888545393943787,
      "learning_rate": 4.432712381564156e-05,
      "loss": 0.096,
      "step": 1800
    },
    {
      "epoch": 0.7205628179848584,
      "grad_norm": 1.6431360244750977,
      "learning_rate": 4.412638509715754e-05,
      "loss": 0.0794,
      "step": 1850
    },
    {
      "epoch": 0.740037488741206,
      "grad_norm": 1.4778351783752441,
      "learning_rate": 4.392564637867352e-05,
      "loss": 0.1018,
      "step": 1900
    },
    {
      "epoch": 0.7595121594975535,
      "grad_norm": 0.8444734811782837,
      "learning_rate": 4.37249076601895e-05,
      "loss": 0.0857,
      "step": 1950
    },
    {
      "epoch": 0.778986830253901,
      "grad_norm": 2.2724545001983643,
      "learning_rate": 4.352416894170548e-05,
      "loss": 0.0815,
      "step": 2000
    },
    {
      "epoch": 0.7984615010102486,
      "grad_norm": 0.9710624814033508,
      "learning_rate": 4.3323430223221454e-05,
      "loss": 0.0925,
      "step": 2050
    },
    {
      "epoch": 0.817936171766596,
      "grad_norm": 3.127761125564575,
      "learning_rate": 4.3122691504737435e-05,
      "loss": 0.0853,
      "step": 2100
    },
    {
      "epoch": 0.8374108425229436,
      "grad_norm": 1.6220273971557617,
      "learning_rate": 4.2921952786253416e-05,
      "loss": 0.0958,
      "step": 2150
    },
    {
      "epoch": 0.8568855132792911,
      "grad_norm": 1.2299429178237915,
      "learning_rate": 4.27212140677694e-05,
      "loss": 0.0776,
      "step": 2200
    },
    {
      "epoch": 0.8763601840356386,
      "grad_norm": 0.5453816056251526,
      "learning_rate": 4.252047534928537e-05,
      "loss": 0.0917,
      "step": 2250
    },
    {
      "epoch": 0.8958348547919862,
      "grad_norm": 0.5183418989181519,
      "learning_rate": 4.2319736630801346e-05,
      "loss": 0.0947,
      "step": 2300
    },
    {
      "epoch": 0.9153095255483337,
      "grad_norm": 0.9797115921974182,
      "learning_rate": 4.2118997912317334e-05,
      "loss": 0.1015,
      "step": 2350
    },
    {
      "epoch": 0.9347841963046812,
      "grad_norm": 0.6935784816741943,
      "learning_rate": 4.191825919383331e-05,
      "loss": 0.0917,
      "step": 2400
    },
    {
      "epoch": 0.9542588670610288,
      "grad_norm": 0.6485304236412048,
      "learning_rate": 4.171752047534929e-05,
      "loss": 0.0866,
      "step": 2450
    },
    {
      "epoch": 0.9737335378173763,
      "grad_norm": 1.0669267177581787,
      "learning_rate": 4.1516781756865263e-05,
      "loss": 0.0803,
      "step": 2500
    },
    {
      "epoch": 0.9932082085737238,
      "grad_norm": 0.6269816160202026,
      "learning_rate": 4.1316043038381245e-05,
      "loss": 0.0869,
      "step": 2550
    },
    {
      "epoch": 1.000778986830254,
      "eval_loss": 0.08723858743906021,
      "eval_runtime": 2019.4659,
      "eval_samples_per_second": 4.351,
      "eval_steps_per_second": 4.351,
      "step": 2570
    },
    {
      "epoch": 1.0124637892840624,
      "grad_norm": 1.133891224861145,
      "learning_rate": 4.1115304319897226e-05,
      "loss": 0.0914,
      "step": 2600
    },
    {
      "epoch": 1.03193846004041,
      "grad_norm": 2.529383897781372,
      "learning_rate": 4.09145656014132e-05,
      "loss": 0.0793,
      "step": 2650
    },
    {
      "epoch": 1.0514131307967576,
      "grad_norm": 0.2053399384021759,
      "learning_rate": 4.071382688292918e-05,
      "loss": 0.0763,
      "step": 2700
    },
    {
      "epoch": 1.070887801553105,
      "grad_norm": 1.020317792892456,
      "learning_rate": 4.051308816444516e-05,
      "loss": 0.0705,
      "step": 2750
    },
    {
      "epoch": 1.0903624723094525,
      "grad_norm": 0.4260736107826233,
      "learning_rate": 4.031234944596114e-05,
      "loss": 0.0827,
      "step": 2800
    },
    {
      "epoch": 1.1098371430658,
      "grad_norm": 0.7442433834075928,
      "learning_rate": 4.011161072747712e-05,
      "loss": 0.0838,
      "step": 2850
    },
    {
      "epoch": 1.1293118138221476,
      "grad_norm": 1.5380264520645142,
      "learning_rate": 3.991087200899309e-05,
      "loss": 0.088,
      "step": 2900
    },
    {
      "epoch": 1.148786484578495,
      "grad_norm": 0.4754176139831543,
      "learning_rate": 3.971013329050908e-05,
      "loss": 0.0843,
      "step": 2950
    },
    {
      "epoch": 1.1682611553348425,
      "grad_norm": 0.19053319096565247,
      "learning_rate": 3.9509394572025054e-05,
      "loss": 0.0726,
      "step": 3000
    },
    {
      "epoch": 1.18773582609119,
      "grad_norm": 0.6779389381408691,
      "learning_rate": 3.930865585354103e-05,
      "loss": 0.0863,
      "step": 3050
    },
    {
      "epoch": 1.2072104968475377,
      "grad_norm": 1.8041186332702637,
      "learning_rate": 3.910791713505701e-05,
      "loss": 0.0799,
      "step": 3100
    },
    {
      "epoch": 1.2266851676038852,
      "grad_norm": 0.8090332746505737,
      "learning_rate": 3.890717841657299e-05,
      "loss": 0.0728,
      "step": 3150
    },
    {
      "epoch": 1.2461598383602328,
      "grad_norm": 0.9021999835968018,
      "learning_rate": 3.870643969808897e-05,
      "loss": 0.0884,
      "step": 3200
    },
    {
      "epoch": 1.2656345091165804,
      "grad_norm": 0.6653307676315308,
      "learning_rate": 3.8505700979604947e-05,
      "loss": 0.0776,
      "step": 3250
    },
    {
      "epoch": 1.2851091798729277,
      "grad_norm": 0.6856317520141602,
      "learning_rate": 3.830496226112093e-05,
      "loss": 0.0909,
      "step": 3300
    },
    {
      "epoch": 1.3045838506292753,
      "grad_norm": 0.7508180737495422,
      "learning_rate": 3.810422354263691e-05,
      "loss": 0.0657,
      "step": 3350
    },
    {
      "epoch": 1.3240585213856229,
      "grad_norm": 0.6884450912475586,
      "learning_rate": 3.790348482415288e-05,
      "loss": 0.0796,
      "step": 3400
    },
    {
      "epoch": 1.3435331921419704,
      "grad_norm": 0.6676681637763977,
      "learning_rate": 3.7702746105668864e-05,
      "loss": 0.0742,
      "step": 3450
    },
    {
      "epoch": 1.3630078628983178,
      "grad_norm": 0.442012757062912,
      "learning_rate": 3.750200738718484e-05,
      "loss": 0.0695,
      "step": 3500
    },
    {
      "epoch": 1.3824825336546653,
      "grad_norm": 1.2243999242782593,
      "learning_rate": 3.730126866870082e-05,
      "loss": 0.0814,
      "step": 3550
    },
    {
      "epoch": 1.401957204411013,
      "grad_norm": 1.0853660106658936,
      "learning_rate": 3.71005299502168e-05,
      "loss": 0.0788,
      "step": 3600
    },
    {
      "epoch": 1.4214318751673605,
      "grad_norm": 0.5980709791183472,
      "learning_rate": 3.6899791231732775e-05,
      "loss": 0.0768,
      "step": 3650
    },
    {
      "epoch": 1.440906545923708,
      "grad_norm": 0.8297127485275269,
      "learning_rate": 3.6699052513248757e-05,
      "loss": 0.088,
      "step": 3700
    },
    {
      "epoch": 1.4603812166800556,
      "grad_norm": 0.9789328575134277,
      "learning_rate": 3.649831379476474e-05,
      "loss": 0.0801,
      "step": 3750
    },
    {
      "epoch": 1.479855887436403,
      "grad_norm": 0.44734472036361694,
      "learning_rate": 3.629757507628072e-05,
      "loss": 0.0882,
      "step": 3800
    },
    {
      "epoch": 1.4993305581927505,
      "grad_norm": 2.5796074867248535,
      "learning_rate": 3.609683635779669e-05,
      "loss": 0.0753,
      "step": 3850
    },
    {
      "epoch": 1.518805228949098,
      "grad_norm": 0.3246218264102936,
      "learning_rate": 3.589609763931267e-05,
      "loss": 0.0722,
      "step": 3900
    },
    {
      "epoch": 1.5382798997054457,
      "grad_norm": 0.3470999002456665,
      "learning_rate": 3.5695358920828655e-05,
      "loss": 0.0946,
      "step": 3950
    },
    {
      "epoch": 1.557754570461793,
      "grad_norm": 0.4152591824531555,
      "learning_rate": 3.549462020234463e-05,
      "loss": 0.0689,
      "step": 4000
    },
    {
      "epoch": 1.5772292412181406,
      "grad_norm": 1.6761703491210938,
      "learning_rate": 3.529388148386061e-05,
      "loss": 0.0855,
      "step": 4050
    },
    {
      "epoch": 1.5967039119744881,
      "grad_norm": 0.2937428653240204,
      "learning_rate": 3.5093142765376585e-05,
      "loss": 0.0874,
      "step": 4100
    },
    {
      "epoch": 1.6161785827308357,
      "grad_norm": 1.742002010345459,
      "learning_rate": 3.4892404046892566e-05,
      "loss": 0.0705,
      "step": 4150
    },
    {
      "epoch": 1.6356532534871833,
      "grad_norm": 0.30842268466949463,
      "learning_rate": 3.469166532840855e-05,
      "loss": 0.093,
      "step": 4200
    },
    {
      "epoch": 1.6551279242435308,
      "grad_norm": 0.3749549686908722,
      "learning_rate": 3.449092660992452e-05,
      "loss": 0.0853,
      "step": 4250
    },
    {
      "epoch": 1.6746025949998784,
      "grad_norm": 1.0977647304534912,
      "learning_rate": 3.42901878914405e-05,
      "loss": 0.0755,
      "step": 4300
    },
    {
      "epoch": 1.694077265756226,
      "grad_norm": 1.4811633825302124,
      "learning_rate": 3.4089449172956484e-05,
      "loss": 0.0852,
      "step": 4350
    },
    {
      "epoch": 1.7135519365125733,
      "grad_norm": 1.2811256647109985,
      "learning_rate": 3.388871045447246e-05,
      "loss": 0.0839,
      "step": 4400
    },
    {
      "epoch": 1.7330266072689209,
      "grad_norm": 0.5837087035179138,
      "learning_rate": 3.368797173598844e-05,
      "loss": 0.0797,
      "step": 4450
    },
    {
      "epoch": 1.7525012780252682,
      "grad_norm": 0.6788424253463745,
      "learning_rate": 3.3487233017504414e-05,
      "loss": 0.0727,
      "step": 4500
    },
    {
      "epoch": 1.7719759487816158,
      "grad_norm": 1.1200990676879883,
      "learning_rate": 3.32864942990204e-05,
      "loss": 0.0852,
      "step": 4550
    },
    {
      "epoch": 1.7914506195379634,
      "grad_norm": 0.2120555341243744,
      "learning_rate": 3.3085755580536376e-05,
      "loss": 0.0901,
      "step": 4600
    },
    {
      "epoch": 1.810925290294311,
      "grad_norm": 0.327854722738266,
      "learning_rate": 3.288501686205235e-05,
      "loss": 0.0745,
      "step": 4650
    },
    {
      "epoch": 1.8303999610506585,
      "grad_norm": 0.7954887747764587,
      "learning_rate": 3.268427814356833e-05,
      "loss": 0.0848,
      "step": 4700
    },
    {
      "epoch": 1.849874631807006,
      "grad_norm": 1.1503158807754517,
      "learning_rate": 3.248353942508431e-05,
      "loss": 0.0816,
      "step": 4750
    },
    {
      "epoch": 1.8693493025633536,
      "grad_norm": 3.737298011779785,
      "learning_rate": 3.2282800706600294e-05,
      "loss": 0.0826,
      "step": 4800
    },
    {
      "epoch": 1.8888239733197012,
      "grad_norm": 0.33175522089004517,
      "learning_rate": 3.208206198811627e-05,
      "loss": 0.0839,
      "step": 4850
    },
    {
      "epoch": 1.9082986440760485,
      "grad_norm": 1.508979320526123,
      "learning_rate": 3.188132326963224e-05,
      "loss": 0.0752,
      "step": 4900
    },
    {
      "epoch": 1.9277733148323961,
      "grad_norm": 1.0748512744903564,
      "learning_rate": 3.168058455114823e-05,
      "loss": 0.0995,
      "step": 4950
    },
    {
      "epoch": 1.9472479855887437,
      "grad_norm": 0.6768724918365479,
      "learning_rate": 3.1479845832664205e-05,
      "loss": 0.0735,
      "step": 5000
    },
    {
      "epoch": 1.966722656345091,
      "grad_norm": 0.3881910443305969,
      "learning_rate": 3.1279107114180186e-05,
      "loss": 0.0846,
      "step": 5050
    },
    {
      "epoch": 1.9861973271014386,
      "grad_norm": 1.8929243087768555,
      "learning_rate": 3.107836839569616e-05,
      "loss": 0.0843,
      "step": 5100
    },
    {
      "epoch": 2.001557973660508,
      "eval_loss": 0.08049318939447403,
      "eval_runtime": 1922.9241,
      "eval_samples_per_second": 4.569,
      "eval_steps_per_second": 4.569,
      "step": 5140
    },
    {
      "epoch": 2.0054529078117773,
      "grad_norm": 0.37951722741127014,
      "learning_rate": 3.087762967721214e-05,
      "loss": 0.0758,
      "step": 5150
    },
    {
      "epoch": 2.024927578568125,
      "grad_norm": 1.266481876373291,
      "learning_rate": 3.067689095872812e-05,
      "loss": 0.0673,
      "step": 5200
    },
    {
      "epoch": 2.0444022493244725,
      "grad_norm": 0.6115933656692505,
      "learning_rate": 3.04761522402441e-05,
      "loss": 0.0762,
      "step": 5250
    },
    {
      "epoch": 2.06387692008082,
      "grad_norm": 0.18234838545322418,
      "learning_rate": 3.0275413521760075e-05,
      "loss": 0.0818,
      "step": 5300
    },
    {
      "epoch": 2.0833515908371676,
      "grad_norm": 0.6721600890159607,
      "learning_rate": 3.007467480327606e-05,
      "loss": 0.073,
      "step": 5350
    },
    {
      "epoch": 2.102826261593515,
      "grad_norm": 2.195401430130005,
      "learning_rate": 2.9873936084792037e-05,
      "loss": 0.0787,
      "step": 5400
    },
    {
      "epoch": 2.1223009323498623,
      "grad_norm": 1.8093966245651245,
      "learning_rate": 2.9673197366308015e-05,
      "loss": 0.0813,
      "step": 5450
    },
    {
      "epoch": 2.14177560310621,
      "grad_norm": 0.5653008222579956,
      "learning_rate": 2.9472458647823993e-05,
      "loss": 0.085,
      "step": 5500
    },
    {
      "epoch": 2.1612502738625574,
      "grad_norm": 0.654668390750885,
      "learning_rate": 2.9271719929339974e-05,
      "loss": 0.0717,
      "step": 5550
    },
    {
      "epoch": 2.180724944618905,
      "grad_norm": 0.6850634813308716,
      "learning_rate": 2.907098121085595e-05,
      "loss": 0.0662,
      "step": 5600
    },
    {
      "epoch": 2.2001996153752525,
      "grad_norm": 0.8737797737121582,
      "learning_rate": 2.887024249237193e-05,
      "loss": 0.0653,
      "step": 5650
    },
    {
      "epoch": 2.2196742861316,
      "grad_norm": 1.9062203168869019,
      "learning_rate": 2.8669503773887907e-05,
      "loss": 0.0645,
      "step": 5700
    },
    {
      "epoch": 2.2391489568879477,
      "grad_norm": 1.2866973876953125,
      "learning_rate": 2.8468765055403888e-05,
      "loss": 0.0687,
      "step": 5750
    },
    {
      "epoch": 2.2586236276442953,
      "grad_norm": 0.7768397927284241,
      "learning_rate": 2.8268026336919866e-05,
      "loss": 0.0747,
      "step": 5800
    },
    {
      "epoch": 2.278098298400643,
      "grad_norm": 0.42886605858802795,
      "learning_rate": 2.8067287618435844e-05,
      "loss": 0.0699,
      "step": 5850
    },
    {
      "epoch": 2.29757296915699,
      "grad_norm": 0.39341261982917786,
      "learning_rate": 2.786654889995182e-05,
      "loss": 0.0638,
      "step": 5900
    },
    {
      "epoch": 2.317047639913338,
      "grad_norm": 0.9734807014465332,
      "learning_rate": 2.7665810181467806e-05,
      "loss": 0.0764,
      "step": 5950
    },
    {
      "epoch": 2.336522310669685,
      "grad_norm": 2.782169818878174,
      "learning_rate": 2.7465071462983784e-05,
      "loss": 0.0679,
      "step": 6000
    },
    {
      "epoch": 2.3559969814260326,
      "grad_norm": 1.1434515714645386,
      "learning_rate": 2.726433274449976e-05,
      "loss": 0.0767,
      "step": 6050
    },
    {
      "epoch": 2.37547165218238,
      "grad_norm": 0.6737245321273804,
      "learning_rate": 2.7063594026015736e-05,
      "loss": 0.0649,
      "step": 6100
    },
    {
      "epoch": 2.394946322938728,
      "grad_norm": 0.76911461353302,
      "learning_rate": 2.686285530753172e-05,
      "loss": 0.0706,
      "step": 6150
    },
    {
      "epoch": 2.4144209936950753,
      "grad_norm": 0.649750292301178,
      "learning_rate": 2.6662116589047698e-05,
      "loss": 0.0748,
      "step": 6200
    },
    {
      "epoch": 2.433895664451423,
      "grad_norm": 1.132710576057434,
      "learning_rate": 2.6461377870563676e-05,
      "loss": 0.0757,
      "step": 6250
    },
    {
      "epoch": 2.4533703352077705,
      "grad_norm": 0.9789937138557434,
      "learning_rate": 2.6260639152079654e-05,
      "loss": 0.0763,
      "step": 6300
    },
    {
      "epoch": 2.472845005964118,
      "grad_norm": 1.2011152505874634,
      "learning_rate": 2.6059900433595635e-05,
      "loss": 0.0693,
      "step": 6350
    },
    {
      "epoch": 2.4923196767204656,
      "grad_norm": 0.6792304515838623,
      "learning_rate": 2.5859161715111613e-05,
      "loss": 0.0677,
      "step": 6400
    },
    {
      "epoch": 2.5117943474768127,
      "grad_norm": 1.5217628479003906,
      "learning_rate": 2.565842299662759e-05,
      "loss": 0.0855,
      "step": 6450
    },
    {
      "epoch": 2.5312690182331608,
      "grad_norm": 0.9752156138420105,
      "learning_rate": 2.5457684278143568e-05,
      "loss": 0.0736,
      "step": 6500
    },
    {
      "epoch": 2.550743688989508,
      "grad_norm": 0.9746353626251221,
      "learning_rate": 2.525694555965955e-05,
      "loss": 0.0703,
      "step": 6550
    },
    {
      "epoch": 2.5702183597458554,
      "grad_norm": 1.0685961246490479,
      "learning_rate": 2.5056206841175527e-05,
      "loss": 0.0656,
      "step": 6600
    },
    {
      "epoch": 2.589693030502203,
      "grad_norm": 0.683659553527832,
      "learning_rate": 2.4855468122691505e-05,
      "loss": 0.0806,
      "step": 6650
    },
    {
      "epoch": 2.6091677012585506,
      "grad_norm": 0.7976388931274414,
      "learning_rate": 2.4654729404207486e-05,
      "loss": 0.0598,
      "step": 6700
    },
    {
      "epoch": 2.628642372014898,
      "grad_norm": 0.16490519046783447,
      "learning_rate": 2.4453990685723464e-05,
      "loss": 0.0774,
      "step": 6750
    },
    {
      "epoch": 2.6481170427712457,
      "grad_norm": 2.247441291809082,
      "learning_rate": 2.4253251967239445e-05,
      "loss": 0.0705,
      "step": 6800
    },
    {
      "epoch": 2.6675917135275933,
      "grad_norm": 0.8353046178817749,
      "learning_rate": 2.405251324875542e-05,
      "loss": 0.0725,
      "step": 6850
    },
    {
      "epoch": 2.687066384283941,
      "grad_norm": 0.3906151056289673,
      "learning_rate": 2.38517745302714e-05,
      "loss": 0.0666,
      "step": 6900
    },
    {
      "epoch": 2.7065410550402884,
      "grad_norm": 0.5618936419487,
      "learning_rate": 2.3651035811787378e-05,
      "loss": 0.0723,
      "step": 6950
    },
    {
      "epoch": 2.7260157257966355,
      "grad_norm": 1.5971934795379639,
      "learning_rate": 2.345029709330336e-05,
      "loss": 0.0692,
      "step": 7000
    },
    {
      "epoch": 2.7454903965529835,
      "grad_norm": 2.1623284816741943,
      "learning_rate": 2.3249558374819337e-05,
      "loss": 0.0899,
      "step": 7050
    },
    {
      "epoch": 2.7649650673093307,
      "grad_norm": 2.7822725772857666,
      "learning_rate": 2.3048819656335315e-05,
      "loss": 0.055,
      "step": 7100
    },
    {
      "epoch": 2.7844397380656782,
      "grad_norm": 1.0677257776260376,
      "learning_rate": 2.2848080937851292e-05,
      "loss": 0.0718,
      "step": 7150
    },
    {
      "epoch": 2.803914408822026,
      "grad_norm": 2.2943084239959717,
      "learning_rate": 2.2647342219367273e-05,
      "loss": 0.0613,
      "step": 7200
    },
    {
      "epoch": 2.8233890795783734,
      "grad_norm": 1.4092962741851807,
      "learning_rate": 2.244660350088325e-05,
      "loss": 0.0778,
      "step": 7250
    },
    {
      "epoch": 2.842863750334721,
      "grad_norm": 0.1870727688074112,
      "learning_rate": 2.2245864782399232e-05,
      "loss": 0.0732,
      "step": 7300
    },
    {
      "epoch": 2.8623384210910685,
      "grad_norm": 2.425405502319336,
      "learning_rate": 2.204512606391521e-05,
      "loss": 0.0795,
      "step": 7350
    },
    {
      "epoch": 2.881813091847416,
      "grad_norm": 1.6372150182724,
      "learning_rate": 2.1844387345431188e-05,
      "loss": 0.0724,
      "step": 7400
    },
    {
      "epoch": 2.9012877626037636,
      "grad_norm": 1.244913935661316,
      "learning_rate": 2.1643648626947166e-05,
      "loss": 0.0699,
      "step": 7450
    },
    {
      "epoch": 2.920762433360111,
      "grad_norm": 0.5185152888298035,
      "learning_rate": 2.1442909908463147e-05,
      "loss": 0.0739,
      "step": 7500
    },
    {
      "epoch": 2.9402371041164583,
      "grad_norm": 0.7067573666572571,
      "learning_rate": 2.1242171189979124e-05,
      "loss": 0.0691,
      "step": 7550
    },
    {
      "epoch": 2.959711774872806,
      "grad_norm": 0.9058798551559448,
      "learning_rate": 2.1041432471495106e-05,
      "loss": 0.0602,
      "step": 7600
    },
    {
      "epoch": 2.9791864456291535,
      "grad_norm": 2.245223045349121,
      "learning_rate": 2.084069375301108e-05,
      "loss": 0.0647,
      "step": 7650
    },
    {
      "epoch": 2.998661116385501,
      "grad_norm": 0.436065137386322,
      "learning_rate": 2.063995503452706e-05,
      "loss": 0.0762,
      "step": 7700
    },
    {
      "epoch": 3.0023369604907617,
      "eval_loss": 0.07932399958372116,
      "eval_runtime": 1924.013,
      "eval_samples_per_second": 4.566,
      "eval_steps_per_second": 4.566,
      "step": 7710
    },
    {
      "epoch": 3.0179166970958398,
      "grad_norm": 0.9210475087165833,
      "learning_rate": 2.043921631604304e-05,
      "loss": 0.0687,
      "step": 7750
    },
    {
      "epoch": 3.0373913678521873,
      "grad_norm": 1.369194507598877,
      "learning_rate": 2.023847759755902e-05,
      "loss": 0.0604,
      "step": 7800
    },
    {
      "epoch": 3.056866038608535,
      "grad_norm": 0.23503068089485168,
      "learning_rate": 2.0037738879074998e-05,
      "loss": 0.0603,
      "step": 7850
    },
    {
      "epoch": 3.0763407093648825,
      "grad_norm": 1.7587577104568481,
      "learning_rate": 1.9837000160590975e-05,
      "loss": 0.0625,
      "step": 7900
    },
    {
      "epoch": 3.09581538012123,
      "grad_norm": 1.1643247604370117,
      "learning_rate": 1.9636261442106953e-05,
      "loss": 0.0577,
      "step": 7950
    },
    {
      "epoch": 3.115290050877577,
      "grad_norm": 1.1020978689193726,
      "learning_rate": 1.9435522723622934e-05,
      "loss": 0.0732,
      "step": 8000
    },
    {
      "epoch": 3.1347647216339247,
      "grad_norm": 0.4856720566749573,
      "learning_rate": 1.9234784005138912e-05,
      "loss": 0.0604,
      "step": 8050
    },
    {
      "epoch": 3.1542393923902723,
      "grad_norm": 2.4464707374572754,
      "learning_rate": 1.9034045286654893e-05,
      "loss": 0.078,
      "step": 8100
    },
    {
      "epoch": 3.17371406314662,
      "grad_norm": 1.033069372177124,
      "learning_rate": 1.8833306568170868e-05,
      "loss": 0.0597,
      "step": 8150
    },
    {
      "epoch": 3.1931887339029674,
      "grad_norm": 1.2751474380493164,
      "learning_rate": 1.863256784968685e-05,
      "loss": 0.0678,
      "step": 8200
    },
    {
      "epoch": 3.212663404659315,
      "grad_norm": 2.1464297771453857,
      "learning_rate": 1.8431829131202826e-05,
      "loss": 0.0619,
      "step": 8250
    },
    {
      "epoch": 3.2321380754156626,
      "grad_norm": 0.7006711959838867,
      "learning_rate": 1.8231090412718808e-05,
      "loss": 0.0753,
      "step": 8300
    },
    {
      "epoch": 3.25161274617201,
      "grad_norm": 2.704240322113037,
      "learning_rate": 1.8030351694234785e-05,
      "loss": 0.0653,
      "step": 8350
    },
    {
      "epoch": 3.2710874169283577,
      "grad_norm": 2.0529298782348633,
      "learning_rate": 1.7829612975750763e-05,
      "loss": 0.0599,
      "step": 8400
    },
    {
      "epoch": 3.2905620876847053,
      "grad_norm": 0.7824965715408325,
      "learning_rate": 1.762887425726674e-05,
      "loss": 0.0585,
      "step": 8450
    },
    {
      "epoch": 3.3100367584410524,
      "grad_norm": 0.9085853695869446,
      "learning_rate": 1.7428135538782722e-05,
      "loss": 0.0597,
      "step": 8500
    },
    {
      "epoch": 3.3295114291974,
      "grad_norm": 1.9036874771118164,
      "learning_rate": 1.72273968202987e-05,
      "loss": 0.0726,
      "step": 8550
    },
    {
      "epoch": 3.3489860999537475,
      "grad_norm": 0.5535111427307129,
      "learning_rate": 1.702665810181468e-05,
      "loss": 0.066,
      "step": 8600
    },
    {
      "epoch": 3.368460770710095,
      "grad_norm": 1.1052730083465576,
      "learning_rate": 1.682591938333066e-05,
      "loss": 0.0616,
      "step": 8650
    },
    {
      "epoch": 3.3879354414664427,
      "grad_norm": 0.14949871599674225,
      "learning_rate": 1.6625180664846636e-05,
      "loss": 0.0627,
      "step": 8700
    },
    {
      "epoch": 3.40741011222279,
      "grad_norm": 1.5739502906799316,
      "learning_rate": 1.6424441946362614e-05,
      "loss": 0.0513,
      "step": 8750
    },
    {
      "epoch": 3.426884782979138,
      "grad_norm": 0.9218549728393555,
      "learning_rate": 1.6223703227878595e-05,
      "loss": 0.0551,
      "step": 8800
    },
    {
      "epoch": 3.4463594537354854,
      "grad_norm": 1.3149793148040771,
      "learning_rate": 1.6022964509394573e-05,
      "loss": 0.0755,
      "step": 8850
    },
    {
      "epoch": 3.465834124491833,
      "grad_norm": 0.45739904046058655,
      "learning_rate": 1.5822225790910554e-05,
      "loss": 0.0674,
      "step": 8900
    },
    {
      "epoch": 3.4853087952481805,
      "grad_norm": 3.1985950469970703,
      "learning_rate": 1.562148707242653e-05,
      "loss": 0.0692,
      "step": 8950
    },
    {
      "epoch": 3.504783466004528,
      "grad_norm": 3.0219337940216064,
      "learning_rate": 1.542074835394251e-05,
      "loss": 0.0583,
      "step": 9000
    },
    {
      "epoch": 3.524258136760875,
      "grad_norm": 1.799170970916748,
      "learning_rate": 1.5220009635458487e-05,
      "loss": 0.0621,
      "step": 9050
    },
    {
      "epoch": 3.5437328075172227,
      "grad_norm": 0.7198128700256348,
      "learning_rate": 1.5019270916974469e-05,
      "loss": 0.0664,
      "step": 9100
    },
    {
      "epoch": 3.5632074782735703,
      "grad_norm": 0.5522721409797668,
      "learning_rate": 1.4818532198490445e-05,
      "loss": 0.0665,
      "step": 9150
    },
    {
      "epoch": 3.582682149029918,
      "grad_norm": 0.8569539785385132,
      "learning_rate": 1.4617793480006426e-05,
      "loss": 0.0631,
      "step": 9200
    },
    {
      "epoch": 3.6021568197862655,
      "grad_norm": 1.2913566827774048,
      "learning_rate": 1.4417054761522403e-05,
      "loss": 0.0609,
      "step": 9250
    },
    {
      "epoch": 3.621631490542613,
      "grad_norm": 0.5229593515396118,
      "learning_rate": 1.4216316043038383e-05,
      "loss": 0.0778,
      "step": 9300
    },
    {
      "epoch": 3.6411061612989606,
      "grad_norm": 0.5900986194610596,
      "learning_rate": 1.401557732455436e-05,
      "loss": 0.0614,
      "step": 9350
    },
    {
      "epoch": 3.660580832055308,
      "grad_norm": 0.26634809374809265,
      "learning_rate": 1.381483860607034e-05,
      "loss": 0.0607,
      "step": 9400
    },
    {
      "epoch": 3.6800555028116557,
      "grad_norm": 1.0957669019699097,
      "learning_rate": 1.3614099887586318e-05,
      "loss": 0.0693,
      "step": 9450
    },
    {
      "epoch": 3.699530173568003,
      "grad_norm": 1.0748209953308105,
      "learning_rate": 1.3413361169102299e-05,
      "loss": 0.057,
      "step": 9500
    },
    {
      "epoch": 3.719004844324351,
      "grad_norm": 0.6272428631782532,
      "learning_rate": 1.3212622450618275e-05,
      "loss": 0.0686,
      "step": 9550
    },
    {
      "epoch": 3.738479515080698,
      "grad_norm": 0.8502069711685181,
      "learning_rate": 1.3011883732134256e-05,
      "loss": 0.0738,
      "step": 9600
    },
    {
      "epoch": 3.7579541858370455,
      "grad_norm": 3.6690289974212646,
      "learning_rate": 1.2811145013650234e-05,
      "loss": 0.0723,
      "step": 9650
    },
    {
      "epoch": 3.777428856593393,
      "grad_norm": 0.6449735164642334,
      "learning_rate": 1.2610406295166213e-05,
      "loss": 0.0719,
      "step": 9700
    },
    {
      "epoch": 3.7969035273497407,
      "grad_norm": 0.8122988939285278,
      "learning_rate": 1.2409667576682191e-05,
      "loss": 0.0611,
      "step": 9750
    },
    {
      "epoch": 3.8163781981060882,
      "grad_norm": 0.6326124668121338,
      "learning_rate": 1.2208928858198169e-05,
      "loss": 0.0769,
      "step": 9800
    },
    {
      "epoch": 3.835852868862436,
      "grad_norm": 0.5390480160713196,
      "learning_rate": 1.2008190139714148e-05,
      "loss": 0.0596,
      "step": 9850
    },
    {
      "epoch": 3.8553275396187834,
      "grad_norm": 1.1412957906723022,
      "learning_rate": 1.1807451421230128e-05,
      "loss": 0.0645,
      "step": 9900
    },
    {
      "epoch": 3.874802210375131,
      "grad_norm": 1.2442283630371094,
      "learning_rate": 1.1606712702746105e-05,
      "loss": 0.068,
      "step": 9950
    },
    {
      "epoch": 3.8942768811314785,
      "grad_norm": 0.6811057925224304,
      "learning_rate": 1.1405973984262085e-05,
      "loss": 0.0558,
      "step": 10000
    },
    {
      "epoch": 3.9137515518878256,
      "grad_norm": 0.14894594252109528,
      "learning_rate": 1.1205235265778063e-05,
      "loss": 0.0593,
      "step": 10050
    },
    {
      "epoch": 3.9332262226441737,
      "grad_norm": 2.967617988586426,
      "learning_rate": 1.1004496547294042e-05,
      "loss": 0.0556,
      "step": 10100
    },
    {
      "epoch": 3.9527008934005208,
      "grad_norm": 0.636897087097168,
      "learning_rate": 1.0803757828810022e-05,
      "loss": 0.067,
      "step": 10150
    },
    {
      "epoch": 3.9721755641568683,
      "grad_norm": 0.5751776695251465,
      "learning_rate": 1.0603019110326e-05,
      "loss": 0.0733,
      "step": 10200
    },
    {
      "epoch": 3.991650234913216,
      "grad_norm": 0.9590122103691101,
      "learning_rate": 1.0402280391841979e-05,
      "loss": 0.0757,
      "step": 10250
    },
    {
      "epoch": 4.003115947321016,
      "eval_loss": 0.08097672462463379,
      "eval_runtime": 1923.2851,
      "eval_samples_per_second": 4.568,
      "eval_steps_per_second": 4.568,
      "step": 10280
    },
    {
      "epoch": 4.010905815623555,
      "grad_norm": 1.3406717777252197,
      "learning_rate": 1.0201541673357958e-05,
      "loss": 0.0684,
      "step": 10300
    },
    {
      "epoch": 4.030380486379902,
      "grad_norm": 1.5897672176361084,
      "learning_rate": 1.0000802954873936e-05,
      "loss": 0.0513,
      "step": 10350
    },
    {
      "epoch": 4.04985515713625,
      "grad_norm": 0.892322301864624,
      "learning_rate": 9.800064236389915e-06,
      "loss": 0.0583,
      "step": 10400
    },
    {
      "epoch": 4.069329827892597,
      "grad_norm": 0.9451673626899719,
      "learning_rate": 9.599325517905893e-06,
      "loss": 0.0706,
      "step": 10450
    },
    {
      "epoch": 4.088804498648945,
      "grad_norm": 0.8324442505836487,
      "learning_rate": 9.398586799421873e-06,
      "loss": 0.0557,
      "step": 10500
    },
    {
      "epoch": 4.108279169405292,
      "grad_norm": 2.6826863288879395,
      "learning_rate": 9.197848080937852e-06,
      "loss": 0.058,
      "step": 10550
    },
    {
      "epoch": 4.12775384016164,
      "grad_norm": 0.6278085112571716,
      "learning_rate": 8.99710936245383e-06,
      "loss": 0.0601,
      "step": 10600
    },
    {
      "epoch": 4.147228510917987,
      "grad_norm": 1.184908151626587,
      "learning_rate": 8.79637064396981e-06,
      "loss": 0.0641,
      "step": 10650
    },
    {
      "epoch": 4.166703181674335,
      "grad_norm": 1.4436358213424683,
      "learning_rate": 8.595631925485789e-06,
      "loss": 0.0689,
      "step": 10700
    },
    {
      "epoch": 4.186177852430682,
      "grad_norm": 2.753650665283203,
      "learning_rate": 8.394893207001766e-06,
      "loss": 0.0564,
      "step": 10750
    },
    {
      "epoch": 4.20565252318703,
      "grad_norm": 1.243371605873108,
      "learning_rate": 8.194154488517746e-06,
      "loss": 0.0586,
      "step": 10800
    },
    {
      "epoch": 4.225127193943377,
      "grad_norm": 2.3658010959625244,
      "learning_rate": 7.993415770033724e-06,
      "loss": 0.0467,
      "step": 10850
    },
    {
      "epoch": 4.244601864699725,
      "grad_norm": 2.3002991676330566,
      "learning_rate": 7.792677051549703e-06,
      "loss": 0.0531,
      "step": 10900
    },
    {
      "epoch": 4.264076535456073,
      "grad_norm": 1.0079865455627441,
      "learning_rate": 7.591938333065682e-06,
      "loss": 0.0597,
      "step": 10950
    },
    {
      "epoch": 4.28355120621242,
      "grad_norm": 4.444775581359863,
      "learning_rate": 7.39119961458166e-06,
      "loss": 0.0615,
      "step": 11000
    },
    {
      "epoch": 4.303025876968768,
      "grad_norm": 1.2776538133621216,
      "learning_rate": 7.19046089609764e-06,
      "loss": 0.0526,
      "step": 11050
    },
    {
      "epoch": 4.322500547725115,
      "grad_norm": 0.5796922445297241,
      "learning_rate": 6.989722177613618e-06,
      "loss": 0.0609,
      "step": 11100
    },
    {
      "epoch": 4.341975218481463,
      "grad_norm": 1.3023371696472168,
      "learning_rate": 6.788983459129597e-06,
      "loss": 0.0614,
      "step": 11150
    },
    {
      "epoch": 4.36144988923781,
      "grad_norm": 0.8447081446647644,
      "learning_rate": 6.5882447406455754e-06,
      "loss": 0.066,
      "step": 11200
    },
    {
      "epoch": 4.380924559994158,
      "grad_norm": 0.7996883392333984,
      "learning_rate": 6.387506022161555e-06,
      "loss": 0.054,
      "step": 11250
    },
    {
      "epoch": 4.400399230750505,
      "grad_norm": 1.4960861206054688,
      "learning_rate": 6.1867673036775335e-06,
      "loss": 0.0453,
      "step": 11300
    },
    {
      "epoch": 4.419873901506852,
      "grad_norm": 2.005622386932373,
      "learning_rate": 5.986028585193512e-06,
      "loss": 0.0547,
      "step": 11350
    },
    {
      "epoch": 4.4393485722632,
      "grad_norm": 1.6383010149002075,
      "learning_rate": 5.785289866709491e-06,
      "loss": 0.0617,
      "step": 11400
    },
    {
      "epoch": 4.458823243019547,
      "grad_norm": 0.29584747552871704,
      "learning_rate": 5.58455114822547e-06,
      "loss": 0.061,
      "step": 11450
    },
    {
      "epoch": 4.478297913775895,
      "grad_norm": 0.7636495232582092,
      "learning_rate": 5.383812429741449e-06,
      "loss": 0.0547,
      "step": 11500
    },
    {
      "epoch": 4.4977725845322425,
      "grad_norm": 1.4257756471633911,
      "learning_rate": 5.183073711257427e-06,
      "loss": 0.0528,
      "step": 11550
    },
    {
      "epoch": 4.5172472552885905,
      "grad_norm": 4.97982120513916,
      "learning_rate": 4.982334992773406e-06,
      "loss": 0.0566,
      "step": 11600
    },
    {
      "epoch": 4.536721926044938,
      "grad_norm": 4.365649223327637,
      "learning_rate": 4.781596274289385e-06,
      "loss": 0.0634,
      "step": 11650
    },
    {
      "epoch": 4.556196596801286,
      "grad_norm": 0.2925974130630493,
      "learning_rate": 4.580857555805364e-06,
      "loss": 0.0704,
      "step": 11700
    },
    {
      "epoch": 4.575671267557633,
      "grad_norm": 2.0554964542388916,
      "learning_rate": 4.3801188373213425e-06,
      "loss": 0.0619,
      "step": 11750
    },
    {
      "epoch": 4.59514593831398,
      "grad_norm": 2.3360776901245117,
      "learning_rate": 4.179380118837321e-06,
      "loss": 0.0656,
      "step": 11800
    },
    {
      "epoch": 4.614620609070328,
      "grad_norm": 0.596118152141571,
      "learning_rate": 3.9786414003533e-06,
      "loss": 0.0662,
      "step": 11850
    },
    {
      "epoch": 4.634095279826676,
      "grad_norm": 3.7271342277526855,
      "learning_rate": 3.7779026818692787e-06,
      "loss": 0.066,
      "step": 11900
    },
    {
      "epoch": 4.653569950583023,
      "grad_norm": 2.827242374420166,
      "learning_rate": 3.5771639633852578e-06,
      "loss": 0.0598,
      "step": 11950
    },
    {
      "epoch": 4.67304462133937,
      "grad_norm": 1.218589186668396,
      "learning_rate": 3.3764252449012364e-06,
      "loss": 0.0597,
      "step": 12000
    },
    {
      "epoch": 4.692519292095718,
      "grad_norm": 1.0595146417617798,
      "learning_rate": 3.1756865264172154e-06,
      "loss": 0.0553,
      "step": 12050
    },
    {
      "epoch": 4.711993962852065,
      "grad_norm": 1.09525728225708,
      "learning_rate": 2.9749478079331944e-06,
      "loss": 0.0501,
      "step": 12100
    },
    {
      "epoch": 4.731468633608413,
      "grad_norm": 1.6276094913482666,
      "learning_rate": 2.7742090894491734e-06,
      "loss": 0.0563,
      "step": 12150
    },
    {
      "epoch": 4.75094330436476,
      "grad_norm": 1.1772747039794922,
      "learning_rate": 2.573470370965152e-06,
      "loss": 0.0544,
      "step": 12200
    },
    {
      "epoch": 4.770417975121108,
      "grad_norm": 1.2498146295547485,
      "learning_rate": 2.372731652481131e-06,
      "loss": 0.0583,
      "step": 12250
    },
    {
      "epoch": 4.789892645877456,
      "grad_norm": 0.3437400162220001,
      "learning_rate": 2.1719929339971096e-06,
      "loss": 0.0588,
      "step": 12300
    },
    {
      "epoch": 4.809367316633804,
      "grad_norm": 0.40512868762016296,
      "learning_rate": 1.9712542155130882e-06,
      "loss": 0.0598,
      "step": 12350
    },
    {
      "epoch": 4.828841987390151,
      "grad_norm": 2.9345450401306152,
      "learning_rate": 1.7705154970290668e-06,
      "loss": 0.0523,
      "step": 12400
    },
    {
      "epoch": 4.848316658146498,
      "grad_norm": 3.7520699501037598,
      "learning_rate": 1.5697767785450456e-06,
      "loss": 0.0581,
      "step": 12450
    },
    {
      "epoch": 4.867791328902846,
      "grad_norm": 0.5678414106369019,
      "learning_rate": 1.3690380600610246e-06,
      "loss": 0.0571,
      "step": 12500
    },
    {
      "epoch": 4.887265999659193,
      "grad_norm": 5.592129230499268,
      "learning_rate": 1.1682993415770034e-06,
      "loss": 0.0609,
      "step": 12550
    },
    {
      "epoch": 4.906740670415541,
      "grad_norm": 0.9075773358345032,
      "learning_rate": 9.675606230929822e-07,
      "loss": 0.0536,
      "step": 12600
    },
    {
      "epoch": 4.926215341171888,
      "grad_norm": 0.8757668137550354,
      "learning_rate": 7.668219046089611e-07,
      "loss": 0.0512,
      "step": 12650
    },
    {
      "epoch": 4.945690011928236,
      "grad_norm": 0.6421528458595276,
      "learning_rate": 5.660831861249399e-07,
      "loss": 0.0526,
      "step": 12700
    },
    {
      "epoch": 4.965164682684583,
      "grad_norm": 1.0533632040023804,
      "learning_rate": 3.6534446764091856e-07,
      "loss": 0.0439,
      "step": 12750
    },
    {
      "epoch": 4.984639353440931,
      "grad_norm": 1.2793043851852417,
      "learning_rate": 1.646057491568974e-07,
      "loss": 0.0519,
      "step": 12800
    }
  ],
  "logging_steps": 50,
  "max_steps": 12840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 2570,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.440254844767756e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

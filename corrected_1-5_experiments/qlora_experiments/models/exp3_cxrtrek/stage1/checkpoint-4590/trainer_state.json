{
  "best_global_step": 3668,
  "best_metric": 0.08533525466918945,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/qlora_experiments/models/exp3_cxrtrek/stage1/checkpoint-3668",
  "epoch": 5.0,
  "eval_steps": 917,
  "global_step": 4590,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05449962531507596,
      "grad_norm": 2.1836071014404297,
      "learning_rate": 1.7753623188405798e-05,
      "loss": 1.2924,
      "step": 50
    },
    {
      "epoch": 0.10899925063015192,
      "grad_norm": 0.6809667348861694,
      "learning_rate": 3.58695652173913e-05,
      "loss": 0.4974,
      "step": 100
    },
    {
      "epoch": 0.16349887594522788,
      "grad_norm": 0.8725099563598633,
      "learning_rate": 4.987646001796946e-05,
      "loss": 0.1983,
      "step": 150
    },
    {
      "epoch": 0.21799850126030385,
      "grad_norm": 1.6612145900726318,
      "learning_rate": 4.9314914645103324e-05,
      "loss": 0.1718,
      "step": 200
    },
    {
      "epoch": 0.2724981265753798,
      "grad_norm": 1.1665724515914917,
      "learning_rate": 4.87533692722372e-05,
      "loss": 0.1641,
      "step": 250
    },
    {
      "epoch": 0.32699775189045577,
      "grad_norm": 1.1191614866256714,
      "learning_rate": 4.819182389937107e-05,
      "loss": 0.1519,
      "step": 300
    },
    {
      "epoch": 0.38149737720553173,
      "grad_norm": 1.4753096103668213,
      "learning_rate": 4.763027852650494e-05,
      "loss": 0.1234,
      "step": 350
    },
    {
      "epoch": 0.4359970025206077,
      "grad_norm": 1.2348580360412598,
      "learning_rate": 4.7068733153638816e-05,
      "loss": 0.126,
      "step": 400
    },
    {
      "epoch": 0.49049662783568365,
      "grad_norm": 0.6549976468086243,
      "learning_rate": 4.650718778077269e-05,
      "loss": 0.1146,
      "step": 450
    },
    {
      "epoch": 0.5449962531507596,
      "grad_norm": 0.7099913954734802,
      "learning_rate": 4.5945642407906555e-05,
      "loss": 0.1144,
      "step": 500
    },
    {
      "epoch": 0.5994958784658355,
      "grad_norm": 0.7197632193565369,
      "learning_rate": 4.5384097035040435e-05,
      "loss": 0.1207,
      "step": 550
    },
    {
      "epoch": 0.6539955037809115,
      "grad_norm": 1.2354542016983032,
      "learning_rate": 4.482255166217431e-05,
      "loss": 0.1212,
      "step": 600
    },
    {
      "epoch": 0.7084951290959874,
      "grad_norm": 0.5955350399017334,
      "learning_rate": 4.4261006289308174e-05,
      "loss": 0.1063,
      "step": 650
    },
    {
      "epoch": 0.7629947544110635,
      "grad_norm": 0.21705758571624756,
      "learning_rate": 4.3699460916442054e-05,
      "loss": 0.0957,
      "step": 700
    },
    {
      "epoch": 0.8174943797261394,
      "grad_norm": 0.22939163446426392,
      "learning_rate": 4.3137915543575927e-05,
      "loss": 0.1056,
      "step": 750
    },
    {
      "epoch": 0.8719940050412154,
      "grad_norm": 2.0275018215179443,
      "learning_rate": 4.257637017070979e-05,
      "loss": 0.122,
      "step": 800
    },
    {
      "epoch": 0.9264936303562913,
      "grad_norm": 0.9097750186920166,
      "learning_rate": 4.2014824797843666e-05,
      "loss": 0.1128,
      "step": 850
    },
    {
      "epoch": 0.9809932556713673,
      "grad_norm": 0.5924999117851257,
      "learning_rate": 4.1453279424977545e-05,
      "loss": 0.0946,
      "step": 900
    },
    {
      "epoch": 0.9995231282784931,
      "eval_loss": 0.10278341919183731,
      "eval_runtime": 1558.0059,
      "eval_samples_per_second": 1.981,
      "eval_steps_per_second": 1.981,
      "step": 917
    },
    {
      "epoch": 1.0348797602016486,
      "grad_norm": 0.7994444966316223,
      "learning_rate": 4.089173405211141e-05,
      "loss": 0.0835,
      "step": 950
    },
    {
      "epoch": 1.0893793855167246,
      "grad_norm": 0.47247615456581116,
      "learning_rate": 4.0330188679245284e-05,
      "loss": 0.1008,
      "step": 1000
    },
    {
      "epoch": 1.1438790108318004,
      "grad_norm": 0.6770596504211426,
      "learning_rate": 3.976864330637916e-05,
      "loss": 0.0993,
      "step": 1050
    },
    {
      "epoch": 1.1983786361468765,
      "grad_norm": 1.370674967765808,
      "learning_rate": 3.920709793351303e-05,
      "loss": 0.0938,
      "step": 1100
    },
    {
      "epoch": 1.2528782614619525,
      "grad_norm": 1.142350196838379,
      "learning_rate": 3.86455525606469e-05,
      "loss": 0.0921,
      "step": 1150
    },
    {
      "epoch": 1.3073778867770285,
      "grad_norm": 2.462023973464966,
      "learning_rate": 3.8084007187780776e-05,
      "loss": 0.113,
      "step": 1200
    },
    {
      "epoch": 1.3618775120921045,
      "grad_norm": 0.7276492118835449,
      "learning_rate": 3.752246181491464e-05,
      "loss": 0.0861,
      "step": 1250
    },
    {
      "epoch": 1.4163771374071803,
      "grad_norm": 2.572838306427002,
      "learning_rate": 3.696091644204852e-05,
      "loss": 0.0867,
      "step": 1300
    },
    {
      "epoch": 1.4708767627222563,
      "grad_norm": 0.9657453298568726,
      "learning_rate": 3.6399371069182395e-05,
      "loss": 0.0905,
      "step": 1350
    },
    {
      "epoch": 1.525376388037332,
      "grad_norm": 1.2374688386917114,
      "learning_rate": 3.583782569631626e-05,
      "loss": 0.0969,
      "step": 1400
    },
    {
      "epoch": 1.5798760133524081,
      "grad_norm": 0.7477770447731018,
      "learning_rate": 3.5276280323450134e-05,
      "loss": 0.1053,
      "step": 1450
    },
    {
      "epoch": 1.6343756386674841,
      "grad_norm": 0.6237267255783081,
      "learning_rate": 3.471473495058401e-05,
      "loss": 0.0771,
      "step": 1500
    },
    {
      "epoch": 1.6888752639825602,
      "grad_norm": 1.0997394323349,
      "learning_rate": 3.415318957771788e-05,
      "loss": 0.0756,
      "step": 1550
    },
    {
      "epoch": 1.7433748892976362,
      "grad_norm": 0.2143973708152771,
      "learning_rate": 3.359164420485175e-05,
      "loss": 0.0977,
      "step": 1600
    },
    {
      "epoch": 1.7978745146127122,
      "grad_norm": 0.23646409809589386,
      "learning_rate": 3.3030098831985626e-05,
      "loss": 0.1102,
      "step": 1650
    },
    {
      "epoch": 1.852374139927788,
      "grad_norm": 1.8646374940872192,
      "learning_rate": 3.24685534591195e-05,
      "loss": 0.0926,
      "step": 1700
    },
    {
      "epoch": 1.906873765242864,
      "grad_norm": 1.5683326721191406,
      "learning_rate": 3.190700808625337e-05,
      "loss": 0.0975,
      "step": 1750
    },
    {
      "epoch": 1.9613733905579398,
      "grad_norm": 0.47302013635635376,
      "learning_rate": 3.1345462713387245e-05,
      "loss": 0.0918,
      "step": 1800
    },
    {
      "epoch": 1.9984331357721916,
      "eval_loss": 0.09073296934366226,
      "eval_runtime": 1756.5979,
      "eval_samples_per_second": 1.757,
      "eval_steps_per_second": 1.757,
      "step": 1834
    },
    {
      "epoch": 2.0152598950882212,
      "grad_norm": 0.8647415041923523,
      "learning_rate": 3.078391734052112e-05,
      "loss": 0.0803,
      "step": 1850
    },
    {
      "epoch": 2.0697595204032972,
      "grad_norm": 0.8394344449043274,
      "learning_rate": 3.022237196765499e-05,
      "loss": 0.0748,
      "step": 1900
    },
    {
      "epoch": 2.1242591457183733,
      "grad_norm": 2.6059963703155518,
      "learning_rate": 2.966082659478886e-05,
      "loss": 0.0844,
      "step": 1950
    },
    {
      "epoch": 2.1787587710334493,
      "grad_norm": 1.2850399017333984,
      "learning_rate": 2.909928122192273e-05,
      "loss": 0.0849,
      "step": 2000
    },
    {
      "epoch": 2.2332583963485253,
      "grad_norm": 1.3537451028823853,
      "learning_rate": 2.8537735849056606e-05,
      "loss": 0.0831,
      "step": 2050
    },
    {
      "epoch": 2.287758021663601,
      "grad_norm": 1.3476381301879883,
      "learning_rate": 2.797619047619048e-05,
      "loss": 0.0801,
      "step": 2100
    },
    {
      "epoch": 2.342257646978677,
      "grad_norm": 0.42519083619117737,
      "learning_rate": 2.7414645103324348e-05,
      "loss": 0.0754,
      "step": 2150
    },
    {
      "epoch": 2.396757272293753,
      "grad_norm": 1.9424927234649658,
      "learning_rate": 2.685309973045822e-05,
      "loss": 0.0723,
      "step": 2200
    },
    {
      "epoch": 2.451256897608829,
      "grad_norm": 0.8108159899711609,
      "learning_rate": 2.6291554357592098e-05,
      "loss": 0.0794,
      "step": 2250
    },
    {
      "epoch": 2.505756522923905,
      "grad_norm": 1.2938672304153442,
      "learning_rate": 2.5730008984725967e-05,
      "loss": 0.0721,
      "step": 2300
    },
    {
      "epoch": 2.560256148238981,
      "grad_norm": 1.2507482767105103,
      "learning_rate": 2.5168463611859837e-05,
      "loss": 0.0847,
      "step": 2350
    },
    {
      "epoch": 2.614755773554057,
      "grad_norm": 2.451035976409912,
      "learning_rate": 2.4606918238993713e-05,
      "loss": 0.086,
      "step": 2400
    },
    {
      "epoch": 2.669255398869133,
      "grad_norm": 0.43985825777053833,
      "learning_rate": 2.4045372866127582e-05,
      "loss": 0.0857,
      "step": 2450
    },
    {
      "epoch": 2.723755024184209,
      "grad_norm": 1.6103962659835815,
      "learning_rate": 2.3483827493261455e-05,
      "loss": 0.0916,
      "step": 2500
    },
    {
      "epoch": 2.7782546494992846,
      "grad_norm": 1.187913179397583,
      "learning_rate": 2.2922282120395332e-05,
      "loss": 0.0807,
      "step": 2550
    },
    {
      "epoch": 2.8327542748143606,
      "grad_norm": 0.44910284876823425,
      "learning_rate": 2.23607367475292e-05,
      "loss": 0.0761,
      "step": 2600
    },
    {
      "epoch": 2.8872539001294366,
      "grad_norm": 1.8953404426574707,
      "learning_rate": 2.1799191374663074e-05,
      "loss": 0.0838,
      "step": 2650
    },
    {
      "epoch": 2.9417535254445126,
      "grad_norm": 4.822086811065674,
      "learning_rate": 2.1237646001796947e-05,
      "loss": 0.0858,
      "step": 2700
    },
    {
      "epoch": 2.9962531507595886,
      "grad_norm": 0.7877388596534729,
      "learning_rate": 2.067610062893082e-05,
      "loss": 0.0859,
      "step": 2750
    },
    {
      "epoch": 2.99734314326589,
      "eval_loss": 0.08611692488193512,
      "eval_runtime": 1555.5183,
      "eval_samples_per_second": 1.984,
      "eval_steps_per_second": 1.984,
      "step": 2751
    },
    {
      "epoch": 3.05013965528987,
      "grad_norm": 0.7984302639961243,
      "learning_rate": 2.011455525606469e-05,
      "loss": 0.084,
      "step": 2800
    },
    {
      "epoch": 3.1046392806049457,
      "grad_norm": 1.731473684310913,
      "learning_rate": 1.9553009883198563e-05,
      "loss": 0.0722,
      "step": 2850
    },
    {
      "epoch": 3.1591389059200217,
      "grad_norm": 1.27853524684906,
      "learning_rate": 1.8991464510332435e-05,
      "loss": 0.0805,
      "step": 2900
    },
    {
      "epoch": 3.2136385312350977,
      "grad_norm": 0.5072411894798279,
      "learning_rate": 1.842991913746631e-05,
      "loss": 0.0704,
      "step": 2950
    },
    {
      "epoch": 3.2681381565501737,
      "grad_norm": 0.635221540927887,
      "learning_rate": 1.786837376460018e-05,
      "loss": 0.0752,
      "step": 3000
    },
    {
      "epoch": 3.3226377818652497,
      "grad_norm": 2.2418370246887207,
      "learning_rate": 1.7306828391734054e-05,
      "loss": 0.0792,
      "step": 3050
    },
    {
      "epoch": 3.3771374071803257,
      "grad_norm": 7.973780632019043,
      "learning_rate": 1.6745283018867924e-05,
      "loss": 0.0688,
      "step": 3100
    },
    {
      "epoch": 3.4316370324954018,
      "grad_norm": 0.9535382390022278,
      "learning_rate": 1.6183737646001797e-05,
      "loss": 0.0778,
      "step": 3150
    },
    {
      "epoch": 3.4861366578104773,
      "grad_norm": 1.7404409646987915,
      "learning_rate": 1.562219227313567e-05,
      "loss": 0.0746,
      "step": 3200
    },
    {
      "epoch": 3.5406362831255533,
      "grad_norm": 1.3884730339050293,
      "learning_rate": 1.5060646900269543e-05,
      "loss": 0.0683,
      "step": 3250
    },
    {
      "epoch": 3.5951359084406294,
      "grad_norm": 1.5645785331726074,
      "learning_rate": 1.4499101527403414e-05,
      "loss": 0.0835,
      "step": 3300
    },
    {
      "epoch": 3.6496355337557054,
      "grad_norm": 0.6484010815620422,
      "learning_rate": 1.3937556154537287e-05,
      "loss": 0.0627,
      "step": 3350
    },
    {
      "epoch": 3.7041351590707814,
      "grad_norm": 0.7386772036552429,
      "learning_rate": 1.3376010781671158e-05,
      "loss": 0.0921,
      "step": 3400
    },
    {
      "epoch": 3.7586347843858574,
      "grad_norm": 2.106583833694458,
      "learning_rate": 1.2814465408805033e-05,
      "loss": 0.0744,
      "step": 3450
    },
    {
      "epoch": 3.8131344097009334,
      "grad_norm": 1.9073065519332886,
      "learning_rate": 1.2252920035938904e-05,
      "loss": 0.0699,
      "step": 3500
    },
    {
      "epoch": 3.8676340350160094,
      "grad_norm": 0.6392430067062378,
      "learning_rate": 1.1691374663072777e-05,
      "loss": 0.0719,
      "step": 3550
    },
    {
      "epoch": 3.9221336603310855,
      "grad_norm": 1.3331338167190552,
      "learning_rate": 1.112982929020665e-05,
      "loss": 0.0621,
      "step": 3600
    },
    {
      "epoch": 3.976633285646161,
      "grad_norm": 1.7413766384124756,
      "learning_rate": 1.0568283917340521e-05,
      "loss": 0.0659,
      "step": 3650
    },
    {
      "epoch": 3.9962531507595886,
      "eval_loss": 0.08533525466918945,
      "eval_runtime": 1551.3205,
      "eval_samples_per_second": 1.989,
      "eval_steps_per_second": 1.989,
      "step": 3668
    },
    {
      "epoch": 4.0305197901764425,
      "grad_norm": 1.132327675819397,
      "learning_rate": 1.0006738544474394e-05,
      "loss": 0.0615,
      "step": 3700
    },
    {
      "epoch": 4.0850194154915185,
      "grad_norm": 1.8479716777801514,
      "learning_rate": 9.445193171608265e-06,
      "loss": 0.0569,
      "step": 3750
    },
    {
      "epoch": 4.1395190408065945,
      "grad_norm": 1.8758052587509155,
      "learning_rate": 8.883647798742138e-06,
      "loss": 0.0769,
      "step": 3800
    },
    {
      "epoch": 4.1940186661216705,
      "grad_norm": 2.081071615219116,
      "learning_rate": 8.322102425876011e-06,
      "loss": 0.0701,
      "step": 3850
    },
    {
      "epoch": 4.2485182914367465,
      "grad_norm": 1.0982693433761597,
      "learning_rate": 7.760557053009884e-06,
      "loss": 0.0697,
      "step": 3900
    },
    {
      "epoch": 4.3030179167518225,
      "grad_norm": 2.086707353591919,
      "learning_rate": 7.199011680143757e-06,
      "loss": 0.063,
      "step": 3950
    },
    {
      "epoch": 4.357517542066899,
      "grad_norm": 1.1609625816345215,
      "learning_rate": 6.637466307277629e-06,
      "loss": 0.0627,
      "step": 4000
    },
    {
      "epoch": 4.412017167381975,
      "grad_norm": 0.509951114654541,
      "learning_rate": 6.0759209344115e-06,
      "loss": 0.0714,
      "step": 4050
    },
    {
      "epoch": 4.466516792697051,
      "grad_norm": 1.3106496334075928,
      "learning_rate": 5.514375561545373e-06,
      "loss": 0.0744,
      "step": 4100
    },
    {
      "epoch": 4.521016418012126,
      "grad_norm": 1.2890514135360718,
      "learning_rate": 4.952830188679246e-06,
      "loss": 0.0641,
      "step": 4150
    },
    {
      "epoch": 4.575516043327202,
      "grad_norm": 1.6794184446334839,
      "learning_rate": 4.391284815813118e-06,
      "loss": 0.0572,
      "step": 4200
    },
    {
      "epoch": 4.630015668642278,
      "grad_norm": 1.0696903467178345,
      "learning_rate": 3.82973944294699e-06,
      "loss": 0.0769,
      "step": 4250
    },
    {
      "epoch": 4.684515293957354,
      "grad_norm": 2.092512369155884,
      "learning_rate": 3.2681940700808626e-06,
      "loss": 0.0688,
      "step": 4300
    },
    {
      "epoch": 4.73901491927243,
      "grad_norm": 1.9282102584838867,
      "learning_rate": 2.706648697214735e-06,
      "loss": 0.0653,
      "step": 4350
    },
    {
      "epoch": 4.793514544587506,
      "grad_norm": 3.8062548637390137,
      "learning_rate": 2.145103324348607e-06,
      "loss": 0.0582,
      "step": 4400
    },
    {
      "epoch": 4.848014169902582,
      "grad_norm": 0.2243417501449585,
      "learning_rate": 1.5835579514824797e-06,
      "loss": 0.0756,
      "step": 4450
    },
    {
      "epoch": 4.902513795217658,
      "grad_norm": 2.205259084701538,
      "learning_rate": 1.0220125786163522e-06,
      "loss": 0.0665,
      "step": 4500
    },
    {
      "epoch": 4.957013420532734,
      "grad_norm": 2.2002298831939697,
      "learning_rate": 4.604672057502246e-07,
      "loss": 0.0576,
      "step": 4550
    },
    {
      "epoch": 4.995163158253287,
      "eval_loss": 0.08871384710073471,
      "eval_runtime": 1550.5615,
      "eval_samples_per_second": 1.99,
      "eval_steps_per_second": 1.99,
      "step": 4585
    }
  ],
  "logging_steps": 50,
  "max_steps": 4590,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 917,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.917917273285361e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": 7710,
  "best_metric": 0.07996512949466705,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/qlora_experiments/models/exp2_qwen_reordered/checkpoint-7710",
  "epoch": 5.0,
  "eval_steps": 2570,
  "global_step": 12840,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019474670756347526,
      "grad_norm": 2.6782400608062744,
      "learning_rate": 6.347150259067358e-06,
      "loss": 1.2683,
      "step": 50
    },
    {
      "epoch": 0.03894934151269505,
      "grad_norm": 0.9339721202850342,
      "learning_rate": 1.2823834196891193e-05,
      "loss": 1.1353,
      "step": 100
    },
    {
      "epoch": 0.05842401226904258,
      "grad_norm": 1.3420748710632324,
      "learning_rate": 1.9300518134715025e-05,
      "loss": 0.44,
      "step": 150
    },
    {
      "epoch": 0.0778986830253901,
      "grad_norm": 0.929776132106781,
      "learning_rate": 2.5777202072538865e-05,
      "loss": 0.2559,
      "step": 200
    },
    {
      "epoch": 0.09737335378173763,
      "grad_norm": 0.6383854746818542,
      "learning_rate": 3.225388601036269e-05,
      "loss": 0.1847,
      "step": 250
    },
    {
      "epoch": 0.11684802453808515,
      "grad_norm": 1.3174418210983276,
      "learning_rate": 3.873056994818653e-05,
      "loss": 0.1839,
      "step": 300
    },
    {
      "epoch": 0.13632269529443267,
      "grad_norm": 1.2083326578140259,
      "learning_rate": 4.520725388601036e-05,
      "loss": 0.1723,
      "step": 350
    },
    {
      "epoch": 0.1557973660507802,
      "grad_norm": 0.7449233531951904,
      "learning_rate": 4.994780793319416e-05,
      "loss": 0.1471,
      "step": 400
    },
    {
      "epoch": 0.17527203680712772,
      "grad_norm": 0.5894939303398132,
      "learning_rate": 4.974706921471013e-05,
      "loss": 0.1319,
      "step": 450
    },
    {
      "epoch": 0.19474670756347526,
      "grad_norm": 1.088955044746399,
      "learning_rate": 4.954633049622611e-05,
      "loss": 0.1136,
      "step": 500
    },
    {
      "epoch": 0.21422137831982277,
      "grad_norm": 1.4944190979003906,
      "learning_rate": 4.9345591777742094e-05,
      "loss": 0.1479,
      "step": 550
    },
    {
      "epoch": 0.2336960490761703,
      "grad_norm": 0.5776036381721497,
      "learning_rate": 4.9144853059258075e-05,
      "loss": 0.1268,
      "step": 600
    },
    {
      "epoch": 0.2531707198325178,
      "grad_norm": 0.9758409857749939,
      "learning_rate": 4.894411434077405e-05,
      "loss": 0.1157,
      "step": 650
    },
    {
      "epoch": 0.27264539058886533,
      "grad_norm": 0.7557951807975769,
      "learning_rate": 4.874337562229003e-05,
      "loss": 0.1289,
      "step": 700
    },
    {
      "epoch": 0.2921200613452129,
      "grad_norm": 0.36358335614204407,
      "learning_rate": 4.854263690380601e-05,
      "loss": 0.1106,
      "step": 750
    },
    {
      "epoch": 0.3115947321015604,
      "grad_norm": 2.082404375076294,
      "learning_rate": 4.8341898185321986e-05,
      "loss": 0.1074,
      "step": 800
    },
    {
      "epoch": 0.3310694028579079,
      "grad_norm": 0.9551264047622681,
      "learning_rate": 4.814115946683797e-05,
      "loss": 0.1101,
      "step": 850
    },
    {
      "epoch": 0.35054407361425544,
      "grad_norm": 1.0336939096450806,
      "learning_rate": 4.794042074835394e-05,
      "loss": 0.1036,
      "step": 900
    },
    {
      "epoch": 0.370018744370603,
      "grad_norm": 0.8853057622909546,
      "learning_rate": 4.773968202986992e-05,
      "loss": 0.105,
      "step": 950
    },
    {
      "epoch": 0.3894934151269505,
      "grad_norm": 0.741865873336792,
      "learning_rate": 4.7538943311385904e-05,
      "loss": 0.1085,
      "step": 1000
    },
    {
      "epoch": 0.408968085883298,
      "grad_norm": 0.5025643706321716,
      "learning_rate": 4.733820459290188e-05,
      "loss": 0.1223,
      "step": 1050
    },
    {
      "epoch": 0.42844275663964554,
      "grad_norm": 2.7979068756103516,
      "learning_rate": 4.713746587441786e-05,
      "loss": 0.0969,
      "step": 1100
    },
    {
      "epoch": 0.4479174273959931,
      "grad_norm": 1.3586416244506836,
      "learning_rate": 4.693672715593384e-05,
      "loss": 0.0974,
      "step": 1150
    },
    {
      "epoch": 0.4673920981523406,
      "grad_norm": 0.7135780453681946,
      "learning_rate": 4.6735988437449815e-05,
      "loss": 0.0983,
      "step": 1200
    },
    {
      "epoch": 0.48686676890868813,
      "grad_norm": 0.6623705625534058,
      "learning_rate": 4.6535249718965796e-05,
      "loss": 0.1058,
      "step": 1250
    },
    {
      "epoch": 0.5063414396650356,
      "grad_norm": 2.4690589904785156,
      "learning_rate": 4.633451100048177e-05,
      "loss": 0.0872,
      "step": 1300
    },
    {
      "epoch": 0.5258161104213832,
      "grad_norm": 1.41069757938385,
      "learning_rate": 4.613377228199776e-05,
      "loss": 0.1088,
      "step": 1350
    },
    {
      "epoch": 0.5452907811777307,
      "grad_norm": 0.6532394886016846,
      "learning_rate": 4.593303356351373e-05,
      "loss": 0.0984,
      "step": 1400
    },
    {
      "epoch": 0.5647654519340782,
      "grad_norm": 3.457484245300293,
      "learning_rate": 4.5732294845029714e-05,
      "loss": 0.1071,
      "step": 1450
    },
    {
      "epoch": 0.5842401226904258,
      "grad_norm": 0.88014155626297,
      "learning_rate": 4.553155612654569e-05,
      "loss": 0.0867,
      "step": 1500
    },
    {
      "epoch": 0.6037147934467733,
      "grad_norm": 1.2389416694641113,
      "learning_rate": 4.533081740806167e-05,
      "loss": 0.0998,
      "step": 1550
    },
    {
      "epoch": 0.6231894642031208,
      "grad_norm": 0.7443467378616333,
      "learning_rate": 4.513007868957765e-05,
      "loss": 0.0954,
      "step": 1600
    },
    {
      "epoch": 0.6426641349594684,
      "grad_norm": 2.197470188140869,
      "learning_rate": 4.4929339971093625e-05,
      "loss": 0.0962,
      "step": 1650
    },
    {
      "epoch": 0.6621388057158158,
      "grad_norm": 0.1516454964876175,
      "learning_rate": 4.4728601252609606e-05,
      "loss": 0.0983,
      "step": 1700
    },
    {
      "epoch": 0.6816134764721634,
      "grad_norm": 1.128591775894165,
      "learning_rate": 4.452786253412559e-05,
      "loss": 0.0905,
      "step": 1750
    },
    {
      "epoch": 0.7010881472285109,
      "grad_norm": 1.202581763267517,
      "learning_rate": 4.432712381564156e-05,
      "loss": 0.0851,
      "step": 1800
    },
    {
      "epoch": 0.7205628179848584,
      "grad_norm": 0.7686196565628052,
      "learning_rate": 4.412638509715754e-05,
      "loss": 0.083,
      "step": 1850
    },
    {
      "epoch": 0.740037488741206,
      "grad_norm": 0.5166720747947693,
      "learning_rate": 4.392564637867352e-05,
      "loss": 0.1022,
      "step": 1900
    },
    {
      "epoch": 0.7595121594975535,
      "grad_norm": 1.1949307918548584,
      "learning_rate": 4.37249076601895e-05,
      "loss": 0.091,
      "step": 1950
    },
    {
      "epoch": 0.778986830253901,
      "grad_norm": 0.8803325295448303,
      "learning_rate": 4.352416894170548e-05,
      "loss": 0.0906,
      "step": 2000
    },
    {
      "epoch": 0.7984615010102486,
      "grad_norm": 1.1490216255187988,
      "learning_rate": 4.3323430223221454e-05,
      "loss": 0.0768,
      "step": 2050
    },
    {
      "epoch": 0.817936171766596,
      "grad_norm": 0.6036552786827087,
      "learning_rate": 4.3122691504737435e-05,
      "loss": 0.0885,
      "step": 2100
    },
    {
      "epoch": 0.8374108425229436,
      "grad_norm": 0.7776727676391602,
      "learning_rate": 4.2921952786253416e-05,
      "loss": 0.0927,
      "step": 2150
    },
    {
      "epoch": 0.8568855132792911,
      "grad_norm": 0.20178066194057465,
      "learning_rate": 4.27212140677694e-05,
      "loss": 0.0874,
      "step": 2200
    },
    {
      "epoch": 0.8763601840356386,
      "grad_norm": 1.5367587804794312,
      "learning_rate": 4.252047534928537e-05,
      "loss": 0.0878,
      "step": 2250
    },
    {
      "epoch": 0.8958348547919862,
      "grad_norm": 0.6233471035957336,
      "learning_rate": 4.2319736630801346e-05,
      "loss": 0.0968,
      "step": 2300
    },
    {
      "epoch": 0.9153095255483337,
      "grad_norm": 0.685736894607544,
      "learning_rate": 4.2118997912317334e-05,
      "loss": 0.0867,
      "step": 2350
    },
    {
      "epoch": 0.9347841963046812,
      "grad_norm": 0.6192984580993652,
      "learning_rate": 4.191825919383331e-05,
      "loss": 0.0915,
      "step": 2400
    },
    {
      "epoch": 0.9542588670610288,
      "grad_norm": 2.3069570064544678,
      "learning_rate": 4.171752047534929e-05,
      "loss": 0.0881,
      "step": 2450
    },
    {
      "epoch": 0.9737335378173763,
      "grad_norm": 0.47864896059036255,
      "learning_rate": 4.1516781756865263e-05,
      "loss": 0.0839,
      "step": 2500
    },
    {
      "epoch": 0.9932082085737238,
      "grad_norm": 0.3431068956851959,
      "learning_rate": 4.1316043038381245e-05,
      "loss": 0.0763,
      "step": 2550
    },
    {
      "epoch": 1.000778986830254,
      "eval_loss": 0.08674078434705734,
      "eval_runtime": 1934.2127,
      "eval_samples_per_second": 4.542,
      "eval_steps_per_second": 4.542,
      "step": 2570
    },
    {
      "epoch": 1.0124637892840624,
      "grad_norm": 0.8319634199142456,
      "learning_rate": 4.1115304319897226e-05,
      "loss": 0.0801,
      "step": 2600
    },
    {
      "epoch": 1.03193846004041,
      "grad_norm": 0.7544825673103333,
      "learning_rate": 4.09145656014132e-05,
      "loss": 0.0836,
      "step": 2650
    },
    {
      "epoch": 1.0514131307967576,
      "grad_norm": 0.7455063462257385,
      "learning_rate": 4.071382688292918e-05,
      "loss": 0.0932,
      "step": 2700
    },
    {
      "epoch": 1.070887801553105,
      "grad_norm": 1.1316190958023071,
      "learning_rate": 4.051308816444516e-05,
      "loss": 0.0786,
      "step": 2750
    },
    {
      "epoch": 1.0903624723094525,
      "grad_norm": 1.077717661857605,
      "learning_rate": 4.031234944596114e-05,
      "loss": 0.0906,
      "step": 2800
    },
    {
      "epoch": 1.1098371430658,
      "grad_norm": 0.8410002589225769,
      "learning_rate": 4.011161072747712e-05,
      "loss": 0.0844,
      "step": 2850
    },
    {
      "epoch": 1.1293118138221476,
      "grad_norm": 1.0081312656402588,
      "learning_rate": 3.991087200899309e-05,
      "loss": 0.0908,
      "step": 2900
    },
    {
      "epoch": 1.148786484578495,
      "grad_norm": 0.9257616400718689,
      "learning_rate": 3.971013329050908e-05,
      "loss": 0.0804,
      "step": 2950
    },
    {
      "epoch": 1.1682611553348425,
      "grad_norm": 0.3897239565849304,
      "learning_rate": 3.9509394572025054e-05,
      "loss": 0.0953,
      "step": 3000
    },
    {
      "epoch": 1.18773582609119,
      "grad_norm": 1.25826895236969,
      "learning_rate": 3.930865585354103e-05,
      "loss": 0.0731,
      "step": 3050
    },
    {
      "epoch": 1.2072104968475377,
      "grad_norm": 1.124010682106018,
      "learning_rate": 3.910791713505701e-05,
      "loss": 0.0892,
      "step": 3100
    },
    {
      "epoch": 1.2266851676038852,
      "grad_norm": 1.1020586490631104,
      "learning_rate": 3.890717841657299e-05,
      "loss": 0.0872,
      "step": 3150
    },
    {
      "epoch": 1.2461598383602328,
      "grad_norm": 0.7767069339752197,
      "learning_rate": 3.870643969808897e-05,
      "loss": 0.0873,
      "step": 3200
    },
    {
      "epoch": 1.2656345091165804,
      "grad_norm": 0.9210228323936462,
      "learning_rate": 3.8505700979604947e-05,
      "loss": 0.0862,
      "step": 3250
    },
    {
      "epoch": 1.2851091798729277,
      "grad_norm": 1.2565768957138062,
      "learning_rate": 3.830496226112093e-05,
      "loss": 0.087,
      "step": 3300
    },
    {
      "epoch": 1.3045838506292753,
      "grad_norm": 1.1517010927200317,
      "learning_rate": 3.810422354263691e-05,
      "loss": 0.0888,
      "step": 3350
    },
    {
      "epoch": 1.3240585213856229,
      "grad_norm": 0.4197128117084503,
      "learning_rate": 3.790348482415288e-05,
      "loss": 0.0882,
      "step": 3400
    },
    {
      "epoch": 1.3435331921419704,
      "grad_norm": 1.173756718635559,
      "learning_rate": 3.7702746105668864e-05,
      "loss": 0.0893,
      "step": 3450
    },
    {
      "epoch": 1.3630078628983178,
      "grad_norm": 1.437241792678833,
      "learning_rate": 3.750200738718484e-05,
      "loss": 0.0787,
      "step": 3500
    },
    {
      "epoch": 1.3824825336546653,
      "grad_norm": 1.195618748664856,
      "learning_rate": 3.730126866870082e-05,
      "loss": 0.0794,
      "step": 3550
    },
    {
      "epoch": 1.401957204411013,
      "grad_norm": 1.9352023601531982,
      "learning_rate": 3.71005299502168e-05,
      "loss": 0.076,
      "step": 3600
    },
    {
      "epoch": 1.4214318751673605,
      "grad_norm": 1.0826269388198853,
      "learning_rate": 3.6899791231732775e-05,
      "loss": 0.0823,
      "step": 3650
    },
    {
      "epoch": 1.440906545923708,
      "grad_norm": 1.8156652450561523,
      "learning_rate": 3.6699052513248757e-05,
      "loss": 0.0772,
      "step": 3700
    },
    {
      "epoch": 1.4603812166800556,
      "grad_norm": 0.03637466952204704,
      "learning_rate": 3.649831379476474e-05,
      "loss": 0.0732,
      "step": 3750
    },
    {
      "epoch": 1.479855887436403,
      "grad_norm": 0.4824879765510559,
      "learning_rate": 3.629757507628072e-05,
      "loss": 0.0645,
      "step": 3800
    },
    {
      "epoch": 1.4993305581927505,
      "grad_norm": 0.8185610771179199,
      "learning_rate": 3.609683635779669e-05,
      "loss": 0.0704,
      "step": 3850
    },
    {
      "epoch": 1.518805228949098,
      "grad_norm": 0.8215335607528687,
      "learning_rate": 3.589609763931267e-05,
      "loss": 0.0786,
      "step": 3900
    },
    {
      "epoch": 1.5382798997054457,
      "grad_norm": 0.5334855318069458,
      "learning_rate": 3.5695358920828655e-05,
      "loss": 0.0745,
      "step": 3950
    },
    {
      "epoch": 1.557754570461793,
      "grad_norm": 0.29282164573669434,
      "learning_rate": 3.549462020234463e-05,
      "loss": 0.0812,
      "step": 4000
    },
    {
      "epoch": 1.5772292412181406,
      "grad_norm": 1.2510043382644653,
      "learning_rate": 3.529388148386061e-05,
      "loss": 0.0754,
      "step": 4050
    },
    {
      "epoch": 1.5967039119744881,
      "grad_norm": 0.544284462928772,
      "learning_rate": 3.5093142765376585e-05,
      "loss": 0.0729,
      "step": 4100
    },
    {
      "epoch": 1.6161785827308357,
      "grad_norm": 0.29621002078056335,
      "learning_rate": 3.4892404046892566e-05,
      "loss": 0.0816,
      "step": 4150
    },
    {
      "epoch": 1.6356532534871833,
      "grad_norm": 0.10040954500436783,
      "learning_rate": 3.469166532840855e-05,
      "loss": 0.0769,
      "step": 4200
    },
    {
      "epoch": 1.6551279242435308,
      "grad_norm": 1.7866281270980835,
      "learning_rate": 3.449092660992452e-05,
      "loss": 0.0874,
      "step": 4250
    },
    {
      "epoch": 1.6746025949998784,
      "grad_norm": 2.5681772232055664,
      "learning_rate": 3.42901878914405e-05,
      "loss": 0.0919,
      "step": 4300
    },
    {
      "epoch": 1.694077265756226,
      "grad_norm": 0.7361022233963013,
      "learning_rate": 3.4089449172956484e-05,
      "loss": 0.0633,
      "step": 4350
    },
    {
      "epoch": 1.7135519365125733,
      "grad_norm": 0.3376437723636627,
      "learning_rate": 3.388871045447246e-05,
      "loss": 0.0767,
      "step": 4400
    },
    {
      "epoch": 1.7330266072689209,
      "grad_norm": 0.2276783138513565,
      "learning_rate": 3.368797173598844e-05,
      "loss": 0.1007,
      "step": 4450
    },
    {
      "epoch": 1.7525012780252682,
      "grad_norm": 0.5202165246009827,
      "learning_rate": 3.3487233017504414e-05,
      "loss": 0.0677,
      "step": 4500
    },
    {
      "epoch": 1.7719759487816158,
      "grad_norm": 0.270570307970047,
      "learning_rate": 3.32864942990204e-05,
      "loss": 0.0869,
      "step": 4550
    },
    {
      "epoch": 1.7914506195379634,
      "grad_norm": 0.5535165071487427,
      "learning_rate": 3.3085755580536376e-05,
      "loss": 0.087,
      "step": 4600
    },
    {
      "epoch": 1.810925290294311,
      "grad_norm": 1.1067993640899658,
      "learning_rate": 3.288501686205235e-05,
      "loss": 0.0787,
      "step": 4650
    },
    {
      "epoch": 1.8303999610506585,
      "grad_norm": 1.719653844833374,
      "learning_rate": 3.268427814356833e-05,
      "loss": 0.0892,
      "step": 4700
    },
    {
      "epoch": 1.849874631807006,
      "grad_norm": 0.628442108631134,
      "learning_rate": 3.248353942508431e-05,
      "loss": 0.0729,
      "step": 4750
    },
    {
      "epoch": 1.8693493025633536,
      "grad_norm": 2.029972791671753,
      "learning_rate": 3.2282800706600294e-05,
      "loss": 0.0812,
      "step": 4800
    },
    {
      "epoch": 1.8888239733197012,
      "grad_norm": 0.8689267635345459,
      "learning_rate": 3.208206198811627e-05,
      "loss": 0.0662,
      "step": 4850
    },
    {
      "epoch": 1.9082986440760485,
      "grad_norm": 0.7658007144927979,
      "learning_rate": 3.188132326963224e-05,
      "loss": 0.0932,
      "step": 4900
    },
    {
      "epoch": 1.9277733148323961,
      "grad_norm": 0.5750874280929565,
      "learning_rate": 3.168058455114823e-05,
      "loss": 0.0732,
      "step": 4950
    },
    {
      "epoch": 1.9472479855887437,
      "grad_norm": 0.8890137076377869,
      "learning_rate": 3.1479845832664205e-05,
      "loss": 0.0817,
      "step": 5000
    },
    {
      "epoch": 1.966722656345091,
      "grad_norm": 1.2561744451522827,
      "learning_rate": 3.1279107114180186e-05,
      "loss": 0.0874,
      "step": 5050
    },
    {
      "epoch": 1.9861973271014386,
      "grad_norm": 0.17602618038654327,
      "learning_rate": 3.107836839569616e-05,
      "loss": 0.0794,
      "step": 5100
    },
    {
      "epoch": 2.001557973660508,
      "eval_loss": 0.08152318745851517,
      "eval_runtime": 1929.7355,
      "eval_samples_per_second": 4.553,
      "eval_steps_per_second": 4.553,
      "step": 5140
    },
    {
      "epoch": 2.0054529078117773,
      "grad_norm": 0.46491187810897827,
      "learning_rate": 3.087762967721214e-05,
      "loss": 0.0787,
      "step": 5150
    },
    {
      "epoch": 2.024927578568125,
      "grad_norm": 0.9094627499580383,
      "learning_rate": 3.067689095872812e-05,
      "loss": 0.0788,
      "step": 5200
    },
    {
      "epoch": 2.0444022493244725,
      "grad_norm": 0.784762442111969,
      "learning_rate": 3.04761522402441e-05,
      "loss": 0.0822,
      "step": 5250
    },
    {
      "epoch": 2.06387692008082,
      "grad_norm": 0.7033857107162476,
      "learning_rate": 3.0275413521760075e-05,
      "loss": 0.0635,
      "step": 5300
    },
    {
      "epoch": 2.0833515908371676,
      "grad_norm": 1.0722776651382446,
      "learning_rate": 3.007467480327606e-05,
      "loss": 0.0857,
      "step": 5350
    },
    {
      "epoch": 2.102826261593515,
      "grad_norm": 0.3549136221408844,
      "learning_rate": 2.9873936084792037e-05,
      "loss": 0.0707,
      "step": 5400
    },
    {
      "epoch": 2.1223009323498623,
      "grad_norm": 0.22968991100788116,
      "learning_rate": 2.9673197366308015e-05,
      "loss": 0.0545,
      "step": 5450
    },
    {
      "epoch": 2.14177560310621,
      "grad_norm": 0.6469301581382751,
      "learning_rate": 2.9472458647823993e-05,
      "loss": 0.0712,
      "step": 5500
    },
    {
      "epoch": 2.1612502738625574,
      "grad_norm": 0.3132959008216858,
      "learning_rate": 2.9271719929339974e-05,
      "loss": 0.0619,
      "step": 5550
    },
    {
      "epoch": 2.180724944618905,
      "grad_norm": 0.9295791983604431,
      "learning_rate": 2.907098121085595e-05,
      "loss": 0.0797,
      "step": 5600
    },
    {
      "epoch": 2.2001996153752525,
      "grad_norm": 5.632770538330078,
      "learning_rate": 2.887024249237193e-05,
      "loss": 0.0724,
      "step": 5650
    },
    {
      "epoch": 2.2196742861316,
      "grad_norm": 0.6620182394981384,
      "learning_rate": 2.8669503773887907e-05,
      "loss": 0.073,
      "step": 5700
    },
    {
      "epoch": 2.2391489568879477,
      "grad_norm": 0.19529007375240326,
      "learning_rate": 2.8468765055403888e-05,
      "loss": 0.0776,
      "step": 5750
    },
    {
      "epoch": 2.2586236276442953,
      "grad_norm": 0.7491660714149475,
      "learning_rate": 2.8268026336919866e-05,
      "loss": 0.0714,
      "step": 5800
    },
    {
      "epoch": 2.278098298400643,
      "grad_norm": 1.6818745136260986,
      "learning_rate": 2.8067287618435844e-05,
      "loss": 0.0739,
      "step": 5850
    },
    {
      "epoch": 2.29757296915699,
      "grad_norm": 2.064788579940796,
      "learning_rate": 2.786654889995182e-05,
      "loss": 0.0761,
      "step": 5900
    },
    {
      "epoch": 2.317047639913338,
      "grad_norm": 0.8641449213027954,
      "learning_rate": 2.7665810181467806e-05,
      "loss": 0.0707,
      "step": 5950
    },
    {
      "epoch": 2.336522310669685,
      "grad_norm": 1.2104196548461914,
      "learning_rate": 2.7465071462983784e-05,
      "loss": 0.0823,
      "step": 6000
    },
    {
      "epoch": 2.3559969814260326,
      "grad_norm": 0.8220031261444092,
      "learning_rate": 2.726433274449976e-05,
      "loss": 0.0669,
      "step": 6050
    },
    {
      "epoch": 2.37547165218238,
      "grad_norm": 0.6223728060722351,
      "learning_rate": 2.7063594026015736e-05,
      "loss": 0.0675,
      "step": 6100
    },
    {
      "epoch": 2.394946322938728,
      "grad_norm": 0.5645125508308411,
      "learning_rate": 2.686285530753172e-05,
      "loss": 0.0684,
      "step": 6150
    },
    {
      "epoch": 2.4144209936950753,
      "grad_norm": 1.5381526947021484,
      "learning_rate": 2.6662116589047698e-05,
      "loss": 0.0721,
      "step": 6200
    },
    {
      "epoch": 2.433895664451423,
      "grad_norm": 0.8032523989677429,
      "learning_rate": 2.6461377870563676e-05,
      "loss": 0.0776,
      "step": 6250
    },
    {
      "epoch": 2.4533703352077705,
      "grad_norm": 1.5533547401428223,
      "learning_rate": 2.6260639152079654e-05,
      "loss": 0.0808,
      "step": 6300
    },
    {
      "epoch": 2.472845005964118,
      "grad_norm": 1.4248348474502563,
      "learning_rate": 2.6059900433595635e-05,
      "loss": 0.0817,
      "step": 6350
    },
    {
      "epoch": 2.4923196767204656,
      "grad_norm": 0.13115210831165314,
      "learning_rate": 2.5859161715111613e-05,
      "loss": 0.0779,
      "step": 6400
    },
    {
      "epoch": 2.5117943474768127,
      "grad_norm": 0.8283383250236511,
      "learning_rate": 2.565842299662759e-05,
      "loss": 0.0648,
      "step": 6450
    },
    {
      "epoch": 2.5312690182331608,
      "grad_norm": 1.1835345029830933,
      "learning_rate": 2.5457684278143568e-05,
      "loss": 0.0648,
      "step": 6500
    },
    {
      "epoch": 2.550743688989508,
      "grad_norm": 0.3833991587162018,
      "learning_rate": 2.525694555965955e-05,
      "loss": 0.0781,
      "step": 6550
    },
    {
      "epoch": 2.5702183597458554,
      "grad_norm": 1.532918930053711,
      "learning_rate": 2.5056206841175527e-05,
      "loss": 0.0727,
      "step": 6600
    },
    {
      "epoch": 2.589693030502203,
      "grad_norm": 1.8034414052963257,
      "learning_rate": 2.4855468122691505e-05,
      "loss": 0.089,
      "step": 6650
    },
    {
      "epoch": 2.6091677012585506,
      "grad_norm": 1.0544533729553223,
      "learning_rate": 2.4654729404207486e-05,
      "loss": 0.0647,
      "step": 6700
    },
    {
      "epoch": 2.628642372014898,
      "grad_norm": 0.8297218680381775,
      "learning_rate": 2.4453990685723464e-05,
      "loss": 0.0705,
      "step": 6750
    },
    {
      "epoch": 2.6481170427712457,
      "grad_norm": 1.0940097570419312,
      "learning_rate": 2.4253251967239445e-05,
      "loss": 0.0695,
      "step": 6800
    },
    {
      "epoch": 2.6675917135275933,
      "grad_norm": 3.3465423583984375,
      "learning_rate": 2.405251324875542e-05,
      "loss": 0.0706,
      "step": 6850
    },
    {
      "epoch": 2.687066384283941,
      "grad_norm": 1.7361897230148315,
      "learning_rate": 2.38517745302714e-05,
      "loss": 0.0702,
      "step": 6900
    },
    {
      "epoch": 2.7065410550402884,
      "grad_norm": 0.19719994068145752,
      "learning_rate": 2.3651035811787378e-05,
      "loss": 0.0602,
      "step": 6950
    },
    {
      "epoch": 2.7260157257966355,
      "grad_norm": 0.1126461923122406,
      "learning_rate": 2.345029709330336e-05,
      "loss": 0.0672,
      "step": 7000
    },
    {
      "epoch": 2.7454903965529835,
      "grad_norm": 0.7710656523704529,
      "learning_rate": 2.3249558374819337e-05,
      "loss": 0.0766,
      "step": 7050
    },
    {
      "epoch": 2.7649650673093307,
      "grad_norm": 0.18356426060199738,
      "learning_rate": 2.3048819656335315e-05,
      "loss": 0.0626,
      "step": 7100
    },
    {
      "epoch": 2.7844397380656782,
      "grad_norm": 1.3741239309310913,
      "learning_rate": 2.2848080937851292e-05,
      "loss": 0.0778,
      "step": 7150
    },
    {
      "epoch": 2.803914408822026,
      "grad_norm": 0.8728005290031433,
      "learning_rate": 2.2647342219367273e-05,
      "loss": 0.0686,
      "step": 7200
    },
    {
      "epoch": 2.8233890795783734,
      "grad_norm": 1.6128177642822266,
      "learning_rate": 2.244660350088325e-05,
      "loss": 0.087,
      "step": 7250
    },
    {
      "epoch": 2.842863750334721,
      "grad_norm": 0.4795592129230499,
      "learning_rate": 2.2245864782399232e-05,
      "loss": 0.0697,
      "step": 7300
    },
    {
      "epoch": 2.8623384210910685,
      "grad_norm": 1.7126750946044922,
      "learning_rate": 2.204512606391521e-05,
      "loss": 0.0723,
      "step": 7350
    },
    {
      "epoch": 2.881813091847416,
      "grad_norm": 1.0676740407943726,
      "learning_rate": 2.1844387345431188e-05,
      "loss": 0.0839,
      "step": 7400
    },
    {
      "epoch": 2.9012877626037636,
      "grad_norm": 0.6678335070610046,
      "learning_rate": 2.1643648626947166e-05,
      "loss": 0.0647,
      "step": 7450
    },
    {
      "epoch": 2.920762433360111,
      "grad_norm": 1.0612764358520508,
      "learning_rate": 2.1442909908463147e-05,
      "loss": 0.0655,
      "step": 7500
    },
    {
      "epoch": 2.9402371041164583,
      "grad_norm": 0.16635437309741974,
      "learning_rate": 2.1242171189979124e-05,
      "loss": 0.0743,
      "step": 7550
    },
    {
      "epoch": 2.959711774872806,
      "grad_norm": 1.532870888710022,
      "learning_rate": 2.1041432471495106e-05,
      "loss": 0.0668,
      "step": 7600
    },
    {
      "epoch": 2.9791864456291535,
      "grad_norm": 1.391165852546692,
      "learning_rate": 2.084069375301108e-05,
      "loss": 0.0748,
      "step": 7650
    },
    {
      "epoch": 2.998661116385501,
      "grad_norm": 1.0278029441833496,
      "learning_rate": 2.063995503452706e-05,
      "loss": 0.0755,
      "step": 7700
    },
    {
      "epoch": 3.0023369604907617,
      "eval_loss": 0.07996512949466705,
      "eval_runtime": 1933.1256,
      "eval_samples_per_second": 4.545,
      "eval_steps_per_second": 4.545,
      "step": 7710
    },
    {
      "epoch": 3.0179166970958398,
      "grad_norm": 0.30070990324020386,
      "learning_rate": 2.043921631604304e-05,
      "loss": 0.0702,
      "step": 7750
    },
    {
      "epoch": 3.0373913678521873,
      "grad_norm": 1.7956942319869995,
      "learning_rate": 2.023847759755902e-05,
      "loss": 0.0758,
      "step": 7800
    },
    {
      "epoch": 3.056866038608535,
      "grad_norm": 1.7840394973754883,
      "learning_rate": 2.0037738879074998e-05,
      "loss": 0.0602,
      "step": 7850
    },
    {
      "epoch": 3.0763407093648825,
      "grad_norm": 1.6574465036392212,
      "learning_rate": 1.9837000160590975e-05,
      "loss": 0.0639,
      "step": 7900
    },
    {
      "epoch": 3.09581538012123,
      "grad_norm": 1.1104992628097534,
      "learning_rate": 1.9636261442106953e-05,
      "loss": 0.0744,
      "step": 7950
    },
    {
      "epoch": 3.115290050877577,
      "grad_norm": 1.1967729330062866,
      "learning_rate": 1.9435522723622934e-05,
      "loss": 0.0642,
      "step": 8000
    },
    {
      "epoch": 3.1347647216339247,
      "grad_norm": 0.9885398149490356,
      "learning_rate": 1.9234784005138912e-05,
      "loss": 0.0557,
      "step": 8050
    },
    {
      "epoch": 3.1542393923902723,
      "grad_norm": 0.3894854187965393,
      "learning_rate": 1.9034045286654893e-05,
      "loss": 0.0702,
      "step": 8100
    },
    {
      "epoch": 3.17371406314662,
      "grad_norm": 0.10084807872772217,
      "learning_rate": 1.8833306568170868e-05,
      "loss": 0.0729,
      "step": 8150
    },
    {
      "epoch": 3.1931887339029674,
      "grad_norm": 0.791208028793335,
      "learning_rate": 1.863256784968685e-05,
      "loss": 0.069,
      "step": 8200
    },
    {
      "epoch": 3.212663404659315,
      "grad_norm": 0.860937237739563,
      "learning_rate": 1.8431829131202826e-05,
      "loss": 0.0578,
      "step": 8250
    },
    {
      "epoch": 3.2321380754156626,
      "grad_norm": 1.443316102027893,
      "learning_rate": 1.8231090412718808e-05,
      "loss": 0.0682,
      "step": 8300
    },
    {
      "epoch": 3.25161274617201,
      "grad_norm": 1.2034870386123657,
      "learning_rate": 1.8030351694234785e-05,
      "loss": 0.0629,
      "step": 8350
    },
    {
      "epoch": 3.2710874169283577,
      "grad_norm": 2.2036020755767822,
      "learning_rate": 1.7829612975750763e-05,
      "loss": 0.0613,
      "step": 8400
    },
    {
      "epoch": 3.2905620876847053,
      "grad_norm": 1.1616666316986084,
      "learning_rate": 1.762887425726674e-05,
      "loss": 0.065,
      "step": 8450
    },
    {
      "epoch": 3.3100367584410524,
      "grad_norm": 1.3046015501022339,
      "learning_rate": 1.7428135538782722e-05,
      "loss": 0.0733,
      "step": 8500
    },
    {
      "epoch": 3.3295114291974,
      "grad_norm": 0.6348037123680115,
      "learning_rate": 1.72273968202987e-05,
      "loss": 0.0653,
      "step": 8550
    },
    {
      "epoch": 3.3489860999537475,
      "grad_norm": 0.7723544239997864,
      "learning_rate": 1.702665810181468e-05,
      "loss": 0.0582,
      "step": 8600
    },
    {
      "epoch": 3.368460770710095,
      "grad_norm": 0.8552418351173401,
      "learning_rate": 1.682591938333066e-05,
      "loss": 0.0737,
      "step": 8650
    },
    {
      "epoch": 3.3879354414664427,
      "grad_norm": 0.8251749873161316,
      "learning_rate": 1.6625180664846636e-05,
      "loss": 0.0542,
      "step": 8700
    },
    {
      "epoch": 3.40741011222279,
      "grad_norm": 0.47420430183410645,
      "learning_rate": 1.6424441946362614e-05,
      "loss": 0.0733,
      "step": 8750
    },
    {
      "epoch": 3.426884782979138,
      "grad_norm": 0.2783268690109253,
      "learning_rate": 1.6223703227878595e-05,
      "loss": 0.0682,
      "step": 8800
    },
    {
      "epoch": 3.4463594537354854,
      "grad_norm": 1.2637412548065186,
      "learning_rate": 1.6022964509394573e-05,
      "loss": 0.0627,
      "step": 8850
    },
    {
      "epoch": 3.465834124491833,
      "grad_norm": 0.6728519797325134,
      "learning_rate": 1.5822225790910554e-05,
      "loss": 0.0694,
      "step": 8900
    },
    {
      "epoch": 3.4853087952481805,
      "grad_norm": 0.23769576847553253,
      "learning_rate": 1.562148707242653e-05,
      "loss": 0.062,
      "step": 8950
    },
    {
      "epoch": 3.504783466004528,
      "grad_norm": 0.5591052770614624,
      "learning_rate": 1.542074835394251e-05,
      "loss": 0.0634,
      "step": 9000
    },
    {
      "epoch": 3.524258136760875,
      "grad_norm": 2.033684015274048,
      "learning_rate": 1.5220009635458487e-05,
      "loss": 0.0515,
      "step": 9050
    },
    {
      "epoch": 3.5437328075172227,
      "grad_norm": 4.2253947257995605,
      "learning_rate": 1.5019270916974469e-05,
      "loss": 0.0765,
      "step": 9100
    },
    {
      "epoch": 3.5632074782735703,
      "grad_norm": 0.4571508765220642,
      "learning_rate": 1.4818532198490445e-05,
      "loss": 0.0606,
      "step": 9150
    },
    {
      "epoch": 3.582682149029918,
      "grad_norm": 0.4352540075778961,
      "learning_rate": 1.4617793480006426e-05,
      "loss": 0.0676,
      "step": 9200
    },
    {
      "epoch": 3.6021568197862655,
      "grad_norm": 2.3573508262634277,
      "learning_rate": 1.4417054761522403e-05,
      "loss": 0.0585,
      "step": 9250
    },
    {
      "epoch": 3.621631490542613,
      "grad_norm": 1.5069025754928589,
      "learning_rate": 1.4216316043038383e-05,
      "loss": 0.0648,
      "step": 9300
    },
    {
      "epoch": 3.6411061612989606,
      "grad_norm": 0.7547840476036072,
      "learning_rate": 1.401557732455436e-05,
      "loss": 0.0682,
      "step": 9350
    },
    {
      "epoch": 3.660580832055308,
      "grad_norm": 1.4810978174209595,
      "learning_rate": 1.381483860607034e-05,
      "loss": 0.0642,
      "step": 9400
    },
    {
      "epoch": 3.6800555028116557,
      "grad_norm": 3.6335833072662354,
      "learning_rate": 1.3614099887586318e-05,
      "loss": 0.0741,
      "step": 9450
    },
    {
      "epoch": 3.699530173568003,
      "grad_norm": 3.919050931930542,
      "learning_rate": 1.3413361169102299e-05,
      "loss": 0.0656,
      "step": 9500
    },
    {
      "epoch": 3.719004844324351,
      "grad_norm": 1.919108271598816,
      "learning_rate": 1.3212622450618275e-05,
      "loss": 0.0701,
      "step": 9550
    },
    {
      "epoch": 3.738479515080698,
      "grad_norm": 1.2887351512908936,
      "learning_rate": 1.3011883732134256e-05,
      "loss": 0.0644,
      "step": 9600
    },
    {
      "epoch": 3.7579541858370455,
      "grad_norm": 0.4950656592845917,
      "learning_rate": 1.2811145013650234e-05,
      "loss": 0.059,
      "step": 9650
    },
    {
      "epoch": 3.777428856593393,
      "grad_norm": 2.6119544506073,
      "learning_rate": 1.2610406295166213e-05,
      "loss": 0.0654,
      "step": 9700
    },
    {
      "epoch": 3.7969035273497407,
      "grad_norm": 0.914099931716919,
      "learning_rate": 1.2409667576682191e-05,
      "loss": 0.0688,
      "step": 9750
    },
    {
      "epoch": 3.8163781981060882,
      "grad_norm": 1.368498682975769,
      "learning_rate": 1.2208928858198169e-05,
      "loss": 0.0732,
      "step": 9800
    },
    {
      "epoch": 3.835852868862436,
      "grad_norm": 1.0028977394104004,
      "learning_rate": 1.2008190139714148e-05,
      "loss": 0.0714,
      "step": 9850
    },
    {
      "epoch": 3.8553275396187834,
      "grad_norm": 1.4413317441940308,
      "learning_rate": 1.1807451421230128e-05,
      "loss": 0.0702,
      "step": 9900
    },
    {
      "epoch": 3.874802210375131,
      "grad_norm": 1.6705173254013062,
      "learning_rate": 1.1606712702746105e-05,
      "loss": 0.0557,
      "step": 9950
    },
    {
      "epoch": 3.8942768811314785,
      "grad_norm": 0.41787630319595337,
      "learning_rate": 1.1405973984262085e-05,
      "loss": 0.0617,
      "step": 10000
    },
    {
      "epoch": 3.9137515518878256,
      "grad_norm": 2.404517412185669,
      "learning_rate": 1.1205235265778063e-05,
      "loss": 0.061,
      "step": 10050
    },
    {
      "epoch": 3.9332262226441737,
      "grad_norm": 0.9211013317108154,
      "learning_rate": 1.1004496547294042e-05,
      "loss": 0.0614,
      "step": 10100
    },
    {
      "epoch": 3.9527008934005208,
      "grad_norm": 0.017080888152122498,
      "learning_rate": 1.0803757828810022e-05,
      "loss": 0.0619,
      "step": 10150
    },
    {
      "epoch": 3.9721755641568683,
      "grad_norm": 0.7108085751533508,
      "learning_rate": 1.0603019110326e-05,
      "loss": 0.0579,
      "step": 10200
    },
    {
      "epoch": 3.991650234913216,
      "grad_norm": 1.138494610786438,
      "learning_rate": 1.0402280391841979e-05,
      "loss": 0.061,
      "step": 10250
    },
    {
      "epoch": 4.003115947321016,
      "eval_loss": 0.08263424783945084,
      "eval_runtime": 1930.6981,
      "eval_samples_per_second": 4.551,
      "eval_steps_per_second": 4.551,
      "step": 10280
    },
    {
      "epoch": 4.010905815623555,
      "grad_norm": 2.66664981842041,
      "learning_rate": 1.0201541673357958e-05,
      "loss": 0.0652,
      "step": 10300
    },
    {
      "epoch": 4.030380486379902,
      "grad_norm": 0.6414310336112976,
      "learning_rate": 1.0000802954873936e-05,
      "loss": 0.0594,
      "step": 10350
    },
    {
      "epoch": 4.04985515713625,
      "grad_norm": 0.5000545382499695,
      "learning_rate": 9.800064236389915e-06,
      "loss": 0.0632,
      "step": 10400
    },
    {
      "epoch": 4.069329827892597,
      "grad_norm": 1.5287798643112183,
      "learning_rate": 9.599325517905893e-06,
      "loss": 0.0662,
      "step": 10450
    },
    {
      "epoch": 4.088804498648945,
      "grad_norm": 1.978405237197876,
      "learning_rate": 9.398586799421873e-06,
      "loss": 0.0618,
      "step": 10500
    },
    {
      "epoch": 4.108279169405292,
      "grad_norm": 1.764984369277954,
      "learning_rate": 9.197848080937852e-06,
      "loss": 0.0708,
      "step": 10550
    },
    {
      "epoch": 4.12775384016164,
      "grad_norm": 1.255053162574768,
      "learning_rate": 8.99710936245383e-06,
      "loss": 0.0645,
      "step": 10600
    },
    {
      "epoch": 4.147228510917987,
      "grad_norm": 2.212766170501709,
      "learning_rate": 8.79637064396981e-06,
      "loss": 0.0636,
      "step": 10650
    },
    {
      "epoch": 4.166703181674335,
      "grad_norm": 2.102506637573242,
      "learning_rate": 8.595631925485789e-06,
      "loss": 0.0534,
      "step": 10700
    },
    {
      "epoch": 4.186177852430682,
      "grad_norm": 0.26606282591819763,
      "learning_rate": 8.394893207001766e-06,
      "loss": 0.0594,
      "step": 10750
    },
    {
      "epoch": 4.20565252318703,
      "grad_norm": 3.1376497745513916,
      "learning_rate": 8.194154488517746e-06,
      "loss": 0.0552,
      "step": 10800
    },
    {
      "epoch": 4.225127193943377,
      "grad_norm": 0.6333580613136292,
      "learning_rate": 7.993415770033724e-06,
      "loss": 0.0594,
      "step": 10850
    },
    {
      "epoch": 4.244601864699725,
      "grad_norm": 4.549350738525391,
      "learning_rate": 7.792677051549703e-06,
      "loss": 0.0762,
      "step": 10900
    },
    {
      "epoch": 4.264076535456073,
      "grad_norm": 2.2117438316345215,
      "learning_rate": 7.591938333065682e-06,
      "loss": 0.0704,
      "step": 10950
    },
    {
      "epoch": 4.28355120621242,
      "grad_norm": 0.23700469732284546,
      "learning_rate": 7.39119961458166e-06,
      "loss": 0.0579,
      "step": 11000
    },
    {
      "epoch": 4.303025876968768,
      "grad_norm": 1.5939476490020752,
      "learning_rate": 7.19046089609764e-06,
      "loss": 0.0601,
      "step": 11050
    },
    {
      "epoch": 4.322500547725115,
      "grad_norm": 0.6719505786895752,
      "learning_rate": 6.989722177613618e-06,
      "loss": 0.058,
      "step": 11100
    },
    {
      "epoch": 4.341975218481463,
      "grad_norm": 2.494243860244751,
      "learning_rate": 6.788983459129597e-06,
      "loss": 0.0563,
      "step": 11150
    },
    {
      "epoch": 4.36144988923781,
      "grad_norm": 0.32198038697242737,
      "learning_rate": 6.5882447406455754e-06,
      "loss": 0.0577,
      "step": 11200
    },
    {
      "epoch": 4.380924559994158,
      "grad_norm": 0.33702075481414795,
      "learning_rate": 6.387506022161555e-06,
      "loss": 0.0698,
      "step": 11250
    },
    {
      "epoch": 4.400399230750505,
      "grad_norm": 1.0941493511199951,
      "learning_rate": 6.1867673036775335e-06,
      "loss": 0.0591,
      "step": 11300
    },
    {
      "epoch": 4.419873901506852,
      "grad_norm": 1.3288652896881104,
      "learning_rate": 5.986028585193512e-06,
      "loss": 0.051,
      "step": 11350
    },
    {
      "epoch": 4.4393485722632,
      "grad_norm": 0.7054290175437927,
      "learning_rate": 5.785289866709491e-06,
      "loss": 0.0623,
      "step": 11400
    },
    {
      "epoch": 4.458823243019547,
      "grad_norm": 2.5169155597686768,
      "learning_rate": 5.58455114822547e-06,
      "loss": 0.057,
      "step": 11450
    },
    {
      "epoch": 4.478297913775895,
      "grad_norm": 1.6933300495147705,
      "learning_rate": 5.383812429741449e-06,
      "loss": 0.0484,
      "step": 11500
    },
    {
      "epoch": 4.4977725845322425,
      "grad_norm": 3.201472759246826,
      "learning_rate": 5.183073711257427e-06,
      "loss": 0.0557,
      "step": 11550
    },
    {
      "epoch": 4.5172472552885905,
      "grad_norm": 2.5447025299072266,
      "learning_rate": 4.982334992773406e-06,
      "loss": 0.0555,
      "step": 11600
    },
    {
      "epoch": 4.536721926044938,
      "grad_norm": 2.0378165245056152,
      "learning_rate": 4.781596274289385e-06,
      "loss": 0.0526,
      "step": 11650
    },
    {
      "epoch": 4.556196596801286,
      "grad_norm": 2.4558627605438232,
      "learning_rate": 4.580857555805364e-06,
      "loss": 0.059,
      "step": 11700
    },
    {
      "epoch": 4.575671267557633,
      "grad_norm": 1.1666781902313232,
      "learning_rate": 4.3801188373213425e-06,
      "loss": 0.0558,
      "step": 11750
    },
    {
      "epoch": 4.59514593831398,
      "grad_norm": 1.0287399291992188,
      "learning_rate": 4.179380118837321e-06,
      "loss": 0.0631,
      "step": 11800
    },
    {
      "epoch": 4.614620609070328,
      "grad_norm": 1.5610233545303345,
      "learning_rate": 3.9786414003533e-06,
      "loss": 0.0624,
      "step": 11850
    },
    {
      "epoch": 4.634095279826676,
      "grad_norm": 1.9289263486862183,
      "learning_rate": 3.7779026818692787e-06,
      "loss": 0.047,
      "step": 11900
    },
    {
      "epoch": 4.653569950583023,
      "grad_norm": 5.80812406539917,
      "learning_rate": 3.5771639633852578e-06,
      "loss": 0.0656,
      "step": 11950
    },
    {
      "epoch": 4.67304462133937,
      "grad_norm": 1.2609752416610718,
      "learning_rate": 3.3764252449012364e-06,
      "loss": 0.0632,
      "step": 12000
    },
    {
      "epoch": 4.692519292095718,
      "grad_norm": 0.8786079287528992,
      "learning_rate": 3.1756865264172154e-06,
      "loss": 0.046,
      "step": 12050
    },
    {
      "epoch": 4.711993962852065,
      "grad_norm": 0.6655886173248291,
      "learning_rate": 2.9749478079331944e-06,
      "loss": 0.0471,
      "step": 12100
    },
    {
      "epoch": 4.731468633608413,
      "grad_norm": 3.3714582920074463,
      "learning_rate": 2.7742090894491734e-06,
      "loss": 0.0496,
      "step": 12150
    },
    {
      "epoch": 4.75094330436476,
      "grad_norm": 2.775116443634033,
      "learning_rate": 2.573470370965152e-06,
      "loss": 0.066,
      "step": 12200
    },
    {
      "epoch": 4.770417975121108,
      "grad_norm": 1.0623027086257935,
      "learning_rate": 2.372731652481131e-06,
      "loss": 0.0629,
      "step": 12250
    },
    {
      "epoch": 4.789892645877456,
      "grad_norm": 3.2300031185150146,
      "learning_rate": 2.1719929339971096e-06,
      "loss": 0.0545,
      "step": 12300
    },
    {
      "epoch": 4.809367316633804,
      "grad_norm": 0.3166443109512329,
      "learning_rate": 1.9712542155130882e-06,
      "loss": 0.0599,
      "step": 12350
    },
    {
      "epoch": 4.828841987390151,
      "grad_norm": 1.5816658735275269,
      "learning_rate": 1.7705154970290668e-06,
      "loss": 0.0539,
      "step": 12400
    },
    {
      "epoch": 4.848316658146498,
      "grad_norm": 1.5678397417068481,
      "learning_rate": 1.5697767785450456e-06,
      "loss": 0.053,
      "step": 12450
    },
    {
      "epoch": 4.867791328902846,
      "grad_norm": 2.5463011264801025,
      "learning_rate": 1.3690380600610246e-06,
      "loss": 0.0583,
      "step": 12500
    },
    {
      "epoch": 4.887265999659193,
      "grad_norm": 0.4011881649494171,
      "learning_rate": 1.1682993415770034e-06,
      "loss": 0.0527,
      "step": 12550
    },
    {
      "epoch": 4.906740670415541,
      "grad_norm": 0.376315176486969,
      "learning_rate": 9.675606230929822e-07,
      "loss": 0.0593,
      "step": 12600
    },
    {
      "epoch": 4.926215341171888,
      "grad_norm": 0.508587121963501,
      "learning_rate": 7.668219046089611e-07,
      "loss": 0.0521,
      "step": 12650
    },
    {
      "epoch": 4.945690011928236,
      "grad_norm": 1.3407808542251587,
      "learning_rate": 5.660831861249399e-07,
      "loss": 0.0575,
      "step": 12700
    },
    {
      "epoch": 4.965164682684583,
      "grad_norm": 2.3015823364257812,
      "learning_rate": 3.6534446764091856e-07,
      "loss": 0.0563,
      "step": 12750
    },
    {
      "epoch": 4.984639353440931,
      "grad_norm": 1.0445735454559326,
      "learning_rate": 1.646057491568974e-07,
      "loss": 0.061,
      "step": 12800
    }
  ],
  "logging_steps": 50,
  "max_steps": 12840,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 2570,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.440254844767756e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

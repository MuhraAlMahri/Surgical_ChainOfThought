# Experiment 2: Qwen Reordered Training with Qwen3-VL-8B - 4 GPUs
# Strategy: Train on QA pairs reordered by Qwen into clinical stages (1→2→3)
# Data is ordered but trained all together (NOT curriculum learning)
# Model: Qwen3-VL-8B-Instruct
# Resolution: Full (2,900 tokens)
# Hardware: 4 GPUs distributed training
# Expected time: ~14 hours (3 epochs)

model_name: Qwen/Qwen3-VL-8B-Instruct

vision_frozen: true

lora:
  r: 8
  alpha: 16
  dropout: 0.05
  target_modules: [q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj]

train:
  seed: 42
  max_seq_len: 2900  # Full resolution: Image needs 2622 + text ~250 = 2870, use 2900 for safety
  train_bs: 1  # Per-device batch size (4 GPUs × 1 = 4 total)
  grad_accum: 4  # Effective batch = 4×1×4 = 16
  eval_bs: 1
  lr: 5.0e-6
  weight_decay: 0.0
  epochs: 3  # Full training for best quality
  warmup_ratio: 0.0
  bf16: true
  gradient_checkpointing: true
  logging_steps: 10
  save_steps: 2000
  eval_steps: 2000

data:
  # Use ULTRA_CONDENSED data (same as exp1 but will preserve stage ordering)
  train_json: datasets/kvasir_ULTRA_CONDENSED/train_CATEGORY_BASED.jsonl
  val_json: datasets/kvasir_ULTRA_CONDENSED/val_CATEGORY_BASED.jsonl
  image_root: /l/users/muhra.almahri/Surgical_COT/datasets/Kvasir-VQA/raw/images
  use_vision_cache: false
  
  # Disable letterbox for full adaptive resolution
  use_letterbox: false
  target_size: 1036  # Not used when use_letterbox=false

eval:
  numeric_rel_tol: 0.05
  numeric_abs_tol: 0.0

# ============================================================================
# EXP2: QWEN REORDERED STRATEGY (4-GPU)
# ============================================================================
# - Same data as Exp1 BUT ordered by Qwen's clinical stages (1→2→3)
# - Stage 1 (35%): Initial Assessment (quality, procedure, artifacts)
# - Stage 2 (64%): Findings Identification (abnormalities, instruments)
# - Stage 3 (0.1%): Clinical Context (diagnosis, treatment)
# 
# - 4 GPUs: ~3.6x speedup (80-90% efficiency)
# - Full resolution: 2,900 tokens (no quality loss)
# - 3 epochs: Full training for maximum quality
# - Expected time: ~14 hours
# - Memory per GPU: ~10GB (fits easily in 40GB)
#
# This tests whether Qwen's intelligent clinical ordering helps vs 
# random order (exp1)
# ============================================================================


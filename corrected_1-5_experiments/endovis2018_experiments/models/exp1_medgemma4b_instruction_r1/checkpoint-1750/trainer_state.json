{
  "best_global_step": 1750,
  "best_metric": 2.3704118575551547e-05,
  "best_model_checkpoint": "/l/users/muhra.almahri/Surgical_COT/corrected_1-5_experiments/endovis2018_experiments/models/exp1_medgemma4b_instruction_r1/checkpoint-1750",
  "epoch": 4.487179487179487,
  "eval_steps": 125,
  "global_step": 1750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 1.322722315788269,
      "learning_rate": 4.152542372881356e-05,
      "loss": 1.8789,
      "step": 50
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 0.6022623777389526,
      "learning_rate": 4.8942358540454786e-05,
      "loss": 0.1692,
      "step": 100
    },
    {
      "epoch": 0.32051282051282054,
      "eval_loss": 0.009023880586028099,
      "eval_runtime": 133.3442,
      "eval_samples_per_second": 6.839,
      "eval_steps_per_second": 3.42,
      "step": 125
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.147438883781433,
      "learning_rate": 4.7620306716023275e-05,
      "loss": 0.0951,
      "step": 150
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 0.6117956638336182,
      "learning_rate": 4.629825489159175e-05,
      "loss": 0.0861,
      "step": 200
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 0.7467714548110962,
      "learning_rate": 4.497620306716023e-05,
      "loss": 0.0385,
      "step": 250
    },
    {
      "epoch": 0.6410256410256411,
      "eval_loss": 0.004371103830635548,
      "eval_runtime": 135.0602,
      "eval_samples_per_second": 6.753,
      "eval_steps_per_second": 3.376,
      "step": 250
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.4267531931400299,
      "learning_rate": 4.365415124272872e-05,
      "loss": 0.0348,
      "step": 300
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 1.821763038635254,
      "learning_rate": 4.23320994182972e-05,
      "loss": 0.0304,
      "step": 350
    },
    {
      "epoch": 0.9615384615384616,
      "eval_loss": 0.0008932010387070477,
      "eval_runtime": 135.4241,
      "eval_samples_per_second": 6.734,
      "eval_steps_per_second": 3.367,
      "step": 375
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.5365064144134521,
      "learning_rate": 4.101004759386568e-05,
      "loss": 0.0362,
      "step": 400
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.2623492181301117,
      "learning_rate": 3.968799576943417e-05,
      "loss": 0.0196,
      "step": 450
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 1.0675368309020996,
      "learning_rate": 3.8365943945002644e-05,
      "loss": 0.0256,
      "step": 500
    },
    {
      "epoch": 1.282051282051282,
      "eval_loss": 0.00233751954510808,
      "eval_runtime": 135.3825,
      "eval_samples_per_second": 6.736,
      "eval_steps_per_second": 3.368,
      "step": 500
    },
    {
      "epoch": 1.4102564102564101,
      "grad_norm": 0.4814022481441498,
      "learning_rate": 3.7043892120571126e-05,
      "loss": 0.0216,
      "step": 550
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.7762015461921692,
      "learning_rate": 3.572184029613961e-05,
      "loss": 0.024,
      "step": 600
    },
    {
      "epoch": 1.6025641025641026,
      "eval_loss": 0.0045344713144004345,
      "eval_runtime": 137.3209,
      "eval_samples_per_second": 6.641,
      "eval_steps_per_second": 3.321,
      "step": 625
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.3603861331939697,
      "learning_rate": 3.43997884717081e-05,
      "loss": 0.0198,
      "step": 650
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 0.3085746467113495,
      "learning_rate": 3.307773664727657e-05,
      "loss": 0.0229,
      "step": 700
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.24030649662017822,
      "learning_rate": 3.1755684822845055e-05,
      "loss": 0.0223,
      "step": 750
    },
    {
      "epoch": 1.9230769230769231,
      "eval_loss": 0.009171243757009506,
      "eval_runtime": 136.7174,
      "eval_samples_per_second": 6.671,
      "eval_steps_per_second": 3.335,
      "step": 750
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 1.9605849981307983,
      "learning_rate": 3.043363299841354e-05,
      "loss": 0.0182,
      "step": 800
    },
    {
      "epoch": 2.1794871794871793,
      "grad_norm": 0.0016863158671185374,
      "learning_rate": 2.9111581173982023e-05,
      "loss": 0.0084,
      "step": 850
    },
    {
      "epoch": 2.2435897435897436,
      "eval_loss": 0.025323759764432907,
      "eval_runtime": 131.9116,
      "eval_samples_per_second": 6.914,
      "eval_steps_per_second": 3.457,
      "step": 875
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.3253571689128876,
      "learning_rate": 2.7789529349550502e-05,
      "loss": 0.0198,
      "step": 900
    },
    {
      "epoch": 2.435897435897436,
      "grad_norm": 0.2713943123817444,
      "learning_rate": 2.6467477525118984e-05,
      "loss": 0.0103,
      "step": 950
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.5391771793365479,
      "learning_rate": 2.514542570068747e-05,
      "loss": 0.0142,
      "step": 1000
    },
    {
      "epoch": 2.564102564102564,
      "eval_loss": 0.004945793654769659,
      "eval_runtime": 135.9121,
      "eval_samples_per_second": 6.71,
      "eval_steps_per_second": 3.355,
      "step": 1000
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 0.6508610844612122,
      "learning_rate": 2.382337387625595e-05,
      "loss": 0.0077,
      "step": 1050
    },
    {
      "epoch": 2.8205128205128203,
      "grad_norm": 0.7019572257995605,
      "learning_rate": 2.2501322051824435e-05,
      "loss": 0.0108,
      "step": 1100
    },
    {
      "epoch": 2.8846153846153846,
      "eval_loss": 0.0031873758416622877,
      "eval_runtime": 135.847,
      "eval_samples_per_second": 6.713,
      "eval_steps_per_second": 3.357,
      "step": 1125
    },
    {
      "epoch": 2.948717948717949,
      "grad_norm": 0.3480932414531708,
      "learning_rate": 2.1179270227392914e-05,
      "loss": 0.0114,
      "step": 1150
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.001953422324731946,
      "learning_rate": 1.9857218402961396e-05,
      "loss": 0.0127,
      "step": 1200
    },
    {
      "epoch": 3.2051282051282053,
      "grad_norm": 0.11518260091543198,
      "learning_rate": 1.853516657852988e-05,
      "loss": 0.0032,
      "step": 1250
    },
    {
      "epoch": 3.2051282051282053,
      "eval_loss": 0.017535895109176636,
      "eval_runtime": 137.1205,
      "eval_samples_per_second": 6.651,
      "eval_steps_per_second": 3.326,
      "step": 1250
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.17600606381893158,
      "learning_rate": 1.721311475409836e-05,
      "loss": 0.0061,
      "step": 1300
    },
    {
      "epoch": 3.4615384615384617,
      "grad_norm": 0.6982715725898743,
      "learning_rate": 1.5891062929666846e-05,
      "loss": 0.0053,
      "step": 1350
    },
    {
      "epoch": 3.5256410256410255,
      "eval_loss": 7.996343629201874e-05,
      "eval_runtime": 136.3791,
      "eval_samples_per_second": 6.687,
      "eval_steps_per_second": 3.344,
      "step": 1375
    },
    {
      "epoch": 3.58974358974359,
      "grad_norm": 0.05703357607126236,
      "learning_rate": 1.4569011105235325e-05,
      "loss": 0.0063,
      "step": 1400
    },
    {
      "epoch": 3.717948717948718,
      "grad_norm": 3.5550179481506348,
      "learning_rate": 1.3246959280803809e-05,
      "loss": 0.0034,
      "step": 1450
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.028596702963113785,
      "learning_rate": 1.1924907456372291e-05,
      "loss": 0.0023,
      "step": 1500
    },
    {
      "epoch": 3.8461538461538463,
      "eval_loss": 0.009437505155801773,
      "eval_runtime": 136.4709,
      "eval_samples_per_second": 6.683,
      "eval_steps_per_second": 3.341,
      "step": 1500
    },
    {
      "epoch": 3.9743589743589745,
      "grad_norm": 0.04462384432554245,
      "learning_rate": 1.0602855631940772e-05,
      "loss": 0.0022,
      "step": 1550
    },
    {
      "epoch": 4.102564102564102,
      "grad_norm": 0.001127929543145001,
      "learning_rate": 9.280803807509254e-06,
      "loss": 0.0019,
      "step": 1600
    },
    {
      "epoch": 4.166666666666667,
      "eval_loss": 3.855117392959073e-05,
      "eval_runtime": 137.7357,
      "eval_samples_per_second": 6.621,
      "eval_steps_per_second": 3.311,
      "step": 1625
    },
    {
      "epoch": 4.230769230769231,
      "grad_norm": 0.003872867673635483,
      "learning_rate": 7.958751983077738e-06,
      "loss": 0.0006,
      "step": 1650
    },
    {
      "epoch": 4.358974358974359,
      "grad_norm": 0.020608525723218918,
      "learning_rate": 6.6367001586462195e-06,
      "loss": 0.0012,
      "step": 1700
    },
    {
      "epoch": 4.487179487179487,
      "grad_norm": 0.0024569525849074125,
      "learning_rate": 5.314648334214702e-06,
      "loss": 0.0004,
      "step": 1750
    },
    {
      "epoch": 4.487179487179487,
      "eval_loss": 2.3704118575551547e-05,
      "eval_runtime": 137.5758,
      "eval_samples_per_second": 6.629,
      "eval_steps_per_second": 3.315,
      "step": 1750
    }
  ],
  "logging_steps": 50,
  "max_steps": 1950,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 125,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.8159172880516576e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

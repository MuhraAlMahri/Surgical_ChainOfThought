# üöÄ Deployment Guide - Nov 5th Deadline

## Current Status (Nov 4, ~00:00)

### ‚úÖ Completed Jobs (3/14)
- **Job 152667**: Exp1 Training (Random Baseline) - 10.8h
- **Job 152668**: Exp2 Training (Qwen Reordered) - 10.8h  
- **Job 152677**: Exp3 Stage 1 - 10.8h

### üîÑ Running Jobs (2/14)
- **Job 152678**: Exp3 Stage 2 - 3h elapsed, 7h remaining
- **Job 152811**: Exp1 Evaluation - Just started, 2h remaining

### ‚è∏Ô∏è Pending Jobs (2/14 - QOS LIMITED)
- **Job 152812**: Exp2 Evaluation - STUCK
- **Job 152813**: Exp5 Training - STUCK

**‚ö†Ô∏è QOS Issue: Only 2 jobs running instead of 4!**

---

## üö® CRITICAL: Contact IT Helpdesk

**Subject:** QOS limit incorrectly set to 2 instead of 4

**Email Body:**
```
Hello IT Support,

I'm experiencing a QOS limit issue preventing my research deadline.

User: muhra.almahri
Partition: cscc-gpu-p
QOS: cscc-gpu-qos

Issue:
- Only 2 jobs can run concurrently
- Jobs stuck PENDING with error: "QOSMaxJobsPerUserLimit"
- Expected: 4 concurrent GPU jobs (as per QOS policy)

Affected Jobs:
- Running: 152678, 152811
- Stuck PENDING: 152812, 152813

Urgency: Nov 5th research deadline - need all 4 slots working

Thank you for urgent assistance!
```

---

## üìã Remaining Work (9 jobs)

### Training (5 jobs)
1. **Exp3 Stage 3** - Wait for Job 152678 (Exp3 S2) to finish
2. **Exp4 Stage 1** - Ready to submit
3. **Exp4 Stage 2** - Depends on Exp4 S1
4. **Exp4 Stage 3** - Depends on Exp4 S2
5. **Exp5 Training** - PENDING (Job 152813)

### Evaluation (4 jobs)
1. **Exp1 Eval** - RUNNING (Job 152811)
2. **Exp2 Eval** - PENDING (Job 152812)
3. **Exp3 Eval** - Wait for all Exp3 stages
4. **Exp4 Eval** - Wait for all Exp4 stages
5. **Exp5 Eval** - Wait for Exp5 training

---

## üéØ Deployment Steps

### Step 1: After IT Fixes QOS ‚úÖ

Run the auto-submission script:
```bash
cd "/l/users/muhra.almahri/Surgical_COT/corrected 1-5 experiments"
./submit_remaining_when_ready.sh
```

This will submit:
- Exp3 Stage 3 (if Exp3 S2 is done)
- Exp4 Stages 1, 2, 3 (with dependencies)

### Step 2: Monitor Progress

Check job status:
```bash
squeue -u muhra.almahri
```

Check training progress:
```bash
./monitor_all_training.sh
```

### Step 3: Submit Evaluations (After Training)

When training completes, manually submit evaluations:

**Exp3 Evaluation** (after all Exp3 stages):
```bash
sbatch experiments/exp3_cxrtrek_sequential/evaluate_exp3.slurm
```

**Exp4 Evaluation** (after all Exp4 stages):
```bash
sbatch experiments/exp4_curriculum_learning/evaluate_exp4.slurm
```

**Exp5 Evaluation** (after Exp5 training):
```bash
sbatch experiments/exp5_sequential_cot/evaluate_sequential_cot.slurm
```

---

## ‚è±Ô∏è Timeline (With QOS Fix)

| Time | Event |
|------|-------|
| **Now** | 2 jobs running (Exp3 S2, Exp1 Eval) |
| **+2h** | Exp1 Eval done ‚Üí Slot freed |
| **+7h** | Exp3 S2 done ‚Üí Submit Exp3 S3 |
| **+9h** | Exp2 Eval, Exp5 Training done |
| **+17h** | Exp3 S3, Exp4 S1 done ‚Üí Submit Exp4 S2 |
| **+27h** | Exp4 S2 done ‚Üí Submit Exp4 S3 |
| **+37h** | Exp4 S3 done ‚Üí Submit Exp4 Eval |
| **+39h** | All evaluations done |
| **Nov 5, 15:00** | ‚úÖ ALL COMPLETE (9h before deadline!) |

**Without QOS fix:** Would miss deadline by ~22 hours ‚ùå

---

## üõ†Ô∏è Quick Reference Commands

### Check Queue
```bash
squeue -u muhra.almahri
```

### Check Recent Completions
```bash
ls -lht logs/*.out | head -10
```

### Check Training Loss
```bash
tail -50 logs/exp*_*.out | grep -i "loss"
```

### Monitor All
```bash
./monitor_all_training.sh
```

### Cancel Job
```bash
scancel <JOB_ID>
```

### Check Job Details
```bash
scontrol show job <JOB_ID>
```

---

## üìä All Job Scripts Ready

### Training
- ‚úÖ `experiments/exp1_random/train_random_baseline.slurm`
- ‚úÖ `experiments/exp2_qwen_reordered/train_qwen_reordered.slurm`
- ‚úÖ `experiments/exp3_cxrtrek_sequential/train_stage1.slurm`
- ‚úÖ `experiments/exp3_cxrtrek_sequential/train_stage2.slurm`
- ‚úÖ `experiments/exp3_cxrtrek_sequential/train_stage3.slurm`
- ‚úÖ `experiments/exp4_curriculum_learning/train_stage1.slurm`
- ‚úÖ `experiments/exp4_curriculum_learning/train_stage2.slurm`
- ‚úÖ `experiments/exp4_curriculum_learning/train_stage3.slurm`
- ‚úÖ `experiments/exp5_sequential_cot/train_exp5.slurm`

### Evaluation
- ‚úÖ `experiments/exp1_random/evaluate_exp1.slurm`
- ‚úÖ `experiments/exp2_qwen_reordered/evaluate_exp2.slurm`
- ‚úÖ `experiments/exp3_cxrtrek_sequential/evaluate_exp3.slurm`
- ‚úÖ `experiments/exp4_curriculum_learning/evaluate_exp4.slurm`
- ‚úÖ `experiments/exp5_sequential_cot/evaluate_sequential_cot.slurm`

---

## üî• Critical Success Factors

1. **IT fixes QOS limit to 4 jobs** - URGENT!
2. **Monitor job completion** - Submit next batch promptly
3. **Check logs for errors** - Fix any failures quickly
4. **Submit evaluations** - Right after training completes

---

## üìû Support

If issues arise:
1. Check logs in `logs/` directory
2. Verify models saved in `models/` directory  
3. Check GPU availability: `nvidia-smi`
4. Contact IT if QOS issues persist

**Good luck! üöÄ**





